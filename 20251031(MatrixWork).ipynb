{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcvancity2022/Computer-Vision-Project-Overview/blob/main/20251031(MatrixWork).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvIx0KGWlPtp"
      },
      "source": [
        "<center><h1> <b>Image Dataset Analysis and Project Development with YOLO </b> </center> </h1>\n",
        "\n",
        "In this tutorial, we will see how image datasets with different types of tasks such as detection , segmentation etc. look like, and how they are labelled, specifically in YOLO format.\n",
        "\n",
        "Then, we will download one dataset to explore it and clean it if required.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLUWE8gn9_RB"
      },
      "source": [
        "## **Classification**\n",
        "\n",
        "Image classification is the simplest and involves classifying an entire image into one of a set of predefined classes.\n",
        "\n",
        "The output of an image classifier is a single class label and a confidence score. Image classification is useful when you need to know only what class an image belongs to and don't need to know where objects of that class are located or what their exact shape is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSkOCZxt-ZAO"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418606-adf35c62-2e11-405d-84c6-b84e7d013804.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OstzhA30B2tK"
      },
      "source": [
        "Usually each image has a single object in it, which is its class> Following image shows CIFAR10 Dataset.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://datagen.tech/wp-content/uploads/2022/11/image1.png\" width=\"600\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcIc5sJBCx2S"
      },
      "source": [
        "The dataset should be labelled by arranging them in the following folders heirarchy.\n",
        "\n",
        "              root/\n",
        "              |-- class1/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class2/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class3/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- ...\n",
        "\n",
        "In this folder structure, the root directory contains one subdirectory for each class in the dataset. Each subdirectory is named after the corresponding class and contains all the images for that class.\n",
        "\n",
        "For example:\n",
        "\n",
        "              cifar-10-/\n",
        "              |\n",
        "              |-- train/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10008_airplane.png\n",
        "              |   |   |-- 10009_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 1000_automobile.png\n",
        "              |   |   |-- 1001_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 10014_bird.png\n",
        "              |   |   |-- 10015_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- test/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10_airplane.png\n",
        "              |   |   |-- 11_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 100_automobile.png\n",
        "              |   |   |-- 101_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 1000_bird.png\n",
        "              |   |   |-- 1001_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTjx8pXEB1B5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cZ9e5J4zvF9"
      },
      "source": [
        "## **Object Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52PMPO-rgZq-"
      },
      "source": [
        "Object detection is a task that involves identifying the location and class of objects in an image or video stream.\n",
        "\n",
        "The output of an object detector is a set of bounding boxes that enclose the objects in the image, along with class labels and confidence scores for each box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDruPnQMi315"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418624-5785cb93-74c9-4541-9179-d5c6782d491a.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFz-X3Zx1xKn"
      },
      "source": [
        "**Labelling format**\n",
        "\n",
        "In object detection tasks, various labeling formats are used to annotate images with information about the objects present. These formats typically include details about the object's class and location within the image. Here are some of the most common labeling formats:\n",
        "\n",
        "1. COCO\n",
        "2. YOLO\n",
        "3. CSV  \n",
        "5. XML\n",
        "6. PASCAL VOC\n",
        "\n",
        "We will be discussing only YOLO format, as you will be using YOLO framework for your project:\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "\n",
        "      class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "- Box coordinates must be normalized between 0 and 1\n",
        "\n",
        "\n",
        "An example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6es7DWt75YTf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/91506361-c7965000-e886-11ea-8291-c72b98c25eec.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDeb1gEM5uIT"
      },
      "source": [
        "Corresponding label text file should look like:\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/112467037-d2568c00-8d66-11eb-8796-55402ac0d62f.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0brGPZa4oRk7"
      },
      "source": [
        "## **Segmentation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56IDqcG6mNw"
      },
      "source": [
        "Instance segmentation goes a step further than object detection and involves identifying individual objects in an image and segmenting them from the rest of the image.\n",
        "\n",
        "The output of an instance segmentation model is a set of masks or contours that outline each object in the image, along with class labels and confidence scores for each object. Instance segmentation is useful when you need to know not only where objects are in an image, but also what their exact shape is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oItmHrqo8qLM"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418644-7df320b8-098d-47f1-85c5-26604d761286.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2C24Fz389GY"
      },
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - bounding coordinates: The bounding coordinates around the mask area, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "      <class-index> <x1> <y1> <x2> <y2> ... <xn> <yn>\n",
        "\n",
        "\n",
        "Here is an example of the YOLO dataset format for a single image with two objects made up of a 3-point segment and a 5-point segment.\n",
        "\n",
        "\n",
        "      0 0.681 0.485 0.670 0.487 0.676 0.487\n",
        "      1 0.504 0.000 0.501 0.004 0.498 0.004 0.493 0.010 0.492 0.0104\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPFHkCO8-2mW"
      },
      "source": [
        "## **Pose Estimation**\n",
        "Pose estimation is a task that involves identifying the location of specific points in an image, usually referred to as keypoints. The keypoints can represent various parts of the object such as joints, landmarks, or other distinctive features. The locations of the keypoints are usually represented as a set of 2D [x, y] or 3D [x, y, visible] coordinates.\n",
        "\n",
        "The output of a pose estimation model is a set of points that represent the keypoints on an object in the image, usually along with the confidence scores for each point. Pose estimation is a good choice when you need to identify specific parts of an object in a scene, and their location in relation to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zebzQ_Z6_CB9"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418616-9811ac0b-a4a7-452a-8aba-484ba32bb4a8.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9M4kU8P_QWU"
      },
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - Object class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - Object center coordinates: The x and y coordinates of the center of the object, normalized to be between 0 and 1.\n",
        "  - Object width and height: The width and height of the object, normalized to be between 0 and 1.\n",
        "  - Object keypoint coordinates: The keypoints of the object, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "Here is an example of the label format for pose estimation task:\n",
        "\n",
        "Format with Dim = 2\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <px2> <py2> ... <pxn> <pyn>\n",
        "Format with Dim = 3\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <p1-visibility> <px2> <py2> <p2-visibility> ... <pxn> <pyn> <p2-visibility>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jCdTqcVbN4h"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')    # mount again\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsAvGgxxHAS3"
      },
      "source": [
        "## FOLDERS HEIRARCHY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt4h9bFXjV9V"
      },
      "source": [
        "\n",
        "\n",
        " We need to convert the dataset into a specific heirarchy of folders for all the tasks except for task of classification.\n",
        "\n",
        "\n",
        "The directories should be in the following format:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKyjblYvb8fW"
      },
      "source": [
        "# **COCO128 Dataset**\n",
        "\n",
        "This section aims to introduce you to COCO dataset frequently used in Artificial Intelligence (AI).It is a foundational dataset in AI, widely used for tasks like object detection, segmentation, and image captioning.\n",
        "\n",
        "\n",
        "It Contains over 330,000 images with more than 200,000 labeled across 80 object categories. Unique for its richly annotated images, including object segmentation.It is widely used in computer vision research and has been used to train and evaluate many state-of-the-art object detection and segmentation models.\n",
        "\n",
        "Link to full dataset: https://cocodataset.org/#home\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G11PH4xOo8zO"
      },
      "source": [
        "We are going using coco128 dataset.This dataset contains the first 128 images of COCO train 2017. It is used as the tutorial dataset for YOLO.\n",
        "\n",
        "Download the dataset from:\n",
        "https://www.kaggle.com/datasets/ultralytics/coco128/data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DUeZCUkSwkG"
      },
      "source": [
        "## Dataset Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJe53Fzd1mZn"
      },
      "source": [
        "\n",
        "To draw bounding boxes on images we need to understand the labelling format used by this dataset. The labels for this dataset are stored in YOLO format. i.e.\n",
        "\n",
        "        class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvPN5o_jSKgK"
      },
      "source": [
        "The class_id is the numerical number assigned to different class labels as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qry8OPsHG3GK"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Full Fire and Smoke Intensity Classes (plain text only)\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Serious Smoke\",\n",
        "    2: \"Moderate Smoke\",\n",
        "    3: \"Mild Smoke\",\n",
        "    4: \"Steam / False Alarm\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense / Non-Threat Smoke\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD3ZrKmubFZd"
      },
      "source": [
        "same bounding box for all to make sure all data is collected for confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpZNqiVSbFMl"
      },
      "outputs": [],
      "source": [
        "def draw_yolo_bbox(image_path, label_path):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read label file\n",
        "    with open(label_path, 'r') as file:\n",
        "        bboxes = file.readlines()\n",
        "\n",
        "    # Draw each bbox\n",
        "    for bbox in bboxes:\n",
        "        class_id, x_center, y_center, bbox_width, bbox_height = [float(x) for x in bbox.split()]\n",
        "\n",
        "        # Convert YOLO bbox format to rectangle coordinates\n",
        "        x1 = int((x_center - bbox_width / 2) * width)\n",
        "        y1 = int((y_center - bbox_height / 2) * height)\n",
        "        x2 = int((x_center + bbox_width / 2) * width)\n",
        "        y2 = int((y_center + bbox_height / 2) * height)\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "        # Put label (class_id) near the bbox\n",
        "        label = class_labels[int(class_id)]\n",
        "        cv2.putText(image, label, (x1, y1+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
        "    # Display image\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8tH0PySW4n"
      },
      "source": [
        "The rest of the four values i.e.\n",
        "\n",
        "    0.479492 0.688771 0.955609 0.5955\n",
        "\n",
        "indidicate the location of the bounding box.\n",
        "\n",
        "These values are normalized, which should be converted to a format that can be used as coordinate values of rectangle function (of cv2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQbCyFCMaueA"
      },
      "source": [
        "First import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoPPaZu5a4Fp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEcvixvYa-A8"
      },
      "source": [
        "Set all the paths of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EntyahAfNf4V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the path to Dataset 1\n",
        "dataset_path = \"/content/drive/MyDrive/dataset 1\"\n",
        "\n",
        "# Collect all image paths from train and val subfolders\n",
        "image_paths = []\n",
        "for subfolder in [\"train\", \"val\"]:\n",
        "    folder = os.path.join(dataset_path, \"images\", subfolder)\n",
        "    if os.path.exists(folder):\n",
        "        for image_name in os.listdir(folder):\n",
        "            if image_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                image_paths.append(os.path.join(folder, image_name))\n",
        "\n",
        "# Collect all label paths from train and val subfolders\n",
        "label_paths = []\n",
        "for subfolder in [\"train\", \"val\"]:\n",
        "    folder = os.path.join(dataset_path, \"labels\", subfolder)\n",
        "    if os.path.exists(folder):\n",
        "        for label_name in os.listdir(folder):\n",
        "            if label_name.endswith(\".txt\"):\n",
        "                label_paths.append(os.path.join(folder, label_name))\n",
        "\n",
        "# Print results\n",
        "print(f\"üì∏ Total images in Dataset 1: {len(image_paths)}\")\n",
        "print(f\"üßæ Total labels in Dataset 1: {len(label_paths)}\")\n",
        "print(\"\\nSample images:\")\n",
        "print(image_paths[:5])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvvtrG47R-vv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# Dataset 2 ‚Äî List all image and label paths\n",
        "# ============================================================\n",
        "dataset_path = \"/content/drive/MyDrive/dataset 2\"\n",
        "\n",
        "# Collect all image paths from train and val folders\n",
        "image_root = os.path.join(dataset_path, \"images\")\n",
        "image_paths = []\n",
        "for subdir in [\"train\", \"val\"]:\n",
        "    subdir_path = os.path.join(image_root, subdir)\n",
        "    if os.path.exists(subdir_path):\n",
        "        for image_name in os.listdir(subdir_path):\n",
        "            image_paths.append(os.path.join(subdir_path, image_name))\n",
        "\n",
        "# Collect all label paths from train and val folders\n",
        "label_root = os.path.join(dataset_path, \"labels\")\n",
        "label_paths = []\n",
        "for subdir in [\"train\", \"val\"]:\n",
        "    subdir_path = os.path.join(label_root, subdir)\n",
        "    if os.path.exists(subdir_path):\n",
        "        for label_name in os.listdir(subdir_path):\n",
        "            label_paths.append(os.path.join(subdir_path, label_name))\n",
        "\n",
        "# ============================================================\n",
        "# Print results\n",
        "# ============================================================\n",
        "print(\"üì∏ Image Paths:\")\n",
        "print(image_paths[:10])  # show first 10 for preview\n",
        "\n",
        "print(\"\\nüóíÔ∏è Label Paths:\")\n",
        "print(label_paths[:10])\n",
        "\n",
        "print(f\"\\n‚úÖ Total images: {len(image_paths)}\")\n",
        "print(f\"‚úÖ Total labels: {len(label_paths)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xS3INAjbPTr"
      },
      "outputs": [],
      "source": [
        "# Set the path to the dataset\n",
        "dataset_path = \"/content/drive/MyDrive/Home fire dataset/test\"\n",
        "\n",
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "print (image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpP4yE5-sitI"
      },
      "source": [
        "\n",
        "\n",
        "Set all the paths of the dataset of Fire and Smoke:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrVyXbVushbR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_root = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "annotations_json = os.path.join(dataset_root, \"annotations\", \"instances_val2017.json\")\n",
        "\n",
        "# Check if JSON exists\n",
        "if os.path.exists(annotations_json):\n",
        "    print(f\"‚úÖ JSON found at: {annotations_json}\")\n",
        "else:\n",
        "    print(f\"‚ùå JSON NOT found! Current working dir: {os.getcwd()}\")\n",
        "    # List contents of dataset_root to see folder names\n",
        "    print(\"Contents of dataset_root:\", os.listdir(dataset_root))\n",
        "    # List contents of annotations folder\n",
        "    annotations_folder = os.path.join(dataset_root, \"annotations\")\n",
        "    if os.path.exists(annotations_folder):\n",
        "        print(\"Contents of annotations folder:\", os.listdir(annotations_folder))\n",
        "    else:\n",
        "        print(\"Annotations folder not found!\")\n",
        "\n",
        "dataset_root = \"Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    for file in files:\n",
        "        if file.endswith(\".json\"):\n",
        "            print(\"Found JSON:\", os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZFQeneewaFY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Dataset Paths ‚Äî Auto Setup\n",
        "# ============================================================\n",
        "dataset_root = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "\n",
        "images_dir = os.path.join(dataset_root, \"val2017\")\n",
        "annotations_dir = os.path.join(dataset_root, \"annotations\")\n",
        "json_file = os.path.join(annotations_dir, \"instances_train2017.json\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\", \"train\")\n",
        "\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# Sanity checks\n",
        "if not os.path.exists(images_dir):\n",
        "    raise FileNotFoundError(f\"‚ùå Image folder missing: {images_dir}\")\n",
        "if not os.path.exists(json_file):\n",
        "    raise FileNotFoundError(f\"‚ùå COCO JSON not found: {json_file}\")\n",
        "\n",
        "print(f\"‚úÖ Image path: {images_dir}\")\n",
        "print(f\"‚úÖ JSON file:  {json_file}\")\n",
        "print(f\"‚úÖ Output dir: {labels_dir}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Load COCO JSON\n",
        "# ============================================================\n",
        "with open(json_file, \"r\") as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "# Validate COCO structure\n",
        "required_keys = {\"images\", \"annotations\", \"categories\"}\n",
        "if not required_keys.issubset(coco.keys()):\n",
        "    raise ValueError(f\"‚ùå Invalid COCO structure. Missing keys: {required_keys - set(coco.keys())}\")\n",
        "\n",
        "# Map image_id ‚Üí filename and size\n",
        "img_id2file = {img['id']: img['file_name'] for img in coco['images']}\n",
        "img_id2size = {img['id']: (img['width'], img['height']) for img in coco['images']}\n",
        "\n",
        "# Group annotations per image\n",
        "img_annotations = defaultdict(list)\n",
        "for ann in coco['annotations']:\n",
        "    if ann.get('bbox') and ann['bbox'][2] > 0 and ann['bbox'][3] > 0:\n",
        "        img_annotations[ann['image_id']].append(ann)\n",
        "\n",
        "print(f\"üìä Total images in JSON:      {len(img_id2file)}\")\n",
        "print(f\"üìä Images with annotations:   {len(img_annotations)}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Convert COCO ‚Üí YOLO format\n",
        "# ============================================================\n",
        "for img_id, anns in tqdm(img_annotations.items(), desc=\"Converting COCO ‚Üí YOLO TXT\"):\n",
        "    img_name = img_id2file[img_id]\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    txt_path = os.path.join(labels_dir, Path(img_name).stem + \".txt\")\n",
        "\n",
        "    # Retrieve image dimensions\n",
        "    if os.path.exists(img_path):\n",
        "        try:\n",
        "            with Image.open(img_path) as im:\n",
        "                w, h = im.size\n",
        "        except Exception:\n",
        "            w, h = img_id2size.get(img_id, (640, 480))\n",
        "    else:\n",
        "        w, h = img_id2size.get(img_id, (640, 480))\n",
        "\n",
        "    # Write YOLO annotation file\n",
        "    with open(txt_path, \"w\") as f:\n",
        "        for ann in anns:\n",
        "            cid = ann[\"category_id\"] - 1  # COCO is 1-indexed\n",
        "            x_min, y_min, box_w, box_h = ann[\"bbox\"]\n",
        "\n",
        "            if box_w <= 0 or box_h <= 0:\n",
        "                continue\n",
        "\n",
        "            x_center = (x_min + box_w / 2) / w\n",
        "            y_center = (y_min + box_h / 2) / h\n",
        "            width_norm = box_w / w\n",
        "            height_norm = box_h / h\n",
        "\n",
        "            f.write(f\"{cid} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Verify results (no display)\n",
        "# ============================================================\n",
        "txt_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
        "if not txt_files:\n",
        "    raise RuntimeError(\"‚ùå No YOLO .txt labels were generated. Check your JSON data.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Successfully created {len(txt_files)} YOLO label files.\")\n",
        "\n",
        "print(\"üéØ Conversion complete. All annotations exported cleanly.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpdeeXqKmf59"
      },
      "source": [
        "Updated fix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tob9jEdAmeUU"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Dataset Paths\n",
        "# ============================================================\n",
        "dataset_root = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "images_dir = os.path.join(dataset_root, \"val2017\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\", \"val\")\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Class Labels\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Smoke\",\n",
        "    2: \"Smoke\",\n",
        "    3: \"Smoke\",\n",
        "    4: \"Steam\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Intensity & Visibility (Data-Based)\n",
        "# ============================================================\n",
        "def analyze_intensity(img, bbox, cid):\n",
        "    from PIL import ImageStat\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean) / (3 * 255)\n",
        "    contrast = sum(stat.stddev) / (3 * 128)\n",
        "\n",
        "    if cid == 0:\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            return \"High Intensity (Flames Visible)\"\n",
        "        elif brightness > 0.45:\n",
        "            return \"Moderate Intensity (Active Burn)\"\n",
        "        else:\n",
        "            return \"Low Intensity (Smoldering Fire)\"\n",
        "    elif cid in [1, 2, 3, 5]:\n",
        "        if brightness < 0.25 and contrast < 0.3:\n",
        "            return \"Dense Smoke (Low Visibility)\"\n",
        "        elif brightness < 0.5:\n",
        "            return \"Moderate Smoke (Partial Visibility)\"\n",
        "        else:\n",
        "            return \"Light Smoke (Thin Haze)\"\n",
        "    elif cid == 4:\n",
        "        return \"Steam Cloud (Reflected Light)\"\n",
        "    elif cid == 6:\n",
        "        return \"Incense (Light Diffusion)\"\n",
        "    else:\n",
        "        return \"Unclassified\"\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Parse YOLO TXT ‚Äî data-only\n",
        "# ============================================================\n",
        "def parse_yolo_label(txt_path, w, h):\n",
        "    boxes = []\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            cid, xc, yc, bw, bh = map(float, parts[:5])\n",
        "            # convert from normalized ‚Üí pixels\n",
        "            xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "            x1, y1, x2, y2 = int(xc - bw / 2), int(yc - bh / 2), int(xc + bw / 2), int(yc + bh / 2)\n",
        "            boxes.append((int(cid), (x1, y1, x2, y2)))\n",
        "    return boxes\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ DATA-ONLY DISPLAY (no visuals, no aesthetics)\n",
        "# ============================================================\n",
        "def show_label_data_only(n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    if not matched:\n",
        "        print(\"‚ö†Ô∏è No matching image‚Äìlabel pairs found!\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìÑ Showing {min(n, len(matched))} data-based detections (no visuals)...\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next((os.path.join(images_dir, stem + ext)\n",
        "                         for ext in image_exts if os.path.exists(os.path.join(images_dir, stem + ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        w, h = img.size\n",
        "        boxes = parse_yolo_label(txt_path, w, h)\n",
        "\n",
        "        print(f\"üì∑ {stem}.jpg ({w}x{h}) ‚Äî {len(boxes)} detections:\")\n",
        "        for cid, (x1, y1, x2, y2) in boxes:\n",
        "            cname = class_labels.get(cid, \"Unknown\")\n",
        "            intensity = analyze_intensity(img, (x1, y1, x2, y2), cid)\n",
        "            print(f\"   - Class: {cname} | Intensity: {intensity}\")\n",
        "            print(f\"     Bounding Box (px): {x1, y1, x2, y2}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Run ‚Äî Data-Only Summary\n",
        "# ============================================================\n",
        "show_label_data_only(n=20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3b2OCk5PhU7"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Directories\n",
        "# ============================================================\n",
        "images_dir = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\"\n",
        "labels_dir = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\"\n",
        "save_dir = \"/content/drive/MyDrive/fire_smoke_previews/data_labels_output\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Parse .txt ‚Äî use *all numeric values as-is*\n",
        "# ============================================================\n",
        "def parse_yolo_label(txt_path, w, h):\n",
        "    \"\"\"Reads YOLO labels and converts to bounding boxes using all .txt numbers.\"\"\"\n",
        "    boxes = []\n",
        "    if not os.path.exists(txt_path):\n",
        "        return boxes\n",
        "\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "\n",
        "            # extract all values\n",
        "            cid = int(float(parts[0]))\n",
        "            vals = list(map(float, parts[1:5]))\n",
        "\n",
        "            # determine if normalized or absolute coordinates\n",
        "            if all(0 <= v <= 1 for v in vals):\n",
        "                xc, yc, bw, bh = vals\n",
        "                x1 = int((xc - bw / 2) * w)\n",
        "                y1 = int((yc - bh / 2) * h)\n",
        "                x2 = int((xc + bw / 2) * w)\n",
        "                y2 = int((yc + bh / 2) * h)\n",
        "            else:\n",
        "                # if absolute\n",
        "                x1, y1, x2, y2 = map(int, vals)\n",
        "\n",
        "            # append including raw numbers (for later display)\n",
        "            boxes.append((cid, (x1, y1, x2, y2), vals))\n",
        "    return boxes\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Draw Bounding Boxes (include txt numbers)\n",
        "# ============================================================\n",
        "def draw_true_labels(img_path, txt_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    w, h = img.size\n",
        "    boxes = parse_yolo_label(txt_path, w, h)\n",
        "    if not boxes:\n",
        "        return img, 0\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    for cid, (x1, y1, x2, y2), vals in boxes:\n",
        "        color = (0, 255, 255)\n",
        "        draw.rectangle((x1, y1, x2, y2), outline=color, width=2)\n",
        "\n",
        "        # show ID + actual txt file numbers\n",
        "        vals_str = \", \".join(f\"{v:.6f}\" for v in vals)\n",
        "        label_text = f\"ID{cid}: [{vals_str}]\"\n",
        "        draw.text((x1 + 3, y1 - 12), label_text, fill=color)\n",
        "\n",
        "    return img, len(boxes)\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Display and Save Images\n",
        "# ============================================================\n",
        "def display_and_save_data_labels(n=5):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    print(f\"\\nüì∏ Displaying {min(n, len(matched))} exact data-based annotations...\\n\")\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next((os.path.join(images_dir, stem + ext)\n",
        "                         for ext in image_exts if os.path.exists(os.path.join(images_dir, stem + ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img, count = draw_true_labels(img_path, txt_path)\n",
        "        display(img)\n",
        "        print(f\"‚úÖ {stem}.jpg ‚Äî {count} boxes (from txt values)\")\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{stem}_from_txt.jpg\")\n",
        "        img.save(save_path)\n",
        "\n",
        "    print(f\"\\nüíæ Saved annotated images to: {save_dir}\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Run\n",
        "# ============================================================\n",
        "display_and_save_data_labels(n=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbPjRswQ1duv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "image_stems = sorted([Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "label_stems = sorted([Path(f).stem for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
        "\n",
        "print(\"üñºÔ∏è  First 10 image names:\", image_stems[:10])\n",
        "print(\"üìù First 10 label names:\", label_stems[:10])\n",
        "print(\"üîé Common stems:\", len(set(image_stems) & set(label_stems)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh72xpjY1hCj"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "img_dir = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\"\n",
        "lbl_dir = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\"\n",
        "\n",
        "img_stems = {os.path.splitext(f)[0] for f in os.listdir(img_dir) if f.endswith(('.jpg','.png'))}\n",
        "for lbl in os.listdir(lbl_dir):\n",
        "    if not lbl.endswith('.txt'): continue\n",
        "    old_path = os.path.join(lbl_dir, lbl)\n",
        "    base = os.path.splitext(lbl)[0]\n",
        "    # find any image name that starts with same digits\n",
        "    match = next((i for i in img_stems if i in base or base in i), None)\n",
        "    if match and base != match:\n",
        "        new_path = os.path.join(lbl_dir, f\"{match}.txt\")\n",
        "        shutil.move(old_path, new_path)\n",
        "        print(f\"üîß Renamed {lbl} ‚Üí {match}.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l46mseBNReL3"
      },
      "source": [
        "validate the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW5VzMIeVJY9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/Home fire dataset/test/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "\n",
        "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "\n",
        "missing_images = sorted(label_stems - image_stems)\n",
        "extra_images = sorted(image_stems - label_stems)\n",
        "\n",
        "# Delete YOLO txts that don‚Äôt match an image\n",
        "for stem in missing_images:\n",
        "    os.remove(os.path.join(labels_dir, f\"{stem}.txt\"))\n",
        "\n",
        "print(f\"‚úÖ Kept {len(image_stems & label_stems)} valid image‚Äìlabel pairs.\")\n",
        "print(f\"üóëÔ∏è Removed {len(missing_images)} orphan label files (no matching image).\")\n",
        "if extra_images:\n",
        "    print(f\"‚ö†Ô∏è {len(extra_images)} images have no label files (you can auto-generate later).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwQmsHS_a4vX"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "image_stems = {Path(f).stem for f in os.listdir(images_dir)}\n",
        "label_stems = {Path(f).stem for f in os.listdir(labels_dir)}\n",
        "matched = image_stems & label_stems\n",
        "print(f\"‚úÖ Matched pairs: {len(matched)} / {len(image_stems)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qKkTJeSRdPh"
      },
      "source": [
        "validate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA82BKt3Rc8A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Set paths for Dataset 1 (with nested train/val folders)\n",
        "# ============================================================\n",
        "dataset_root = \"/content/drive/MyDrive/dataset 1\"\n",
        "images_root = os.path.join(dataset_root, \"images\")\n",
        "labels_root = os.path.join(dataset_root, \"labels\")\n",
        "\n",
        "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "# Collect all images recursively\n",
        "image_files = [p for p in Path(images_root).rglob(\"*\") if p.suffix.lower() in image_exts]\n",
        "label_files = [p for p in Path(labels_root).rglob(\"*.txt\")]\n",
        "\n",
        "image_stems = {f.stem for f in image_files}\n",
        "label_stems = {f.stem for f in label_files}\n",
        "\n",
        "missing_images = sorted(label_stems - image_stems)\n",
        "extra_images = sorted(image_stems - label_stems)\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Delete orphan labels (no matching image)\n",
        "# ============================================================\n",
        "for stem in missing_images:\n",
        "    for lbl in Path(labels_root).rglob(f\"{stem}.txt\"):\n",
        "        os.remove(lbl)\n",
        "\n",
        "print(f\"‚úÖ Kept {len(image_stems & label_stems)} valid image‚Äìlabel pairs in Dataset 1.\")\n",
        "print(f\"üóëÔ∏è Removed {len(missing_images)} orphan label files (no matching image).\")\n",
        "if extra_images:\n",
        "    print(f\"‚ö†Ô∏è {len(extra_images)} images have no label files (you can auto-generate later).\")\n",
        "\n",
        "# Sanity check\n",
        "matched = image_stems & label_stems\n",
        "print(f\"üìä Matched pairs: {len(matched)} / {len(image_stems)} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63-2FvI2RcxN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Set paths for Dataset 2 (with nested train/val folders)\n",
        "# ============================================================\n",
        "dataset_root = \"/content/drive/MyDrive/dataset 2\"\n",
        "images_root = os.path.join(dataset_root, \"images\")\n",
        "labels_root = os.path.join(dataset_root, \"labels\")\n",
        "\n",
        "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "# Collect all images recursively\n",
        "image_files = [p for p in Path(images_root).rglob(\"*\") if p.suffix.lower() in image_exts]\n",
        "label_files = [p for p in Path(labels_root).rglob(\"*.txt\")]\n",
        "\n",
        "image_stems = {f.stem for f in image_files}\n",
        "label_stems = {f.stem for f in label_files}\n",
        "\n",
        "missing_images = sorted(label_stems - image_stems)\n",
        "extra_images = sorted(image_stems - label_stems)\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Delete orphan labels (no matching image)\n",
        "# ============================================================\n",
        "for stem in missing_images:\n",
        "    for lbl in Path(labels_root).rglob(f\"{stem}.txt\"):\n",
        "        os.remove(lbl)\n",
        "\n",
        "print(f\"‚úÖ Kept {len(image_stems & label_stems)} valid image‚Äìlabel pairs in Dataset 2.\")\n",
        "print(f\"üóëÔ∏è Removed {len(missing_images)} orphan label files (no matching image).\")\n",
        "if extra_images:\n",
        "    print(f\"‚ö†Ô∏è {len(extra_images)} images have no label files (you can auto-generate later).\")\n",
        "\n",
        "# Sanity check\n",
        "matched = image_stems & label_stems\n",
        "print(f\"üìä Matched pairs: {len(matched)} / {len(image_stems)} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjRzIU9RRioq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT_aa_4NVLOg"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Paths\n",
        "# ============================================================\n",
        "images_dir = \"/content/drive/MyDrive/Home fire dataset/test/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Class labels\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Smoke\",\n",
        "    2: \"Smoke\",\n",
        "    3: \"Smoke\",\n",
        "    4: \"Steam\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Helpers\n",
        "# ============================================================\n",
        "def strip_annotation(stem: str):\n",
        "    \"\"\"Normalize file stems by removing _annotation or _annotated.\"\"\"\n",
        "    for suf in (\"_annotation\", \"_annotated\"):\n",
        "        if stem.lower().endswith(suf):\n",
        "            stem = stem[: -len(suf)]\n",
        "    return stem\n",
        "\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) < 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts[:5])\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw/2), int(yc - bh/2), int(xc + bw/2), int(yc + bh/2))\n",
        "\n",
        "def analyze_intensity(img, bbox, cid):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean) / (3 * 255)\n",
        "    contrast = sum(stat.stddev) / (3 * 128)\n",
        "\n",
        "    if cid == 0:  # Fire\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            return \"High Intensity (Flames Visible)\"\n",
        "        elif brightness > 0.45:\n",
        "            return \"Medium Intensity (Active Burn)\"\n",
        "        else:\n",
        "            return \"Low Intensity (Smoldering Fire)\"\n",
        "    elif cid in [1, 2, 3, 5]:  # Smoke\n",
        "        if brightness < 0.25 and contrast < 0.3:\n",
        "            return \"Dense Smoke (Low Visibility)\"\n",
        "        elif brightness < 0.5:\n",
        "            return \"Moderate Smoke (Partial Visibility)\"\n",
        "        else:\n",
        "            return \"Light Smoke (Thin Haze)\"\n",
        "    elif cid == 4:\n",
        "        return \"Steam (Reflected Light)\"\n",
        "    elif cid == 6:\n",
        "        return \"Incense / Light Diffusion\"\n",
        "    return \"Unclassified\"\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Display and annotate using TXT labels\n",
        "# ============================================================\n",
        "def display_clean_annotations(images_dir, labels_dir, n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(image_exts)]\n",
        "    label_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    # Normalize stems for matching\n",
        "    image_stems = {strip_annotation(Path(f).stem) for f in image_files}\n",
        "    label_stems = {strip_annotation(Path(f).stem) for f in label_files}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    if not matched:\n",
        "        print(\"‚ö†Ô∏è No matching image-label pairs found!\")\n",
        "        print(f\"Check folder contents: {images_dir} & {labels_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìÇ Displaying {min(n, len(matched))} labeled samples (of {len(matched)} total)...\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        # Match actual files\n",
        "        img_path = next((os.path.join(images_dir, f)\n",
        "                         for f in image_files if strip_annotation(Path(f).stem) == stem), None)\n",
        "        txt_path = next((os.path.join(labels_dir, f)\n",
        "                         for f in label_files if strip_annotation(Path(f).stem) == stem), None)\n",
        "        if not img_path or not txt_path:\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        with open(txt_path, \"r\") as f:\n",
        "            lines = [ln.strip() for ln in f if ln.strip() and not ln.startswith(\"#\")]\n",
        "        if not lines:\n",
        "            print(f\"‚ö†Ô∏è Empty label file for {Path(img_path).name}\")\n",
        "            continue\n",
        "\n",
        "        for line in lines:\n",
        "            cid, bbox = yolo_to_bbox(line, w, h)\n",
        "            if not bbox:\n",
        "                continue\n",
        "            intensity = analyze_intensity(img, bbox, cid)\n",
        "            cname = class_labels.get(cid, \"Unknown\")\n",
        "            label_text = f\"{cname} ‚Äî {intensity}\"\n",
        "\n",
        "            draw.rectangle(bbox, outline=(255, 255, 255), width=2)\n",
        "            draw.text((bbox[0] + 2, bbox[1] - 14), label_text, fill=(255, 255, 255))\n",
        "            print(f\"{Path(img_path).name} ‚Üí {label_text}\")\n",
        "\n",
        "        display(img)\n",
        "        print(f\"‚úÖ Displayed: {Path(img_path).name}\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Run\n",
        "# ============================================================\n",
        "display_clean_annotations(images_dir, labels_dir, n=25)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"/content/drive/MyDrive/Home fire dataset/test/images\")), len(os.listdir(\"/content/drive/MyDrive/Home fire dataset/test/labels\"))\n"
      ],
      "metadata": {
        "id": "gwm3cwQjb7HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find \"/content/drive/MyDrive/Home fire dataset/test\" -maxdepth 2 -type f | head -20\n"
      ],
      "metadata": {
        "id": "CD77Bxq9bOVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT6jdlYWT3di"
      },
      "source": [
        "Datasets NEW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Ju0LDXPTGw"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ PATHS ‚Äî DATASET 1\n",
        "# ============================================================\n",
        "# üîπ Switch between \"train\" and \"val\" easily\n",
        "images_dir = \"/content/drive/MyDrive/dataset 1/images/train\"\n",
        "labels_dir = \"/content/drive/MyDrive/dataset 1/labels/train\"\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ BASE LABELS ‚Äî simplified, no emojis\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Smoke\",\n",
        "    2: \"Smoke\",\n",
        "    3: \"Smoke\",\n",
        "    4: \"Steam\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ YOLO TXT ‚Üí BBox\n",
        "# ============================================================\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw / 2), int(yc - bh / 2), int(xc + bw / 2), int(yc + bh / 2))\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Brightness & Contrast Analyzer\n",
        "# ============================================================\n",
        "def analyze_visibility(img, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean) / (3 * 255)\n",
        "    contrast = sum(stat.stddev) / (3 * 128)\n",
        "    return brightness, contrast\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Intensity Classification System\n",
        "# ============================================================\n",
        "def classify_intensity(cid, brightness, contrast):\n",
        "    \"\"\"Returns a plain-text intensity or density description based on pixel stats.\"\"\"\n",
        "    if cid == 0:  # Fire\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            return \"High Intensity (Flames Visible)\"\n",
        "        elif brightness > 0.45:\n",
        "            return \"Moderate Intensity (Active Burn)\"\n",
        "        else:\n",
        "            return \"Low Intensity (Smoldering)\"\n",
        "    elif cid in [1, 2, 3, 5]:  # Smoke\n",
        "        if brightness < 0.25 and contrast < 0.3:\n",
        "            return \"Dense Smoke (Low Visibility)\"\n",
        "        elif brightness < 0.5:\n",
        "            return \"Moderate Smoke (Partial Visibility)\"\n",
        "        else:\n",
        "            return \"Light Smoke (Thin Haze)\"\n",
        "    elif cid == 4:\n",
        "        return \"Steam Cloud (Reflected Light)\"\n",
        "    elif cid == 6:\n",
        "        return \"Incense Diffusion\"\n",
        "    return \"Unclassified\"\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ DISPLAY FUNCTION ‚Äî Clean Text Labels Only\n",
        "# ============================================================\n",
        "def display_clean_labels(images_dir, labels_dir, n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    print(f\"\\nüìÇ Displaying {min(n, len(matched))} annotated samples (of {len(matched)} total)‚Ä¶\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next((os.path.join(images_dir, stem + ext)\n",
        "                         for ext in image_exts if os.path.exists(os.path.join(images_dir, stem + ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        with open(txt_path) as f:\n",
        "            for line in f.readlines():\n",
        "                cid, bbox = yolo_to_bbox(line, w, h)\n",
        "                if not bbox:\n",
        "                    continue\n",
        "\n",
        "                brightness, contrast = analyze_visibility(img, bbox)\n",
        "                cname = class_labels.get(cid, \"Unknown\")\n",
        "                intensity = classify_intensity(cid, brightness, contrast)\n",
        "\n",
        "                label_text = f\"{cname} ‚Äî {intensity}\"\n",
        "                draw.rectangle(bbox, outline=(255, 255, 255), width=2)\n",
        "                draw.text((bbox[0] + 2, bbox[1] - 14), label_text, fill=(255, 255, 255))\n",
        "\n",
        "        display(img)\n",
        "        print(f\"‚úÖ {stem}.jpg | {label_text}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ RUN\n",
        "# ============================================================\n",
        "display_clean_labels(images_dir, labels_dir, n=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9qMHKF0PS54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Dataset 2 Paths\n",
        "# ============================================================\n",
        "dataset_path = \"/content/drive/MyDrive/dataset 2\"\n",
        "image_root = os.path.join(dataset_path, \"images\")\n",
        "label_root = os.path.join(dataset_path, \"labels\")\n",
        "\n",
        "# Load all image paths (train + val)\n",
        "image_paths = []\n",
        "for split in [\"train\", \"val\"]:\n",
        "    split_dir = os.path.join(image_root, split)\n",
        "    if os.path.exists(split_dir):\n",
        "        for img_name in os.listdir(split_dir):\n",
        "            if img_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                image_paths.append(os.path.join(split_dir, img_name))\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Draw Bounding Boxes (pure YOLO data)\n",
        "# ============================================================\n",
        "def draw_yolo_bbox(image_path, label_path):\n",
        "    \"\"\"Draw rectangles using class numbers directly from .txt.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"‚ö†Ô∏è Could not read image: {image_path}\")\n",
        "        return\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        print(f\"‚ö†Ô∏è Missing label: {label_path}\")\n",
        "        return\n",
        "\n",
        "    with open(label_path, 'r') as file:\n",
        "        bboxes = file.readlines()\n",
        "\n",
        "    # Draw each bounding box directly from data\n",
        "    for bbox in bboxes:\n",
        "        parts = bbox.strip().split()\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "        class_id, x_center, y_center, bbox_width, bbox_height = [float(x) for x in parts[:5]]\n",
        "\n",
        "        # Convert normalized YOLO format ‚Üí pixel rectangle\n",
        "        x1 = int((x_center - bbox_width / 2) * width)\n",
        "        y1 = int((y_center - bbox_height / 2) * height)\n",
        "        x2 = int((x_center + bbox_width / 2) * width)\n",
        "        y2 = int((y_center + bbox_height / 2) * height)\n",
        "\n",
        "        # Draw data-based box (no aesthetic style)\n",
        "        color = (0, 255, 255)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        # Show class number directly from txt\n",
        "        class_text = f\"Class {int(class_id)}\"\n",
        "        cv2.putText(image, class_text, (x1, max(y1 - 10, 10)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)\n",
        "\n",
        "    # Display image (true YOLO annotations)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Display Random Data-Based Images\n",
        "# ============================================================\n",
        "def print_random_images(photos: list, n: int = 5):\n",
        "    for _ in range(n):\n",
        "        random_photo_path = random.choice(photos)\n",
        "        name = os.path.splitext(os.path.basename(random_photo_path))[0]\n",
        "\n",
        "        # Look for label in train or val folder\n",
        "        found_label = False\n",
        "        for split in [\"train\", \"val\"]:\n",
        "            label_path = os.path.join(label_root, split, f\"{name}.txt\")\n",
        "            if os.path.exists(label_path):\n",
        "                print(f\"\\nüì∑ Displaying {name}.jpg with numeric labels from {split}...\")\n",
        "                draw_yolo_bbox(random_photo_path, label_path)\n",
        "                found_label = True\n",
        "                break\n",
        "\n",
        "        if not found_label:\n",
        "            print(f\"üö´ No label found for {name}.jpg\")\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Run Display\n",
        "# ============================================================\n",
        "print_random_images(image_paths, n=6)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifIgjyTMVcvX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MegzRT78_GK9"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ GLOBAL SETTINGS ‚Äî ALL DATASETS\n",
        "# ============================================================\n",
        "datasets = {\n",
        "    \"Fire_Smoke_COCO\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\"\n",
        "    },\n",
        "    \"Home_Fire_Test\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Home fire dataset/test/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "    },\n",
        "    \"Dataset_1\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 1/images/train\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 1/labels/train\"\n",
        "    },\n",
        "    \"Dataset_2\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 2/images/train\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 2/labels/train\"\n",
        "    }\n",
        "}\n",
        "\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Smoke\",\n",
        "    2: \"Smoke\",\n",
        "    3: \"Smoke\",\n",
        "    4: \"Steam\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ HELPERS ‚Äî YOLO PARSING + BRIGHTNESS ANALYSIS\n",
        "# ============================================================\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) < 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts[:5])\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw/2), int(yc - bh/2), int(xc + bw/2), int(yc + bh/2))\n",
        "\n",
        "def analyze_region(img, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"L\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = stat.mean[0] / 255\n",
        "    contrast = stat.stddev[0] / 128\n",
        "    return brightness, contrast\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ INTENSITY CLASSIFIER\n",
        "# ============================================================\n",
        "def classify_intensity(cid, brightness, contrast):\n",
        "    if cid == 0:  # Fire\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            return \"High Intensity (Flames Visible)\"\n",
        "        elif brightness > 0.45:\n",
        "            return \"Moderate Intensity (Active Burn)\"\n",
        "        else:\n",
        "            return \"Low Intensity (Smoldering)\"\n",
        "    elif cid in [1, 2, 3, 5]:  # Smoke\n",
        "        if brightness < 0.25 and contrast < 0.3:\n",
        "            return \"Dense Smoke (Low Visibility)\"\n",
        "        elif brightness < 0.5:\n",
        "            return \"Moderate Smoke (Partial Visibility)\"\n",
        "        else:\n",
        "            return \"Light Smoke (Thin Haze)\"\n",
        "    elif cid == 4:\n",
        "        return \"Steam Cloud (Reflected Light)\"\n",
        "    elif cid == 6:\n",
        "        return \"Incense Diffusion\"\n",
        "    return \"Unclassified\"\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ OBJECT DETECTION + TEXT LABEL DISPLAY\n",
        "# ============================================================\n",
        "def display_detections(images_dir, labels_dir, dataset_name, n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    print(f\"\\nüì¶ Dataset: {dataset_name}\")\n",
        "    print(f\"üì∏ Found {len(matched)} valid image‚Äìlabel pairs.\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next((os.path.join(images_dir, stem + ext)\n",
        "                         for ext in image_exts if os.path.exists(os.path.join(images_dir, stem + ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        detections = []\n",
        "        with open(txt_path) as f:\n",
        "            for line in f.readlines():\n",
        "                cid, bbox = yolo_to_bbox(line, w, h)\n",
        "                if not bbox:\n",
        "                    continue\n",
        "                brightness, contrast = analyze_region(img, bbox)\n",
        "                cname = class_labels.get(cid, \"Unknown\")\n",
        "                intensity = classify_intensity(cid, brightness, contrast)\n",
        "                detections.append((cname, intensity, bbox))\n",
        "\n",
        "        # Draw detections (text only)\n",
        "        for cname, intensity, bbox in detections:\n",
        "            label_text = f\"{cname} ‚Äî {intensity}\"\n",
        "            draw.rectangle(bbox, outline=(255, 255, 255), width=2)\n",
        "            draw.text((bbox[0] + 2, bbox[1] - 14), label_text, fill=(255, 255, 255))\n",
        "\n",
        "        # Display annotated image\n",
        "        display(img)\n",
        "\n",
        "        # Print summary in terminal\n",
        "        print(f\"‚úÖ {stem}.jpg | {len(detections)} objects detected\")\n",
        "        for cname, intensity, bbox in detections:\n",
        "            print(f\"   - {cname}: {intensity}  |  bbox={bbox}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ RUN DETECTIONS FOR ALL DATASETS\n",
        "# ============================================================\n",
        "for name, paths in datasets.items():\n",
        "    display_detections(paths[\"images\"], paths[\"labels\"], name, n=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKD1VpsSbpt3"
      },
      "source": [
        "The funtion \"draw_yolo_box\", takes input an image path and its corresponding label path. Then, draws the bounding boxes and write the object's label in each box. Finally it displays the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1G3t3yXcVOl"
      },
      "outputs": [],
      "source": [
        "def draw_yolo_bbox(image_path, label_path):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read label file\n",
        "    with open(label_path, 'r') as file:\n",
        "        bboxes = file.readlines()\n",
        "\n",
        "    # Draw each bbox\n",
        "    for bbox in bboxes:\n",
        "        cls, x_center, y_center, w, h = map(float, bbox.strip().split())\n",
        "        x1 = int((x_center - w / 2) * width)\n",
        "        y1 = int((y_center - h / 2) * height)\n",
        "        x2 = int((x_center + w / 2) * width)\n",
        "        y2 = int((y_center + h / 2) * height)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QcDHeIZcbuS"
      },
      "source": [
        "The function \"print_random_images\" takes in input the list of images' paths, a number defining how much images we want to print. So it randomly selects the images to display and calls \"draw_yolo_bbox\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9L8MkvV-EBh"
      },
      "outputs": [],
      "source": [
        "def print_random_imagesFireandSmoke(image_paths, n=30):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCmyf-A-pgZN"
      },
      "outputs": [],
      "source": [
        "def print_random_imagesHomeFire(image_paths, n=30):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-qPj7DNoZTH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6TvL9xMmpcx"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ CLASS LABELS (TEXT-ONLY)\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Serious Smoke\",\n",
        "    2: \"Moderate Smoke\",\n",
        "    3: \"Mild Smoke\",\n",
        "    4: \"Steam / False Alarm\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense / Non-Threat Smoke\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ YOLO TXT ‚Üí BBox\n",
        "# ============================================================\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw / 2), int(yc - bh / 2), int(xc + bw / 2), int(yc + bh / 2))\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Condition Analyzer (Intensity + Visibility)\n",
        "# ============================================================\n",
        "def analyze_conditions(img, bbox, cid):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"L\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    mean_brightness = stat.mean[0] / 255\n",
        "    stddev = stat.stddev[0] / 255\n",
        "\n",
        "    # Visibility\n",
        "    if stddev < 0.25:\n",
        "        visibility = \"Low Visibility\"\n",
        "    elif stddev < 0.45:\n",
        "        visibility = \"Partial Visibility\"\n",
        "    else:\n",
        "        visibility = \"Clear Details\"\n",
        "\n",
        "    # Intensity logic\n",
        "    if cid == 0:  # Fire\n",
        "        if mean_brightness > 0.75 and stddev > 0.5:\n",
        "            label = f\"Fire ‚Äî High Intensity (Flames Visible, {visibility})\"\n",
        "        elif mean_brightness > 0.55:\n",
        "            label = f\"Fire ‚Äî Medium Intensity (Active Burn, {visibility})\"\n",
        "        elif mean_brightness > 0.35:\n",
        "            label = f\"Fire ‚Äî Moderate Intensity ({visibility})\"\n",
        "        else:\n",
        "            label = f\"Fire ‚Äî Low Intensity (Smoldering, {visibility})\"\n",
        "\n",
        "    elif cid in [1, 2, 3, 5]:  # Smoke\n",
        "        if mean_brightness < 0.25:\n",
        "            label = f\"Smoke ‚Äî Dense (Toxic, {visibility})\"\n",
        "        elif mean_brightness < 0.45:\n",
        "            label = f\"Smoke ‚Äî Moderate (Thick, {visibility})\"\n",
        "        else:\n",
        "            label = f\"Smoke ‚Äî Light (Thin Haze, {visibility})\"\n",
        "\n",
        "    elif cid == 4:\n",
        "        label = f\"Steam ‚Äî {'Bright' if mean_brightness > 0.6 else 'Dim'} ({visibility})\"\n",
        "\n",
        "    elif cid == 6:\n",
        "        label = f\"Incense ‚Äî {'Gentle' if mean_brightness > 0.6 else 'Subtle'} ({visibility})\"\n",
        "\n",
        "    else:\n",
        "        label = f\"Unknown ({visibility})\"\n",
        "\n",
        "    return (255, 255, 255), label  # white outline, text-only\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ DRAW YOLO BOUNDING BOXES  ‚úÖ (MISSING FUNCTION ADDED)\n",
        "# ============================================================\n",
        "def draw_yolo_bbox(img_path, label_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    w, h = img.size\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        return img\n",
        "\n",
        "    with open(label_path, \"r\") as f:\n",
        "        lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "    for line in lines:\n",
        "        cid, bbox = yolo_to_bbox(line, w, h)\n",
        "        if not bbox:\n",
        "            continue\n",
        "        color, text = analyze_conditions(img, bbox, cid)\n",
        "        draw.rectangle(bbox, outline=color, width=2)\n",
        "        draw.text((bbox[0] + 3, bbox[1] - 14), text, fill=color)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Non-Repeating Trackers\n",
        "# ============================================================\n",
        "shown_FireSmoke = set()\n",
        "shown_HomeFire_Test = set()\n",
        "shown_Dataset1 = set()\n",
        "shown_Dataset2 = set()\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Visualization Grid\n",
        "# ============================================================\n",
        "def show_random_images(image_dir, label_dir, shown_set, title, n=30):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_paths = [p for p in Path(image_dir).glob(\"*\")\n",
        "                   if p.suffix.lower() in image_exts and (Path(label_dir) / (p.stem + \".txt\")).exists()]\n",
        "    unseen = [p for p in image_paths if p.stem not in shown_set]\n",
        "\n",
        "    if not unseen:\n",
        "        print(f\"‚úÖ All {title} images have been shown. Resetting.\")\n",
        "        shown_set.clear()\n",
        "        unseen = image_paths\n",
        "\n",
        "    selected = random.sample(unseen, min(n, len(unseen)))\n",
        "    shown_set.update(p.stem for p in selected)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected):\n",
        "        label_path = Path(label_dir) / f\"{img_path.stem}.txt\"\n",
        "        img = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(5, 6, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.text(0.5, -0.15, img_path.stem, fontsize=9, ha=\"center\", transform=plt.gca().transAxes)\n",
        "    plt.suptitle(f\"{title} ‚Äî {len(selected)} Images\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ RUN ‚Äî All Datasets (Unified)\n",
        "# ============================================================\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/train2017\",\n",
        "    \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/train\",\n",
        "    shown_FireSmoke, \"üî• Fire + Smoke Dataset\", n=30)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/Home fire dataset/test/images\",\n",
        "    \"/content/drive/MyDrive/Home fire dataset/test/labels\",\n",
        "    shown_HomeFire_Test, \"üè† Home Fire Test Dataset\", n=30)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/dataset 1/images/train\",\n",
        "    \"/content/drive/MyDrive/dataset 1/labels/train\",\n",
        "    shown_Dataset1, \"Dataset 1 ‚Äî Train\", n=30)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/dataset 1/images/val\",\n",
        "    \"/content/drive/MyDrive/dataset 1/labels/val\",\n",
        "    shown_Dataset1, \"Dataset 1 ‚Äî Val\", n=30)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/dataset 2/images/train\",\n",
        "    \"/content/drive/MyDrive/dataset 2/labels/train\",\n",
        "    shown_Dataset2, \"Dataset 2 ‚Äî Train\", n=30)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/dataset 2/images/val\",\n",
        "    \"/content/drive/MyDrive/dataset 2/labels/val\",\n",
        "    shown_Dataset2, \"Dataset 2 ‚Äî Val\", n=30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset label setup annotations"
      ],
      "metadata": {
        "id": "7VFdGX9kqjXU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF77_6vG2AoF"
      },
      "outputs": [],
      "source": [
        "import os, re, random, shutil\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# =========================\n",
        "# Naming helpers\n",
        "# =========================\n",
        "def clean_stem(stem: str) -> str:\n",
        "    s = stem\n",
        "    for suf in (\"_annotation\", \"_annotated\"):\n",
        "        while s.lower().endswith(suf):\n",
        "            s = s[: -len(suf)]\n",
        "    s = re.sub(r\"\\s*\\(\\d+\\)$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def canonicalize_folder(folder: str):\n",
        "    \"\"\"Rename messy *_annotation_annotated... files to clean versions.\"\"\"\n",
        "    root = Path(folder)\n",
        "    for p in root.glob(\"*\"):\n",
        "        if not p.is_file() or p.suffix.lower() not in (\".jpg\", \".jpeg\", \".png\", \".txt\"):\n",
        "            continue\n",
        "        new_name = f\"{clean_stem(p.stem)}{p.suffix.lower()}\"\n",
        "        target = p.with_name(new_name)\n",
        "        if target != p:\n",
        "            try:\n",
        "                if target.exists():\n",
        "                    p.unlink()\n",
        "                else:\n",
        "                    p.rename(target)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è rename skipped for {p.name}: {e}\")\n",
        "\n",
        "# ============================================================\n",
        "# Class Labels & Colors\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Serious Smoke\",\n",
        "    2: \"Moderate Smoke\",\n",
        "    3: \"Mild Smoke\",\n",
        "    4: \"Steam / False Alarm\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense / Non-Threat Smoke\"\n",
        "}\n",
        "base_colors = {\n",
        "    0: (255, 60, 0),\n",
        "    1: (80, 80, 80),\n",
        "    2: (180, 100, 20),\n",
        "    3: (255, 220, 50),\n",
        "    4: (150, 150, 150),\n",
        "    5: (200, 200, 200),\n",
        "    6: (130, 200, 255)\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# YOLO parsing + drawing\n",
        "# ============================================================\n",
        "def _is_float(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def parse_label_file(label_path, w, h, default_conf=1.0):\n",
        "    \"\"\"\n",
        "    Universal YOLO label parser.\n",
        "    Supports:\n",
        "    - Normalized YOLO coords (0‚Äì1)\n",
        "    - Absolute pixel coords\n",
        "    - Comma or space separated\n",
        "    - Optional class names ('Fire', 'Smoke', etc.)\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return items\n",
        "\n",
        "    with open(label_path) as f:\n",
        "        lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "    for ln in lines:\n",
        "        # Replace commas/tabs with spaces\n",
        "        ln = re.sub(r\"[,;\\t]+\", \" \", ln.strip())\n",
        "        parts = ln.split()\n",
        "\n",
        "        # Skip malformed lines\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "\n",
        "        # --- Parse class ID or name ---\n",
        "        first = parts[0]\n",
        "        if _is_float(first):\n",
        "            cid = int(float(first))\n",
        "        else:\n",
        "            # Convert class name ‚Üí ID using your class_labels dict\n",
        "            name_match = first.lower()\n",
        "            cid = next((k for k, v in class_labels.items() if v.lower().startswith(name_match)), 0)\n",
        "\n",
        "        # --- Parse coordinates ---\n",
        "        coords = list(map(float, parts[1:5]))\n",
        "\n",
        "        # Detect normalized vs. pixel coordinates\n",
        "        if all(0 <= c <= 1 for c in coords):\n",
        "            # Normalized YOLO format\n",
        "            xc, yc, bw, bh = coords\n",
        "            x1 = int((xc - bw / 2) * w)\n",
        "            y1 = int((yc - bh / 2) * h)\n",
        "            x2 = int((xc + bw / 2) * w)\n",
        "            y2 = int((yc + bh / 2) * h)\n",
        "        else:\n",
        "            # Pixel coordinates (x1, y1, x2, y2)\n",
        "            x1, y1, x2, y2 = map(int, coords)\n",
        "\n",
        "        # --- Optional confidence score ---\n",
        "        conf = float(parts[5]) if len(parts) > 5 and _is_float(parts[5]) else default_conf\n",
        "\n",
        "        # Clamp to image bounds\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
        "\n",
        "        items.append((cid, (x1, y1, x2, y2), conf))\n",
        "\n",
        "    return items\n",
        "\n",
        "\n",
        "\n",
        "def draw_items_on_image(img_path, items):\n",
        "    \"\"\"Draw bounding boxes and labels on an image.\"\"\"\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    d = ImageDraw.Draw(img)\n",
        "    for cid, (x1, y1, x2, y2), conf in items:\n",
        "        color = base_colors.get(cid, (0, 255, 0))\n",
        "        d.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
        "        label = f\"{class_labels.get(cid, cid)} {conf:.2f}\"\n",
        "        tw, th = len(label) * 6, 14\n",
        "        d.rectangle([x1, y1 - th, x1 + tw + 4, y1], fill=color)\n",
        "        d.text((x1 + 2, y1 - th + 1), label, fill=(255, 255, 255))\n",
        "    return img\n",
        "\n",
        "# ============================================================\n",
        "# Label setup\n",
        "# ============================================================\n",
        "def ensure_label_files_exist(image_dir, label_dir):\n",
        "    \"\"\"Create empty .txt label files for any images missing them.\"\"\"\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    Path(label_dir).mkdir(parents=True, exist_ok=True)\n",
        "    created = 0\n",
        "    for img_path in Path(image_dir).glob(\"*\"):\n",
        "        if img_path.suffix.lower() not in image_exts:\n",
        "            continue\n",
        "        lbl_path = Path(label_dir) / f\"{clean_stem(img_path.stem)}.txt\"\n",
        "        if not lbl_path.exists():\n",
        "            lbl_path.write_text(\"\")  # empty placeholder\n",
        "            created += 1\n",
        "    print(f\"‚úÖ Ensured label files for {image_dir} (created {created} new empty labels).\")\n",
        "\n",
        "# ============================================================\n",
        "# Annotation\n",
        "# ============================================================\n",
        "def annotate_dataset(image_dir, label_dir, output_dir, title):\n",
        "    canonicalize_folder(image_dir)\n",
        "    canonicalize_folder(label_dir)\n",
        "    #ensure_label_files_exist(image_dir, label_dir)\n",
        "\n",
        "    # define /images and /labels subfolders under output_dir\n",
        "    output_dir = Path(output_dir)\n",
        "    output_images = output_dir / \"images\"\n",
        "    output_labels = output_dir / \"labels\"\n",
        "    output_images.mkdir(parents=True, exist_ok=True)\n",
        "    output_labels.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    imgs = [p for p in Path(image_dir).glob(\"*\") if p.suffix.lower() in exts]\n",
        "    if not imgs:\n",
        "        print(f\"‚ö†Ô∏è No images found in {image_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüì∏ Annotating {len(imgs)} from {title}\")\n",
        "    saved, blank = 0, 0\n",
        "\n",
        "    for img in imgs:\n",
        "        stem = clean_stem(img.stem)\n",
        "        candidates = [\n",
        "            Path(label_dir) / f\"{stem}.txt\",\n",
        "            Path(label_dir) / f\"{stem}_annotation.txt\"\n",
        "        ]\n",
        "        lbl = next((p for p in candidates if p.exists() and p.stat().st_size > 0), None)  # ‚úÖ only non-empty\n",
        "\n",
        "        if not lbl:\n",
        "            blank += 1\n",
        "            continue\n",
        "\n",
        "        with Image.open(img) as im:\n",
        "            w, h = im.size\n",
        "            items = parse_label_file(lbl, w, h)\n",
        "\n",
        "            if not items:\n",
        "                blank += 1\n",
        "                im.convert(\"RGB\").save(output_images / f\"{stem}_annotation.jpg\")\n",
        "                continue\n",
        "\n",
        "            # ‚úÖ Save annotated image in /images/\n",
        "            out_img = draw_items_on_image(img, items)\n",
        "            out_img.save(output_images / f\"{stem}_annotation.jpg\")\n",
        "\n",
        "            # ‚úÖ Copy label to /labels/ (preserves original YOLO .txt)\n",
        "            shutil.copy(lbl, output_labels / lbl.name)\n",
        "\n",
        "            saved += 1\n",
        "\n",
        "    print(f\"‚úÖ Saved {saved} annotated | ‚ö™ {blank} empty | üìÅ {output_dir}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Dataset paths\n",
        "# ============================================================\n",
        "DATASETS = {\n",
        "    \"üè† Home Fire (Original)\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Home fire dataset/test/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Home fire dataset/test/labels\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/\"\n",
        "    },\n",
        "    \"üî• Fire + Smoke\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\"\n",
        "    },\n",
        "    \"Dataset 1 Train\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 1/images/train\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 1/labels/train\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/dataset1_output/train\"\n",
        "    },\n",
        "    \"Dataset 2 Train\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 2/images/train\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 2/labels/train\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/dataset2_output/train\"\n",
        "    },\n",
        "    \"Dataset 1 Val\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 1/images/val\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 1/labels/val\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/dataset1_output/val\"\n",
        "    },\n",
        "    \"Dataset 2 Val\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 2/images/val\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 2/labels/val\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/dataset2_output/val\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# üöÄ Run annotation pipeline\n",
        "# ============================================================\n",
        "for name, cfg in DATASETS.items():\n",
        "    annotate_dataset(cfg[\"images\"], cfg[\"labels\"], cfg[\"output\"], name)\n",
        "\n",
        "print(\"\\nüéØ All datasets processed ‚Äî every valid label now visualized.\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "from pathlib import Path\n",
        "\n",
        "src = Path(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\")\n",
        "dst = src / \"images\"\n",
        "\n",
        "# create destination folder if missing\n",
        "dst.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "moved = 0\n",
        "for file in src.glob(\"*_annotation.jpg\"):\n",
        "    shutil.move(str(file), dst / file.name)\n",
        "    moved += 1\n",
        "\n",
        "print(f\"‚úÖ Moved {moved} annotated preview images to {dst}\")\n"
      ],
      "metadata": {
        "id": "H2wzJuFBQNPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "from pathlib import Path\n",
        "\n",
        "src = Path(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\")\n",
        "dst = src / \"labels\"\n",
        "\n",
        "# create destination folder if missing\n",
        "dst.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "moved = 0\n",
        "for file in src.glob(\"*.txt\"):\n",
        "    shutil.move(str(file), dst / file.name)\n",
        "    moved += 1\n",
        "\n",
        "print(f\"‚úÖ Moved {moved} YOLO label (.txt) files to {dst}\")\n"
      ],
      "metadata": {
        "id": "Vaw6xhUOSb5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqydWhGISWVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "img_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/images\")\n",
        "lbl_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/labels\")\n",
        "\n",
        "image_files = sorted([p.name for p in img_dir.glob(\"*.jpg\")])\n",
        "label_files = sorted([p.name for p in lbl_dir.glob(\"*.txt\")])\n",
        "\n",
        "print(f\"üñºÔ∏è {len(image_files)} images | üóíÔ∏è {len(label_files)} labels\\n\")\n",
        "\n",
        "for i, img in enumerate(image_files[:75]):\n",
        "    stem = Path(img).stem\n",
        "    has_label = any(f.startswith(stem) for f in label_files)\n",
        "    print(f\"{i+1:02d}. {img:<25}  -->  {'‚úÖ label found' if has_label else '‚ö†Ô∏è missing label'}\")\n"
      ],
      "metadata": {
        "id": "bT8HnKRUETsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path, os\n",
        "lbl_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/labels\")\n",
        "\n",
        "empty = [p for p in lbl_dir.glob(\"*.txt\") if p.stat().st_size == 0]\n",
        "print(f\"üî• Fire + Smoke: {len(empty)} empty labels\")\n"
      ],
      "metadata": {
        "id": "mMNP2yWZsA5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnlxY_VymiZQ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def remove_empty_or_non_numeric_txt(dirpath):\n",
        "    p = Path(dirpath)\n",
        "    removed = 0\n",
        "    for f in p.glob(\"*.txt\"):\n",
        "        txt = f.read_text().strip()\n",
        "        has_numeric = any(ln and ln[0].isdigit() for ln in txt.splitlines())\n",
        "        if (not txt) or (not has_numeric):\n",
        "            f.unlink()\n",
        "            removed += 1\n",
        "    print(f\"üßπ Removed {removed} empty/invalid txt files from {dirpath}\")\n",
        "\n",
        "remove_empty_or_non_numeric_txt(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\")\n",
        "remove_empty_or_non_numeric_txt(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4AN1GG7FfoF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "label_dir = \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/labels\"\n",
        "print(\"Number of TXT label files:\", sum(1 for f in os.listdir(label_dir) if f.endswith(\".txt\")))\n",
        "print(\"Sample label filenames:\")\n",
        "for f in sorted(os.listdir(label_dir))[:10]:\n",
        "    print(\" -\", f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5KCOOvedKoT"
      },
      "source": [
        "Now, finally calling the function to display 30 images randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ox7JnU9qj1o"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "ANNOTATED_SUFFIXES = (\"_annotated\", \"_annotation\")\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "def display_all_annotated_images(title, root_dir, per_page=30, cols=6, recursive=True):\n",
        "    \"\"\"\n",
        "    Show ALL annotated images in `root_dir`, paged `per_page` at a time.\n",
        "    Looks for files whose stem ends with _annotated or _annotation.\n",
        "    \"\"\"\n",
        "    root = Path(root_dir)\n",
        "    it = root.rglob(\"*\") if recursive else root.glob(\"*\")\n",
        "    imgs = sorted(\n",
        "        [p for p in it if p.suffix.lower() in IMG_EXTS\n",
        "         and p.stem.endswith(ANNOTATED_SUFFIXES)]\n",
        "    )\n",
        "\n",
        "    if not imgs:\n",
        "        print(f\"‚ö†Ô∏è No annotated images found in {root_dir} (expected *{ANNOTATED_SUFFIXES}.[jpg|png]).\")\n",
        "        return\n",
        "\n",
        "    print(f\"üì∑ {title}: showing {len(imgs)} annotated images from {root_dir}\")\n",
        "\n",
        "    for i in range(0, len(imgs), per_page):\n",
        "        batch = imgs[i:i+per_page]\n",
        "        rows = math.ceil(len(batch) / cols)\n",
        "        plt.figure(figsize=(3.2*cols, 3.2*rows))\n",
        "        for j, p in enumerate(batch, 1):\n",
        "            plt.subplot(rows, cols, j)\n",
        "            plt.imshow(Image.open(p))\n",
        "            plt.title(p.name, fontsize=8)\n",
        "            plt.axis(\"off\")\n",
        "        plt.suptitle(f\"{title} ‚Äî {i+1}‚Äì{i+len(batch)} of {len(imgs)}\", fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSceYTRWoCO4"
      },
      "outputs": [],
      "source": [
        "display_all_annotated_images(\"üî• Fire + Smoke (annotated)\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\")\n",
        "\n",
        "display_all_annotated_images(\"üè† Home Fire Test (annotated)\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2XL5eBUGs61"
      },
      "source": [
        "## Dataset Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VphL1Y3eDBT"
      },
      "source": [
        "Interestingly, we found out that this dataset is not clean. i.e. labels of some of the images are missing and there are extra labels. So, we need to find out the missing labels files and remove that from the labels folder. Also, we need to find out missing images, which we also need to remove from the images folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp-MBacMgDlx"
      },
      "outputs": [],
      "source": [
        "#we already have a list of images' paths and labels' path, stored in variables : image_paths and label_paths\n",
        "print(image_paths)\n",
        "print(label_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URBrBcojgRPf"
      },
      "source": [
        "Now, we make a list of only the names of images' files and labels' files.\n",
        "\n",
        "e.g.  only  000000000531 without the extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5E_Pw6dgOMO"
      },
      "outputs": [],
      "source": [
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "\n",
        "print(image_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJKT0PFHhk5Y"
      },
      "outputs": [],
      "source": [
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd53OlLafsVP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Corrected removal loop\n",
        "for file in extra_images:\n",
        "    # Get only the filename without any folder\n",
        "    filename = os.path.basename(file)\n",
        "    image_path = os.path.join(dataset_path, \"images\", filename)\n",
        "    if os.path.exists(image_path):\n",
        "        os.remove(image_path)\n",
        "        print(f\"Removed: {image_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {image_path}\")\n",
        "\n",
        "for file in extra_labels:\n",
        "    filename = os.path.basename(file)\n",
        "    label_path = os.path.join(dataset_path, \"labels\", filename)\n",
        "    if os.path.exists(label_path):\n",
        "        os.remove(label_path)\n",
        "        print(f\"Removed: {label_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {label_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFC1RmdVhter"
      },
      "source": [
        "Now removing them from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akqYMfZJjBop"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfqxKksXihaM"
      },
      "source": [
        "Check again if it worked:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cluJu0Hqioo7"
      },
      "outputs": [],
      "source": [
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a29fd86c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7LJCLrTI_69"
      },
      "source": [
        "There are none! great!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnmYJdry2L5h"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install numpy torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbsPYfjcFigH"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üî• YOLOv8 Fire/Smoke Trainer + Annotator (v8.3 Structured)\n",
        "# ============================================================\n",
        "\n",
        "import os, sys, yaml, glob, subprocess, importlib, torch, multiprocessing, shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Utilities\n",
        "# ============================================================\n",
        "def force_numpy():\n",
        "    \"\"\"Ensure NumPy works even in limited environments.\"\"\"\n",
        "    try:\n",
        "        import numpy as np\n",
        "        _ = np.zeros((1, 1))\n",
        "        print(\"‚úÖ NumPy working fine.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è NumPy issue: {e} ‚Äî reinstalling‚Ä¶\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"numpy\"])\n",
        "        import numpy as np\n",
        "    globals()[\"np\"] = importlib.import_module(\"numpy\")\n",
        "    return globals()[\"np\"]\n",
        "\n",
        "np = force_numpy()\n",
        "\n",
        "def ensure_dir(path: str):\n",
        "    \"\"\"Create folder if it doesn't exist.\"\"\"\n",
        "    Path(path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Dataset Structure\n",
        "# ============================================================\n",
        "DATASETS = {\n",
        "    \"TRAIN\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 1/images/train\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 1/labels/train\"\n",
        "    },\n",
        "    \"VAL\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 2/images/val\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 2/labels/val\"\n",
        "    },\n",
        "    \"HOME_FIRE\": {\n",
        "        \"images\": \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/labels\"\n",
        "    },\n",
        "    \"FIRE_SMOKE\": {\n",
        "        \"images\": \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/labels\"\n",
        "    }\n",
        "}\n",
        "\n",
        "YAML_PATH = \"/content/drive/MyDrive/fire_smoke/data.yaml\"\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Dataset Validation\n",
        "# ============================================================\n",
        "def check_dataset(img_dir, lbl_dir):\n",
        "    img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    imgs = [f for ext in img_exts for f in glob.glob(os.path.join(img_dir, f\"*{ext}\"))]\n",
        "    lbls = glob.glob(os.path.join(lbl_dir, \"*.txt\"))\n",
        "    print(f\"üìÅ {Path(img_dir).name}: {len(imgs)} images | {len(lbls)} labels\")\n",
        "    return imgs, lbls\n",
        "\n",
        "for name, cfg in DATASETS.items():\n",
        "    check_dataset(cfg[\"images\"], cfg[\"labels\"])\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ YAML File (Dataset 1 & 2 ‚Äî Correct YOLO Structure)\n",
        "# ============================================================\n",
        "os.makedirs(os.path.dirname(yaml_path), exist_ok=True)\n",
        "\n",
        "# ‚úÖ Always point \"train\" and \"val\" to the parent directory that directly\n",
        "#    contains both /images and /labels subfolders.\n",
        "yaml_config = {\n",
        "    \"train\": \"/content/drive/MyDrive/dataset 1\",  # Dataset 1 root folder\n",
        "    \"val\":   \"/content/drive/MyDrive/dataset 2\",  # Dataset 2 root folder\n",
        "    \"nc\": 7,\n",
        "    \"names\": {\n",
        "        0: \"Fire\",\n",
        "        1: \"Serious Smoke\",\n",
        "        2: \"Moderate Smoke\",\n",
        "        3: \"Mild Smoke\",\n",
        "        4: \"Steam / False Alarm\",\n",
        "        5: \"Non-Fire Smoke\",\n",
        "        6: \"Incense / Non-Threat Smoke\"\n",
        "    }\n",
        "}\n",
        "\n",
        "ensure_dir(os.path.dirname(YAML_PATH))\n",
        "with open(YAML_PATH, \"w\") as f:\n",
        "    yaml.safe_dump(yaml_config, f, sort_keys=False)\n",
        "print(f\"‚úÖ Dataset YAML created ‚Üí {YAML_PATH}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ System Info\n",
        "# ============================================================\n",
        "import ultralytics\n",
        "print(f\"\\nüîé YOLOv8 version: {ultralytics.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ CUDA: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Running on CPU only.\")\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Training\n",
        "# ============================================================\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "train_args = dict(\n",
        "    data=YAML_PATH,\n",
        "    epochs=50,\n",
        "    imgsz=416,\n",
        "    batch=4,\n",
        "    workers=0,\n",
        "    patience=5,\n",
        "    lr0=0.005,\n",
        "    weight_decay=0.0005,\n",
        "    cache=False,\n",
        "    exist_ok=True,\n",
        "    name=\"fire_smoke_yolov8n_cpu_v83\"\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Starting YOLOv8 training (Dataset 1 ‚Üí Train, Dataset 2 ‚Üí Val)‚Ä¶\")\n",
        "results = model.train(**train_args)\n",
        "print(\"\\n‚úÖ Training completed successfully.\")\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Unified Prediction & Output Management\n",
        "# ============================================================\n",
        "def predict_and_save(model, img_dir, out_root, conf=0.15):\n",
        "    \"\"\"Run predictions on a folder and save annotated outputs and labels.\"\"\"\n",
        "    print(f\"\\nüé® Predicting on ‚Üí {img_dir}\")\n",
        "    img_dir = Path(img_dir)\n",
        "    out_root = Path(out_root)\n",
        "    out_images = out_root / \"images\"\n",
        "    out_labels = out_root / \"labels\"\n",
        "    ensure_dir(out_images)\n",
        "    ensure_dir(out_labels)\n",
        "\n",
        "    for img_path in img_dir.glob(\"*.jpg\"):\n",
        "        results = model.predict(source=str(img_path), save=True, save_txt=True, conf=conf)\n",
        "        # Move annotated image\n",
        "        ann_src = Path(results[0].save_dir) / img_path.name\n",
        "        ann_dst = out_images / f\"{img_path.stem}_annotated.jpg\"\n",
        "        if ann_src.exists():\n",
        "            shutil.move(str(ann_src), ann_dst)\n",
        "        # Move label txt if generated\n",
        "        pred_txt = Path(results[0].save_dir) / \"labels\" / f\"{img_path.stem}.txt\"\n",
        "        if pred_txt.exists():\n",
        "            shutil.move(str(pred_txt), out_labels / f\"{img_path.stem}.txt\")\n",
        "\n",
        "    print(f\"‚úÖ Saved annotated outputs to ‚Üí {out_root}\")\n",
        "\n",
        "# ============================================================\n",
        "# 8Ô∏è‚É£ Predict on All Sets\n",
        "# ============================================================\n",
        "OUTPUT_BASE = \"/content/drive/MyDrive/fire_smoke_previews/predictions_v83\"\n",
        "ensure_dir(OUTPUT_BASE)\n",
        "\n",
        "for name, cfg in DATASETS.items():\n",
        "    out_root = Path(OUTPUT_BASE) / name.lower()\n",
        "    predict_and_save(model, cfg[\"images\"], out_root)\n",
        "\n",
        "print(\"\\n‚úÖ Predictions completed for all datasets.\")\n",
        "\n",
        "# ============================================================\n",
        "# 9Ô∏è‚É£ Visual Preview\n",
        "# ============================================================\n",
        "preview_dirs = [\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/predictions_v83/train/images\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/predictions_v83/val/images\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/predictions_v83/home_fire/images\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/predictions_v83/fire_smoke/images\",\n",
        "]\n",
        "\n",
        "preview_samples = []\n",
        "for d in preview_dirs:\n",
        "    preview_samples += glob.glob(os.path.join(d, \"*_annotated.jpg\"))[:2]\n",
        "\n",
        "if preview_samples:\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    for i, path in enumerate(preview_samples):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(Path(path).parent.parent.name + \" ‚Äì \" + Path(path).name)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No annotated preview images found.\")\n",
        "\n",
        "print(f\"\"\"\n",
        "üéâ All annotated predictions saved under:\n",
        "üìÅ /content/drive/MyDrive/fire_smoke_previews/predictions_v83/\n",
        "‚îú‚îÄ‚îÄ train/\n",
        "‚îú‚îÄ‚îÄ val/\n",
        "‚îú‚îÄ‚îÄ home_fire/\n",
        "‚îî‚îÄ‚îÄ fire_smoke/\n",
        "\"\"\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QA7O9_88drP"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üé® YOLOv8 Fire/Smoke Visualization Matrix (Post-Training v8.3)\n",
        "# ============================================================\n",
        "\n",
        "import os, glob, shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Model and Dataset Paths\n",
        "# ============================================================\n",
        "MODEL_PATH = \"/content/runs/detect/fire_smoke_yolov8n_cpu_v83/weights/best.pt\"  # ‚¨ÖÔ∏è update if saved elsewhere\n",
        "OUTPUT_BASE = \"/content/drive/MyDrive/fire_smoke_previews/predictions_matrix_v83\"\n",
        "\n",
        "DATASETS = {\n",
        "    \"TRAIN\": \"/content/drive/MyDrive/dataset 1/images/train\",\n",
        "    \"VAL\": \"/content/drive/MyDrive/dataset 2/images/val\",\n",
        "    \"HOME_FIRE\": \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/images\",\n",
        "    \"FIRE_SMOKE\": \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/images\"\n",
        "}\n",
        "\n",
        "def ensure_dir(p): Path(p).mkdir(parents=True, exist_ok=True)\n",
        "ensure_dir(OUTPUT_BASE)\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Load Model\n",
        "# ============================================================\n",
        "model = YOLO(MODEL_PATH)\n",
        "print(f\"‚úÖ Loaded trained model ‚Üí {MODEL_PATH}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Run Predictions & Save Outputs\n",
        "# ============================================================\n",
        "def predict_and_save(model, img_dir, out_root, conf=0.25):\n",
        "    \"\"\"Predict on dataset, save annotated JPGs and YOLO TXT labels.\"\"\"\n",
        "    img_dir, out_root = Path(img_dir), Path(out_root)\n",
        "    out_images, out_labels = out_root / \"images\", out_root / \"labels\"\n",
        "    ensure_dir(out_images); ensure_dir(out_labels)\n",
        "\n",
        "    print(f\"\\nüéØ Predicting on ‚Üí {img_dir.name}\")\n",
        "    for img_path in img_dir.glob(\"*.jpg\"):\n",
        "        results = model.predict(source=str(img_path), save=True, save_txt=True, conf=conf)\n",
        "        ann_src = Path(results[0].save_dir) / img_path.name\n",
        "        ann_dst = out_images / f\"{img_path.stem}_annotated.jpg\"\n",
        "        if ann_src.exists():\n",
        "            shutil.move(str(ann_src), ann_dst)\n",
        "        pred_txt = Path(results[0].save_dir) / \"labels\" / f\"{img_path.stem}.txt\"\n",
        "        if pred_txt.exists():\n",
        "            shutil.move(str(pred_txt), out_labels / f\"{img_path.stem}.txt\")\n",
        "    print(f\"‚úÖ Annotated predictions saved in: {out_root}\")\n",
        "\n",
        "for name, img_dir in DATASETS.items():\n",
        "    predict_and_save(model, img_dir, Path(OUTPUT_BASE) / name.lower())\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Visual Preview Inline\n",
        "# ============================================================\n",
        "preview_dirs = [f\"{OUTPUT_BASE}/{n.lower()}/images\" for n in DATASETS.keys()]\n",
        "samples = []\n",
        "for d in preview_dirs:\n",
        "    samples += glob.glob(os.path.join(d, \"*_annotated.jpg\"))[:2]\n",
        "\n",
        "if samples:\n",
        "    plt.figure(figsize=(16,10))\n",
        "    for i, path in enumerate(samples):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(2,4,i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(Path(path).parent.parent.name + \" ‚Äì \" + Path(path).name)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No annotated images found for preview.\")\n",
        "\n",
        "print(f\"\"\"\n",
        "üéâ Visualization complete!\n",
        "üìÅ All predictions saved under:\n",
        "{OUTPUT_BASE}/\n",
        "‚îú‚îÄ‚îÄ train/\n",
        "‚îú‚îÄ‚îÄ val/\n",
        "‚îú‚îÄ‚îÄ home_fire/\n",
        "‚îî‚îÄ‚îÄ fire_smoke/\n",
        "\"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 9Ô∏è‚É£ Evaluate Model and Visualize Confusion Matrix (v8.3)\n",
        "# ============================================================\n",
        "\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"\\nüìä Evaluating trained model and generating confusion matrix...\")\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Load Best Model\n",
        "# ============================================================\n",
        "MODEL_PATH = \"/content/runs/detect/fire_smoke_yolov8n_cpu_v83/weights/best.pt\"  # ‚¨ÖÔ∏è Update path if needed\n",
        "assert os.path.exists(MODEL_PATH), f\"‚ùå Model not found at {MODEL_PATH}\"\n",
        "model = YOLO(MODEL_PATH)\n",
        "print(f\"‚úÖ Loaded trained model ‚Üí {MODEL_PATH}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Validate Model (Generate Metrics + Confusion Matrix)\n",
        "# ============================================================\n",
        "# Runs YOLOv8 validation using the same YAML as training\n",
        "results = model.val(data=\"/content/drive/MyDrive/fire_smoke/data.yaml\", conf=0.25, imgsz=416)\n",
        "print(\"\\n‚úÖ Validation complete ‚Äî extracting metrics...\")\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Plot Confusion Matrix\n",
        "# ============================================================\n",
        "try:\n",
        "    cm = results.confusion_matrix.matrix  # (num_classes x num_classes) numpy array\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, cmap=\"Blues\")\n",
        "    plt.title(\"üî• Fire & Smoke Detection ‚Äî Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.colorbar(label=\"Count\")\n",
        "    plt.xticks(ticks=np.arange(len(results.names)), labels=list(results.names.values()), rotation=45)\n",
        "    plt.yticks(ticks=np.arange(len(results.names)), labels=list(results.names.values()))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Could not plot confusion matrix:\", e)\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Print Summary Metrics\n",
        "# ============================================================\n",
        "print(\"\\nüßÆ Evaluation Summary:\")\n",
        "try:\n",
        "    p = float(np.mean(results.box.p)) if hasattr(results.box, \"p\") else results.metrics[\"precision\"]\n",
        "    r = float(np.mean(results.box.r)) if hasattr(results.box, \"r\") else results.metrics[\"recall\"]\n",
        "    map50 = float(np.mean(results.box.map50)) if hasattr(results.box, \"map50\") else results.metrics[\"map50\"]\n",
        "    map95 = float(np.mean(results.box.map)) if hasattr(results.box, \"map\") else results.metrics[\"map\"]\n",
        "    print(f\"Precision: {p:.3f}\")\n",
        "    print(f\"Recall:    {r:.3f}\")\n",
        "    print(f\"mAP50:     {map50:.3f}\")\n",
        "    print(f\"mAP50-95:  {map95:.3f}\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Could not summarize metrics:\", e)\n",
        "    print(results)\n"
      ],
      "metadata": {
        "id": "SD9IyvahZnrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üé® YOLOv8 Fire/Smoke Visualization Matrix (Display Annotated Predictions)\n",
        "# ============================================================\n",
        "\n",
        "import os, glob\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Paths and Configuration\n",
        "# ============================================================\n",
        "OUTPUT_BASE = \"/content/drive/MyDrive/fire_smoke_previews/predictions_matrix_v83\"  # change if you used a different output name\n",
        "\n",
        "# Define datasets to preview\n",
        "DATASETS = [\"train\", \"val\", \"home_fire\", \"fire_smoke\"]\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Collect Annotated Images\n",
        "# ============================================================\n",
        "preview_dirs = [f\"{OUTPUT_BASE}/{ds}/images\" for ds in DATASETS]\n",
        "preview_samples = []\n",
        "\n",
        "for d in preview_dirs:\n",
        "    imgs = glob.glob(os.path.join(d, \"*_annotated.jpg\"))\n",
        "    preview_samples += imgs[:4]  # take up to 4 per dataset\n",
        "\n",
        "print(f\"‚úÖ Found {len(preview_samples)} annotated images to display.\")\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Display Annotated Predictions Inline\n",
        "# ============================================================\n",
        "if preview_samples:\n",
        "    cols = 4\n",
        "    rows = (len(preview_samples) + cols - 1) // cols\n",
        "    plt.figure(figsize=(16, rows * 4))\n",
        "\n",
        "    for i, path in enumerate(preview_samples):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        ds_name = Path(path).parent.parent.name\n",
        "        plt.title(f\"{ds_name.upper()} ‚Äì {Path(path).name}\", fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No annotated images found in prediction folders. Check your OUTPUT_BASE path.\")\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Summary\n",
        "# ============================================================\n",
        "print(f\"\"\"\n",
        "üéâ Visualization Complete!\n",
        "üìÅ Annotated predictions displayed from:\n",
        "{OUTPUT_BASE}/\n",
        "‚îú‚îÄ‚îÄ train/images/\n",
        "‚îú‚îÄ‚îÄ val/images/\n",
        "‚îú‚îÄ‚îÄ home_fire/images/\n",
        "‚îî‚îÄ‚îÄ fire_smoke/images/\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "q8_8HxScYczD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9OYGZJGuxxR"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "train_files = glob.glob(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/*_annotated*.jpg\")\n",
        "val_files = glob.glob(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/*_annotated*.jpg\")\n",
        "\n",
        "print(f\"TRAIN annotated images saved: {len(train_files)}\")\n",
        "print(f\"VAL annotated images saved:   {len(val_files)}\")\n",
        "print(f\"Total annotated files:         {len(train_files) + len(val_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MXAB20pxa-9"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 9Ô∏è‚É£ Evaluate model and visualize confusion matrix\n",
        "# ============================================================\n",
        "from ultralytics.utils import ops\n",
        "from ultralytics.utils.plotting import plot_results\n",
        "from ultralytics.utils.metrics import ConfusionMatrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nüìä Evaluating trained model and generating confusion matrix...\")\n",
        "\n",
        "# Load best model from training\n",
        "model_path = \"/content/runs/detect/fire_smoke_yolov8n_cpu_stable_v74/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Run validation to get metrics and confusion matrix data\n",
        "metrics = model.val(conf=0.25, imgsz=416)\n",
        "\n",
        "# Compute and display confusion matrix\n",
        "cm = metrics.confusion_matrix.matrix  # numpy array (num_classes x num_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.title(\"üî• Fire & Smoke Detection Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Print summarized results\n",
        "print(\"\\nüßÆ Evaluation Summary:\")\n",
        "try:\n",
        "    p = float(np.mean(metrics.box.p))\n",
        "    r = float(np.mean(metrics.box.r))\n",
        "    map50 = float(np.mean(metrics.box.map50))\n",
        "    map95 = float(np.mean(metrics.box.map))\n",
        "    print(f\"Precision: {p:.3f}\")\n",
        "    print(f\"Recall:    {r:.3f}\")\n",
        "    print(f\"mAP50:     {map50:.3f}\")\n",
        "    print(f\"mAP50-95:  {map95:.3f}\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Could not summarize metrics:\", e)\n",
        "    print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3HsPZp0F5Wz"
      },
      "outputs": [],
      "source": [
        "# ------------------------------ imports ------------------------------\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nüìä Evaluating trained model and generating confusion matrix...\")\n",
        "\n",
        "# ------------------------------ load & validate ------------------------------\n",
        "model_path = \"/content/runs/detect/fire_smoke_yolov8n_cpu_stable_v74/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# run validation\n",
        "res = model.val(conf=0.25, imgsz=416, verbose=False)   # uses your data.yaml 'val'\n",
        "\n",
        "# ------------------------------ confusion matrix ------------------------------\n",
        "cm_obj = getattr(res, \"confusion_matrix\", None)\n",
        "if cm_obj is None or getattr(cm_obj, \"matrix\", None) is None:\n",
        "    raise RuntimeError(\"No confusion matrix found in results. Check that your val set has valid labels.\")\n",
        "\n",
        "cm = cm_obj.matrix.astype(float)\n",
        "names = getattr(model, \"names\", None)\n",
        "if names is None and hasattr(model, \"model\"):\n",
        "    names = getattr(model.model, \"names\", {})\n",
        "names = names or {}\n",
        "n = cm.shape[0]\n",
        "tick_labels = [names.get(i, str(i)) for i in range(n)]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 7))\n",
        "im = ax.imshow(cm, cmap=\"Blues\", interpolation=\"nearest\")\n",
        "\n",
        "# Add colorbar\n",
        "cbar = ax.figure.colorbar(im, ax=ax)\n",
        "cbar.ax.set_ylabel(\"Count\", rotation=-90, va=\"bottom\")\n",
        "\n",
        "# Add tick labels\n",
        "ax.set_xticks(range(n))\n",
        "ax.set_yticks(range(n))\n",
        "ax.set_xticklabels(tick_labels, rotation=45, ha=\"right\")\n",
        "ax.set_yticklabels(tick_labels)\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"True Label\")\n",
        "ax.set_title(\"üî• Fire & Smoke Detection Confusion Matrix (Raw Counts)\")\n",
        "\n",
        "# Add numbers inside each square\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        val = cm[i, j]\n",
        "        ax.text(j, i, f\"{int(val)}\", ha=\"center\", va=\"center\",\n",
        "                color=\"black\" if val < cm.max() / 2 else \"white\", fontsize=8)\n",
        "\n",
        "plt.figtext(0.5, -0.05, \"RAVDESS\", ha=\"center\", fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------ metrics (version-proof) ------------------------------\n",
        "d = getattr(res, \"results_dict\", {})  # new API\n",
        "def pick(keys, default=np.nan):\n",
        "    for k in keys:\n",
        "        if k in d:\n",
        "            return float(d[k])\n",
        "    return default\n",
        "\n",
        "p     = pick([\"metrics/precision(B)\", \"metrics/precision\"])\n",
        "r     = pick([\"metrics/recall(B)\", \"metrics/recall\"])\n",
        "map50 = pick([\"metrics/mAP50(B)\", \"metrics/mAP50\"])\n",
        "map95 = pick([\"metrics/mAP50-95(B)\", \"metrics/mAP50-95\"])\n",
        "\n",
        "# fallback for older API\n",
        "if np.isnan(p) and hasattr(res, \"box\"):\n",
        "    p     = float(np.mean(res.box.p))\n",
        "    r     = float(np.mean(res.box.r))\n",
        "    map50 = float(np.mean(res.box.map50))\n",
        "    map95 = float(np.mean(res.box.map))\n",
        "\n",
        "print(\"\\nüßÆ Evaluation Summary:\")\n",
        "print(f\"Precision: {p:.3f}\")\n",
        "print(f\"Recall:    {r:.3f}\")\n",
        "print(f\"mAP50:     {map50:.3f}\")\n",
        "print(f\"mAP50-95:  {map95:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK-NzLfgJ6sP"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "label_dir = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/train2017\"\n",
        "counts = Counter()\n",
        "\n",
        "for file in os.listdir(label_dir):\n",
        "    if file.endswith(\".txt\"):\n",
        "        for line in open(os.path.join(label_dir, file)):\n",
        "            if line.strip():\n",
        "                cid = int(line.split()[0])\n",
        "                counts[cid] += 1\n",
        "\n",
        "print(\"Class distribution:\", counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWI0I6jGJ0lL"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(9,8))\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", cmap=\"Blues\", xticklabels=tick_labels, yticklabels=tick_labels)\n",
        "plt.title(\"üî• Fire & Smoke Detection Confusion Matrix (Raw Counts)\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.figtext(0.5, -0.05, \"RAVDESS\", ha=\"center\", fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzzimYSBF9vG"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "lbl_dir = Path(\"/path/to/your/labels/val\")  # point to your val labels folder\n",
        "counts = {}\n",
        "for f in lbl_dir.rglob(\"*.txt\"):\n",
        "    for ln in f.read_text().splitlines():\n",
        "        if ln.strip() and ln.strip()[0].isdigit():\n",
        "            c = int(float(ln.split()[0]))\n",
        "            counts[c] = counts.get(c, 0) + 1\n",
        "print(\"Val label counts per class-id:\", counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8TXGGeQxdRD"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìà Plotting training and validation curves...\")\n",
        "plot_results(\"/content/runs/detect/fire_smoke_yolov8n_cpu_stable_v74/results.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vb_Mvp7xeiY"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üîç Test on New Images/Videos\n",
        "# ============================================================\n",
        "test_source = \"/content/drive/MyDrive/fire_smoke_previews/new_test_data\"  # üîÅ your folder\n",
        "os.makedirs(test_source, exist_ok=True)\n",
        "\n",
        "print(\"\\nüé• Testing model on new data...\")\n",
        "results = model.predict(source=test_source, conf=0.3, save=True, save_txt=True)\n",
        "\n",
        "print(\"‚úÖ Predictions complete. Check annotated results in /runs/detect/predict/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-oVT-0tbRCf"
      },
      "source": [
        "after training, all of the precision confusion matrix and everything, check to see if results are satisfactory"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
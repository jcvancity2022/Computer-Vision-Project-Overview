{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcvancity2022/Computer-Vision-Project-Overview/blob/main/20251102DONE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvIx0KGWlPtp"
      },
      "source": [
        "<center><h1> <b>Image Dataset Analysis and Project Development with YOLO </b> </center> </h1>\n",
        "\n",
        "In this tutorial, we will see how image datasets with different types of tasks such as detection , segmentation etc. look like, and how they are labelled, specifically in YOLO format.\n",
        "\n",
        "Then, we will download one dataset to explore it and clean it if required.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLUWE8gn9_RB"
      },
      "source": [
        "## **Classification**\n",
        "\n",
        "Image classification is the simplest and involves classifying an entire image into one of a set of predefined classes.\n",
        "\n",
        "The output of an image classifier is a single class label and a confidence score. Image classification is useful when you need to know only what class an image belongs to and don't need to know where objects of that class are located or what their exact shape is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSkOCZxt-ZAO"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418606-adf35c62-2e11-405d-84c6-b84e7d013804.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OstzhA30B2tK"
      },
      "source": [
        "Usually each image has a single object in it, which is its class> Following image shows CIFAR10 Dataset.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://datagen.tech/wp-content/uploads/2022/11/image1.png\" width=\"600\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcIc5sJBCx2S"
      },
      "source": [
        "The dataset should be labelled by arranging them in the following folders heirarchy.\n",
        "\n",
        "              root/\n",
        "              |-- class1/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class2/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class3/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- ...\n",
        "\n",
        "In this folder structure, the root directory contains one subdirectory for each class in the dataset. Each subdirectory is named after the corresponding class and contains all the images for that class.\n",
        "\n",
        "For example:\n",
        "\n",
        "              cifar-10-/\n",
        "              |\n",
        "              |-- train/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10008_airplane.png\n",
        "              |   |   |-- 10009_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 1000_automobile.png\n",
        "              |   |   |-- 1001_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 10014_bird.png\n",
        "              |   |   |-- 10015_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- test/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10_airplane.png\n",
        "              |   |   |-- 11_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 100_automobile.png\n",
        "              |   |   |-- 101_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 1000_bird.png\n",
        "              |   |   |-- 1001_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTjx8pXEB1B5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cZ9e5J4zvF9"
      },
      "source": [
        "## **Object Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52PMPO-rgZq-"
      },
      "source": [
        "Object detection is a task that involves identifying the location and class of objects in an image or video stream.\n",
        "\n",
        "The output of an object detector is a set of bounding boxes that enclose the objects in the image, along with class labels and confidence scores for each box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDruPnQMi315"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418624-5785cb93-74c9-4541-9179-d5c6782d491a.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFz-X3Zx1xKn"
      },
      "source": [
        "**Labelling format**\n",
        "\n",
        "In object detection tasks, various labeling formats are used to annotate images with information about the objects present. These formats typically include details about the object's class and location within the image. Here are some of the most common labeling formats:\n",
        "\n",
        "1. COCO\n",
        "2. YOLO\n",
        "3. CSV  \n",
        "5. XML\n",
        "6. PASCAL VOC\n",
        "\n",
        "We will be discussing only YOLO format, as you will be using YOLO framework for your project:\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "\n",
        "      class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "- Box coordinates must be normalized between 0 and 1\n",
        "\n",
        "\n",
        "An example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6es7DWt75YTf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/91506361-c7965000-e886-11ea-8291-c72b98c25eec.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDeb1gEM5uIT"
      },
      "source": [
        "Corresponding label text file should look like:\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/112467037-d2568c00-8d66-11eb-8796-55402ac0d62f.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0brGPZa4oRk7"
      },
      "source": [
        "## **Segmentation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56IDqcG6mNw"
      },
      "source": [
        "Instance segmentation goes a step further than object detection and involves identifying individual objects in an image and segmenting them from the rest of the image.\n",
        "\n",
        "The output of an instance segmentation model is a set of masks or contours that outline each object in the image, along with class labels and confidence scores for each object. Instance segmentation is useful when you need to know not only where objects are in an image, but also what their exact shape is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oItmHrqo8qLM"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418644-7df320b8-098d-47f1-85c5-26604d761286.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2C24Fz389GY"
      },
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - bounding coordinates: The bounding coordinates around the mask area, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "      <class-index> <x1> <y1> <x2> <y2> ... <xn> <yn>\n",
        "\n",
        "\n",
        "Here is an example of the YOLO dataset format for a single image with two objects made up of a 3-point segment and a 5-point segment.\n",
        "\n",
        "\n",
        "      0 0.681 0.485 0.670 0.487 0.676 0.487\n",
        "      1 0.504 0.000 0.501 0.004 0.498 0.004 0.493 0.010 0.492 0.0104\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPFHkCO8-2mW"
      },
      "source": [
        "## **Pose Estimation**\n",
        "Pose estimation is a task that involves identifying the location of specific points in an image, usually referred to as keypoints. The keypoints can represent various parts of the object such as joints, landmarks, or other distinctive features. The locations of the keypoints are usually represented as a set of 2D [x, y] or 3D [x, y, visible] coordinates.\n",
        "\n",
        "The output of a pose estimation model is a set of points that represent the keypoints on an object in the image, usually along with the confidence scores for each point. Pose estimation is a good choice when you need to identify specific parts of an object in a scene, and their location in relation to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zebzQ_Z6_CB9"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418616-9811ac0b-a4a7-452a-8aba-484ba32bb4a8.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9M4kU8P_QWU"
      },
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - Object class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - Object center coordinates: The x and y coordinates of the center of the object, normalized to be between 0 and 1.\n",
        "  - Object width and height: The width and height of the object, normalized to be between 0 and 1.\n",
        "  - Object keypoint coordinates: The keypoints of the object, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "Here is an example of the label format for pose estimation task:\n",
        "\n",
        "Format with Dim = 2\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <px2> <py2> ... <pxn> <pyn>\n",
        "Format with Dim = 3\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <p1-visibility> <px2> <py2> <p2-visibility> ... <pxn> <pyn> <p2-visibility>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jCdTqcVbN4h"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')    # mount again\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsAvGgxxHAS3"
      },
      "source": [
        "## FOLDERS HEIRARCHY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt4h9bFXjV9V"
      },
      "source": [
        "\n",
        "\n",
        " We need to convert the dataset into a specific heirarchy of folders for all the tasks except for task of classification.\n",
        "\n",
        "\n",
        "The directories should be in the following format:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKyjblYvb8fW"
      },
      "source": [
        "# **COCO128 Dataset**\n",
        "\n",
        "This section aims to introduce you to COCO dataset frequently used in Artificial Intelligence (AI).It is a foundational dataset in AI, widely used for tasks like object detection, segmentation, and image captioning.\n",
        "\n",
        "\n",
        "It Contains over 330,000 images with more than 200,000 labeled across 80 object categories. Unique for its richly annotated images, including object segmentation.It is widely used in computer vision research and has been used to train and evaluate many state-of-the-art object detection and segmentation models.\n",
        "\n",
        "Link to full dataset: https://cocodataset.org/#home\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G11PH4xOo8zO"
      },
      "source": [
        "We are going using coco128 dataset.This dataset contains the first 128 images of COCO train 2017. It is used as the tutorial dataset for YOLO.\n",
        "\n",
        "Download the dataset from:\n",
        "https://www.kaggle.com/datasets/ultralytics/coco128/data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DUeZCUkSwkG"
      },
      "source": [
        "## Dataset Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJe53Fzd1mZn"
      },
      "source": [
        "\n",
        "To draw bounding boxes on images we need to understand the labelling format used by this dataset. The labels for this dataset are stored in YOLO format. i.e.\n",
        "\n",
        "        class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvPN5o_jSKgK"
      },
      "source": [
        "The class_id is the numerical number assigned to different class labels as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qry8OPsHG3GK"
      },
      "outputs": [],
      "source": [
        "# ✅ Full Fire and Smoke Intensity Classes (plain text only)\n",
        "class_labels = {\n",
        "    0: \"Smoke\",\n",
        "    1: \"Fire\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD3ZrKmubFZd"
      },
      "source": [
        "same bounding box for all to make sure all data is collected for confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpZNqiVSbFMl"
      },
      "outputs": [],
      "source": [
        "def draw_yolo_bbox(image_path, label_path):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read label file\n",
        "    with open(label_path, 'r') as file:\n",
        "        bboxes = file.readlines()\n",
        "\n",
        "    # Draw each bbox\n",
        "    for bbox in bboxes:\n",
        "        class_id, x_center, y_center, bbox_width, bbox_height = [float(x) for x in bbox.split()]\n",
        "\n",
        "        # Convert YOLO bbox format to rectangle coordinates\n",
        "        x1 = int((x_center - bbox_width / 2) * width)\n",
        "        y1 = int((y_center - bbox_height / 2) * height)\n",
        "        x2 = int((x_center + bbox_width / 2) * width)\n",
        "        y2 = int((y_center + bbox_height / 2) * height)\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "        # Put label (class_id) near the bbox\n",
        "        label = class_labels[int(class_id)]\n",
        "        cv2.putText(image, label, (x1, y1+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
        "    # Display image\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8tH0PySW4n"
      },
      "source": [
        "The rest of the four values i.e.\n",
        "\n",
        "    0.479492 0.688771 0.955609 0.5955\n",
        "\n",
        "indidicate the location of the bounding box.\n",
        "\n",
        "These values are normalized, which should be converted to a format that can be used as coordinate values of rectangle function (of cv2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQbCyFCMaueA"
      },
      "source": [
        "First import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoPPaZu5a4Fp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEcvixvYa-A8"
      },
      "source": [
        "Set all the paths of the dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "merged dataset 1 2"
      ],
      "metadata": {
        "id": "iHQLsVwMk8WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# Unified Dataset — Dataset 1 2 (merged final version)\n",
        "dataset_path = \"/content/drive/MyDrive/dataset 1 2\"\n",
        "\n",
        "# Collect all image paths\n",
        "image_root = os.path.join(dataset_path, \"images\")\n",
        "label_root = os.path.join(dataset_path, \"labels\")\n",
        "\n",
        "image_paths = [\n",
        "    os.path.join(image_root, f)\n",
        "    for f in os.listdir(image_root)\n",
        "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "]\n",
        "\n",
        "label_paths = [\n",
        "    os.path.join(label_root, f)\n",
        "    for f in os.listdir(label_root)\n",
        "    if f.endswith(\".txt\")\n",
        "]\n",
        "\n",
        "\n",
        "# Print summary\n",
        "print(f\" Total images in Dataset 1 2: {len(image_paths)}\")\n",
        "print(f\"Total labels in Dataset 1 2: {len(label_paths)}\")\n",
        "\n",
        "# Show a few examples\n",
        "print(\"\\nSample image files:\")\n",
        "print(image_paths[:5])\n",
        "\n",
        "print(\"\\nSample label files:\")\n",
        "print(label_paths[:5])\n"
      ],
      "metadata": {
        "id": "hbpVnGHLk-5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xS3INAjbPTr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Home Fire Dataset — List image and label paths\n",
        "dataset_path = \"/content/drive/MyDrive/Home fire dataset/test\"\n",
        "image_dir = os.path.join(dataset_path, \"images\")\n",
        "label_dir = os.path.join(dataset_path, \"labels\")\n",
        "\n",
        "image_paths = [os.path.join(image_dir, f)\n",
        "               for f in sorted(os.listdir(image_dir))\n",
        "               if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "\n",
        "label_paths = [os.path.join(label_dir, f)\n",
        "               for f in sorted(os.listdir(label_dir))\n",
        "               if f.endswith(\".txt\")]\n",
        "\n",
        "print(f\"Total images: {len(image_paths)}\")\n",
        "print(f\"Total labels: {len(label_paths)}\")\n",
        "print(\"\\nSample images:\")\n",
        "for img in image_paths[:5]:\n",
        "    print(os.path.basename(img))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpP4yE5-sitI"
      },
      "source": [
        "\n",
        "\n",
        "Set all the paths of the dataset of Fire and Smoke:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrVyXbVushbR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_root = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "annotations_json = os.path.join(dataset_root, \"annotations\", \"instances_val2017.json\")\n",
        "\n",
        "# Check if JSON exists\n",
        "if os.path.exists(annotations_json):\n",
        "    print(f\"JSON found at: {annotations_json}\")\n",
        "else:\n",
        "    print(f\"JSON NOT found! Current working dir: {os.getcwd()}\")\n",
        "    # List contents of dataset_root to see folder names\n",
        "    print(\"Contents of dataset_root:\", os.listdir(dataset_root))\n",
        "    # List contents of annotations folder\n",
        "    annotations_folder = os.path.join(dataset_root, \"annotations\")\n",
        "    if os.path.exists(annotations_folder):\n",
        "        print(\"Contents of annotations folder:\", os.listdir(annotations_folder))\n",
        "    else:\n",
        "        print(\"Annotations folder not found!\")\n",
        "\n",
        "dataset_root = \"Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    for file in files:\n",
        "        if file.endswith(\".json\"):\n",
        "            print(\"Found JSON:\", os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZFQeneewaFY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Dataset Paths — Auto Setup\n",
        "dataset_root = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "\n",
        "images_dir = os.path.join(dataset_root, \"val2017\")\n",
        "annotations_dir = os.path.join(dataset_root, \"annotations\")\n",
        "json_file = os.path.join(annotations_dir, \"instances_train2017.json\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\", \"train\")\n",
        "\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# Sanity checks\n",
        "if not os.path.exists(images_dir):\n",
        "    raise FileNotFoundError(f\"Image folder missing: {images_dir}\")\n",
        "if not os.path.exists(json_file):\n",
        "    raise FileNotFoundError(f\"COCO JSON not found: {json_file}\")\n",
        "\n",
        "print(f\"Image path: {images_dir}\")\n",
        "print(f\"JSON file:  {json_file}\")\n",
        "print(f\"Output dir: {labels_dir}\")\n",
        "\n",
        "# Load COCO JSON\n",
        "with open(json_file, \"r\") as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "# Validate COCO structure\n",
        "required_keys = {\"images\", \"annotations\", \"categories\"}\n",
        "if not required_keys.issubset(coco.keys()):\n",
        "    raise ValueError(f\"Invalid COCO structure. Missing keys: {required_keys - set(coco.keys())}\")\n",
        "\n",
        "# Map image_id → filename and size\n",
        "img_id2file = {img['id']: img['file_name'] for img in coco['images']}\n",
        "img_id2size = {img['id']: (img['width'], img['height']) for img in coco['images']}\n",
        "\n",
        "# Group annotations per image\n",
        "img_annotations = defaultdict(list)\n",
        "for ann in coco['annotations']:\n",
        "    if ann.get('bbox') and ann['bbox'][2] > 0 and ann['bbox'][3] > 0:\n",
        "        img_annotations[ann['image_id']].append(ann)\n",
        "\n",
        "print(f\"Total images in JSON:      {len(img_id2file)}\")\n",
        "print(f\"Images with annotations:   {len(img_annotations)}\")\n",
        "\n",
        "\n",
        "# Convert COCO → YOLO format\n",
        "for img_id, anns in tqdm(img_annotations.items(), desc=\"Converting COCO → YOLO TXT\"):\n",
        "    img_name = img_id2file[img_id]\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    txt_path = os.path.join(labels_dir, Path(img_name).stem + \".txt\")\n",
        "\n",
        "    # Retrieve image dimensions\n",
        "    if os.path.exists(img_path):\n",
        "        try:\n",
        "            with Image.open(img_path) as im:\n",
        "                w, h = im.size\n",
        "        except Exception:\n",
        "            w, h = img_id2size.get(img_id, (640, 480))\n",
        "    else:\n",
        "        w, h = img_id2size.get(img_id, (640, 480))\n",
        "\n",
        "    # Write YOLO annotation file\n",
        "    with open(txt_path, \"w\") as f:\n",
        "        for ann in anns:\n",
        "            cid = ann[\"category_id\"] - 1  # COCO is 1-indexed\n",
        "            x_min, y_min, box_w, box_h = ann[\"bbox\"]\n",
        "\n",
        "            if box_w <= 0 or box_h <= 0:\n",
        "                continue\n",
        "\n",
        "            x_center = (x_min + box_w / 2) / w\n",
        "            y_center = (y_min + box_h / 2) / h\n",
        "            width_norm = box_w / w\n",
        "            height_norm = box_h / h\n",
        "\n",
        "            f.write(f\"{cid} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
        "\n",
        "\n",
        "# Verify results (no display)\n",
        "txt_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
        "if not txt_files:\n",
        "    raise RuntimeError(\"No YOLO .txt labels were generated. Check your JSON data.\")\n",
        "else:\n",
        "    print(f\"Successfully created {len(txt_files)} YOLO label files.\")\n",
        "\n",
        "print(\"Conversion complete. All annotations exported cleanly.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpdeeXqKmf59"
      },
      "source": [
        "Updated fix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tob9jEdAmeUU"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Dataset Paths\n",
        "dataset_root = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "images_dir = os.path.join(dataset_root, \"val2017\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\", \"val\")\n",
        "\n",
        "\n",
        "# Class Labels\n",
        "class_labels = {0: \"Smoke\", 1: \"Fire\"}\n",
        "\n",
        "\n",
        "\n",
        "# Intensity & Visibility (Data-Based)\n",
        "def analyze_intensity(img, bbox, cid):\n",
        "    from PIL import ImageStat\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean) / (3 * 255)\n",
        "    contrast = sum(stat.stddev) / (3 * 128)\n",
        "\n",
        "    if cid == 1:  # Fire\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            return \"High Intensity (Flames Visible)\"\n",
        "        elif brightness > 0.45:\n",
        "            return \"Moderate Intensity (Active Burn)\"\n",
        "        else:\n",
        "            return \"Low Intensity (Smoldering Fire)\"\n",
        "    elif cid == 0:  # Smoke\n",
        "        if brightness < 0.25 and contrast < 0.3:\n",
        "            return \"Dense Smoke (Low Visibility)\"\n",
        "        elif brightness < 0.5:\n",
        "            return \"Moderate Smoke (Partial Visibility)\"\n",
        "        else:\n",
        "            return \"Light Smoke (Thin Haze)\"\n",
        "    else:\n",
        "        return \"Unclassified\"\n",
        "\n",
        "\n",
        "# Parse YOLO TXT — data-only\n",
        "def parse_yolo_label(txt_path, w, h):\n",
        "    boxes = []\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            cid, xc, yc, bw, bh = map(float, parts[:5])\n",
        "            # convert from normalized → pixels\n",
        "            xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "            x1, y1, x2, y2 = int(xc - bw / 2), int(yc - bh / 2), int(xc + bw / 2), int(yc + bh / 2)\n",
        "            boxes.append((int(cid), (x1, y1, x2, y2)))\n",
        "    return boxes\n",
        "\n",
        "\n",
        "# DATA-ONLY DISPLAY (no visuals, no aesthetics)\n",
        "def show_label_data_only(n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    if not matched:\n",
        "        print(\"No matching image–label pairs found!\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n Showing {min(n, len(matched))} data-based detections (no visuals)...\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next((os.path.join(images_dir, stem + ext)\n",
        "                         for ext in image_exts if os.path.exists(os.path.join(images_dir, stem + ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        w, h = img.size\n",
        "        boxes = parse_yolo_label(txt_path, w, h)\n",
        "\n",
        "        print(f\"{stem}.jpg ({w}x{h}) — {len(boxes)} detections:\")\n",
        "        for cid, (x1, y1, x2, y2) in boxes:\n",
        "            cname = class_labels.get(cid, \"Unknown\")\n",
        "            intensity = analyze_intensity(img, (x1, y1, x2, y2), cid)\n",
        "            print(f\"   - Class: {cname} | Intensity: {intensity}\")\n",
        "            print(f\"     Bounding Box (px): {x1, y1, x2, y2}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "\n",
        "# Run — Data-Only Summary\n",
        "show_label_data_only(n=30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Permanently Reverse Class IDs (0 ↔ 1)\n",
        "labels_dir = Path(\"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\")\n",
        "flag_file  = labels_dir / \"_class_swap_done.flag\"\n",
        "\n",
        "if flag_file.exists():\n",
        "    print(f\"Swap already done earlier — skipping to avoid double flip.\\nIf you truly want to redo it, delete: {flag_file}\")\n",
        "else:\n",
        "    swapped = 0\n",
        "    for txt in labels_dir.glob(\"*.txt\"):\n",
        "        with open(txt) as f:\n",
        "            lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "        if not lines:\n",
        "            continue  # skip empty files\n",
        "\n",
        "        new_lines, changed = [], False\n",
        "        for ln in lines:\n",
        "            parts = ln.split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            try:\n",
        "                cid = int(float(parts[0]))\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            # Reverse Fire ↔ Smoke mapping\n",
        "            if cid == 0:\n",
        "                parts[0] = \"1\"\n",
        "                changed = True\n",
        "            elif cid == 1:\n",
        "                parts[0] = \"0\"\n",
        "                changed = True\n",
        "\n",
        "            new_lines.append(\" \".join(parts))\n",
        "\n",
        "        if changed:\n",
        "            with open(txt, \"w\") as f:\n",
        "                f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "            swapped += 1\n",
        "\n",
        "    # Create protection flag\n",
        "    flag_file.touch()\n",
        "    print(f\"Reversed class IDs in {swapped} label files inside {labels_dir}\")\n",
        "    print(f\"Protection flag created → {flag_file}\")\n"
      ],
      "metadata": {
        "id": "CDtKoKJc8skK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Permanently Reverse Class IDs (0 ↔ 1)\n",
        "# For: Home fire dataset\n",
        "\n",
        "labels_dir = Path(\"/content/drive/MyDrive/Home fire dataset/test/labels\")\n",
        "flag_file  = labels_dir / \"_class_swap_done.flag\"\n",
        "\n",
        "if not labels_dir.exists():\n",
        "    print(f\"Folder not found: {labels_dir}\")\n",
        "else:\n",
        "    if flag_file.exists():\n",
        "        print(f\"Swap already done earlier — skipping to avoid double flip.\\n\"\n",
        "              f\"If you truly want to redo it, delete: {flag_file}\")\n",
        "    else:\n",
        "        swapped = 0\n",
        "        for txt in labels_dir.glob(\"*.txt\"):\n",
        "            with open(txt) as f:\n",
        "                lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "            if not lines:\n",
        "                continue  # skip empty files\n",
        "\n",
        "            new_lines, changed = [], False\n",
        "            for ln in lines:\n",
        "                parts = ln.split()\n",
        "                if len(parts) < 5:\n",
        "                    continue\n",
        "                try:\n",
        "                    cid = int(float(parts[0]))\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "                # Reverse Fire ↔ Smoke mapping\n",
        "                if cid == 0:\n",
        "                    parts[0] = \"1\"  # Smoke → Fire\n",
        "                    changed = True\n",
        "                elif cid == 1:\n",
        "                    parts[0] = \"0\"  # Fire → Smoke\n",
        "                    changed = True\n",
        "\n",
        "                new_lines.append(\" \".join(parts))\n",
        "\n",
        "            if changed:\n",
        "                with open(txt, \"w\") as f:\n",
        "                    f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "                swapped += 1\n",
        "\n",
        "        # Create protection flag\n",
        "        flag_file.touch()\n",
        "        print(f\"Reversed class IDs in {swapped} label files inside {labels_dir}\")\n",
        "        print(f\"Protection flag created → {flag_file}\")\n"
      ],
      "metadata": {
        "id": "JgSU9uPa_Ip8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3b2OCk5PhU7"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Directories\n",
        "images_dir = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\"\n",
        "labels_dir = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\"\n",
        "save_dir   = \"/content/drive/MyDrive/fire_smoke_previews/data_labels_output\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Parse YOLO Labels — Read IDs exactly as written in .txt\n",
        "def parse_yolo_label(txt_path, w, h):\n",
        "    \"\"\"\n",
        "    Reads YOLO labels (class_id x_center y_center width height)\n",
        "    Converts normalized coordinates into pixel coordinates.\n",
        "    \"\"\"\n",
        "    boxes = []\n",
        "    if not os.path.exists(txt_path):\n",
        "        return boxes\n",
        "\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                cid = int(float(parts[0]))  # read ID from txt file\n",
        "                xc, yc, bw, bh = map(float, parts[1:5])\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            # Ensure normalized values stay within range\n",
        "            xc, yc, bw, bh = [max(0, min(1, v)) for v in (xc, yc, bw, bh)]\n",
        "\n",
        "            # Convert normalized → pixel coordinates\n",
        "            x1 = int((xc - bw / 2) * w)\n",
        "            y1 = int((yc - bh / 2) * h)\n",
        "            x2 = int((xc + bw / 2) * w)\n",
        "            y2 = int((yc + bh / 2) * h)\n",
        "\n",
        "            # Clamp inside image bounds\n",
        "            x1, y1 = max(0, min(x1, w - 1)), max(0, min(y1, h - 1))\n",
        "            x2, y2 = max(0, min(x2, w - 1)), max(0, min(y2, h - 1))\n",
        "\n",
        "            boxes.append((cid, (x1, y1, x2, y2), [xc, yc, bw, bh]))\n",
        "    return boxes\n",
        "\n",
        "\n",
        "\n",
        "# Rewrite .txt Files Based on Detected Classes (0=Smoke, 1=Fire)\n",
        "def enforce_txt_label_integrity(labels_dir):\n",
        "    \"\"\"\n",
        "    Ensures each .txt file uses the correct IDs: 0=Smoke, 1=Fire.\n",
        "    Detects if IDs are reversed by majority class inspection,\n",
        "    and automatically fixes the IDs permanently.\n",
        "    \"\"\"\n",
        "    all_ids = []\n",
        "    txt_files = list(Path(labels_dir).glob(\"*.txt\"))\n",
        "    if not txt_files:\n",
        "        print(\"No label files found.\")\n",
        "        return\n",
        "\n",
        "    # Collect global class ID distribution\n",
        "    for txt in txt_files:\n",
        "        with open(txt) as f:\n",
        "            for line in f:\n",
        "                p = line.strip().split()\n",
        "                if len(p) >= 1 and p[0].isdigit():\n",
        "                    all_ids.append(int(p[0]))\n",
        "\n",
        "    if not all_ids:\n",
        "        print(\"No class IDs found in any file.\")\n",
        "        return\n",
        "\n",
        "    from collections import Counter\n",
        "    id_counts = Counter(all_ids)\n",
        "    print(f\"Current class distribution: {id_counts}\")\n",
        "\n",
        "    # Detect if mapping looks reversed (e.g., Fire dominates ID=0)\n",
        "    reversed_mapping = id_counts.get(0, 0) > id_counts.get(1, 0)\n",
        "    if reversed_mapping:\n",
        "        print(\"Detected reversed class mapping → Swapping IDs (0↔1) across dataset.\")\n",
        "    else:\n",
        "        print(\"Class mapping appears consistent (0=Smoke, 1=Fire).\")\n",
        "\n",
        "    corrected = 0\n",
        "    for txt in txt_files:\n",
        "        with open(txt) as f:\n",
        "            lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "        if not lines:\n",
        "            continue\n",
        "\n",
        "        new_lines, changed = [], False\n",
        "        for ln in lines:\n",
        "            parts = ln.split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                cid = int(float(parts[0]))\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            # Apply reversal if needed\n",
        "            if reversed_mapping:\n",
        "                cid = 1 - cid\n",
        "\n",
        "            parts[0] = str(cid)\n",
        "            new_lines.append(\" \".join(parts))\n",
        "            changed = True\n",
        "\n",
        "        if changed:\n",
        "            with open(txt, \"w\") as f:\n",
        "                f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "            corrected += 1\n",
        "\n",
        "    print(f\"Updated {corrected} label files with consistent IDs (0=Smoke, 1=Fire).\")\n",
        "\n",
        "\n",
        "\n",
        "# Draw Bounding Boxes Using True txt IDs\n",
        "def draw_true_labels(img_path, txt_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    w, h = img.size\n",
        "    boxes = parse_yolo_label(txt_path, w, h)\n",
        "    if not boxes:\n",
        "        return img, 0\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    for cid, (x1, y1, x2, y2), vals in boxes:\n",
        "        label_name = \"Fire\" if cid == 1 else \"Smoke\"\n",
        "        color = (255, 60, 0) if cid == 1 else (80, 200, 255)  # Fire=red, Smoke=cyan\n",
        "        vals_str = \", \".join(f\"{v:.4f}\" for v in vals)\n",
        "        draw.rectangle((x1, y1, x2, y2), outline=color, width=2)\n",
        "        draw.text((x1 + 3, max(0, y1 - 14)), f\"{label_name} [{vals_str}]\", fill=color)\n",
        "\n",
        "    return img, len(boxes)\n",
        "\n",
        "\n",
        "\n",
        "# Display & Save Annotated Images\n",
        "def display_and_save_data_labels(n=5):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    print(f\"\\nDisplaying {min(n, len(matched))} verified annotation previews...\\n\")\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next(\n",
        "            (os.path.join(images_dir, stem + ext)\n",
        "             for ext in image_exts if os.path.exists(os.path.join(images_dir, stem + ext))),\n",
        "            None,\n",
        "        )\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img, count = draw_true_labels(img_path, txt_path)\n",
        "        display(img)\n",
        "        print(f\"{stem}.jpg — {count} boxes drawn from {os.path.basename(txt_path)}\")\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{stem}_from_txt.jpg\")\n",
        "        img.save(save_path)\n",
        "\n",
        "    print(f\"\\nSaved annotated images to: {save_dir}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# Run\n",
        "enforce_txt_label_integrity(labels_dir)\n",
        "display_and_save_data_labels(n=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l46mseBNReL3"
      },
      "source": [
        "validate the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW5VzMIeVJY9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/Home fire dataset/test/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "\n",
        "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "\n",
        "missing_images = sorted(label_stems - image_stems)\n",
        "extra_images = sorted(image_stems - label_stems)\n",
        "\n",
        "# Delete YOLO txts that don’t match an image\n",
        "for stem in missing_images:\n",
        "    os.remove(os.path.join(labels_dir, f\"{stem}.txt\"))\n",
        "\n",
        "print(f\"Kept {len(image_stems & label_stems)} valid image–label pairs.\")\n",
        "print(f\"Removed {len(missing_images)} orphan label files (no matching image).\")\n",
        "if extra_images:\n",
        "    print(f\"{len(extra_images)} images have no label files (you can auto-generate later).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwQmsHS_a4vX"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "image_stems = {Path(f).stem for f in os.listdir(images_dir)}\n",
        "label_stems = {Path(f).stem for f in os.listdir(labels_dir)}\n",
        "matched = image_stems & label_stems\n",
        "print(f\"Matched pairs: {len(matched)} / {len(image_stems)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjF6qaGFA9JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qKkTJeSRdPh"
      },
      "source": [
        "validate images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "debug"
      ],
      "metadata": {
        "id": "1nGLBIIhA8JK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "end of debug"
      ],
      "metadata": {
        "id": "V-x7o2foCVIx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT_aa_4NVLOg"
      },
      "outputs": [],
      "source": [
        "# Verify Fire/Smoke Annotations (no label swapping)\n",
        "\n",
        "import os, random, numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Paths\n",
        "images_dir = \"/content/drive/MyDrive/Home fire dataset/test/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "\n",
        "\n",
        "# Class Labels\n",
        "class_labels = {0: \"Smoke\", 1: \"Fire\"}\n",
        "\n",
        "\n",
        "# Helper Functions\n",
        "def strip_annotation(stem: str):\n",
        "    \"\"\"Remove suffixes like _annotation or _annotated for matching image/label pairs.\"\"\"\n",
        "    for suf in (\"_annotation\", \"_annotated\"):\n",
        "        if stem.lower().endswith(suf):\n",
        "            stem = stem[: -len(suf)]\n",
        "    return stem\n",
        "\n",
        "\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    \"\"\"Convert YOLO bbox format to pixel coordinates.\"\"\"\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) < 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts[:5])\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (\n",
        "        int(xc - bw / 2),\n",
        "        int(yc - bh / 2),\n",
        "        int(xc + bw / 2),\n",
        "        int(yc + bh / 2),\n",
        "    )\n",
        "\n",
        "\n",
        "def analyze_intensity(img, bbox, cid):\n",
        "    \"\"\"Brightness / contrast / color-based heuristic for Fire vs Smoke intensity.\"\"\"\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean) / (3 * 255)\n",
        "    contrast = sum(stat.stddev) / (3 * 128)\n",
        "\n",
        "    hsv = np.array(region.convert(\"HSV\"))\n",
        "    sat = np.mean(hsv[:, :, 1]) / 255.0\n",
        "    hue = np.mean(hsv[:, :, 0])\n",
        "\n",
        "    if cid == 1:  # Fire\n",
        "        if sat > 0.35 and 5 < hue < 45:\n",
        "            if brightness > 0.7 and contrast > 0.5:\n",
        "                return \"High Intensity (Flames Visible)\"\n",
        "            elif brightness > 0.45:\n",
        "                return \"Medium Intensity (Active Burn)\"\n",
        "            else:\n",
        "                return \"Low Intensity (Smoldering Fire)\"\n",
        "        return \"False Positive (Should be Smoke)\"\n",
        "\n",
        "    elif cid == 0:  # Smoke\n",
        "        if sat < 0.35:\n",
        "            if brightness < 0.25 and contrast < 0.3:\n",
        "                return \"Dense Smoke (Low Visibility)\"\n",
        "            elif brightness < 0.5:\n",
        "                return \"Moderate Smoke (Partial Visibility)\"\n",
        "            else:\n",
        "                return \"Light Smoke (Thin Haze)\"\n",
        "        return \"Possible Fire/Hot Spot\"\n",
        "\n",
        "    return \"Unclassified\"\n",
        "\n",
        "\n",
        "\n",
        "# Annotate & Display Random Samples\n",
        "def display_clean_annotations(images_dir, labels_dir, n=10):\n",
        "    \"\"\"Display annotated fire/smoke detections using existing YOLO label files.\"\"\"\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(image_exts)]\n",
        "    label_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    image_stems = {strip_annotation(Path(f).stem) for f in image_files}\n",
        "    label_stems = {strip_annotation(Path(f).stem) for f in label_files}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    if not matched:\n",
        "        print(\"No matching image-label pairs found!\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nDisplaying {min(n, len(matched))} labeled samples \"\n",
        "          f\"(of {len(matched)} total)…\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next(\n",
        "            (os.path.join(images_dir, f)\n",
        "             for f in image_files\n",
        "             if strip_annotation(Path(f).stem) == stem),\n",
        "            None\n",
        "        )\n",
        "        txt_path = next(\n",
        "            (os.path.join(labels_dir, f)\n",
        "             for f in label_files\n",
        "             if strip_annotation(Path(f).stem) == stem),\n",
        "            None\n",
        "        )\n",
        "\n",
        "        if not img_path or not txt_path:\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        with open(txt_path) as f:\n",
        "            lines = [ln.strip() for ln in f if ln.strip()]\n",
        "        if not lines:\n",
        "            continue\n",
        "\n",
        "        for line in lines:\n",
        "            cid, bbox = yolo_to_bbox(line, w, h)\n",
        "            if not bbox:\n",
        "                continue\n",
        "            intensity = analyze_intensity(img, bbox, cid)\n",
        "            cname = class_labels.get(cid, \"Unknown\")\n",
        "            label_text = f\"{cname} — {intensity}\"\n",
        "            draw.rectangle(bbox, outline=(255, 255, 255), width=2)\n",
        "            draw.text((bbox[0] + 3, bbox[1] - 14), label_text, fill=(255, 255, 255))\n",
        "            print(f\"{Path(img_path).name} → {label_text}\")\n",
        "\n",
        "        display(img)\n",
        "        print(f\"Displayed: {Path(img_path).name}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# Run Preview\n",
        "\n",
        "display_clean_annotations(images_dir, labels_dir, n=30)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT6jdlYWT3di"
      },
      "source": [
        "Datasets NEW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# # Swap class IDs (0 ↔ 1) in Dataset 1 2 label files\n",
        "# labels_dir = \"/content/drive/MyDrive/dataset 1 2/labels\"\n",
        "#\n",
        "# swapped = 0\n",
        "# for fname in os.listdir(labels_dir):\n",
        "#     if not fname.endswith(\".txt\"):\n",
        "#         continue\n",
        "#     path = os.path.join(labels_dir, fname)\n",
        "#\n",
        "#     with open(path, \"r\") as f:\n",
        "#         lines = [ln.strip() for ln in f if ln.strip()]\n",
        "#\n",
        "#     new_lines, changed = [], False\n",
        "#     for ln in lines:\n",
        "#         parts = ln.split()\n",
        "#         if len(parts) < 5:\n",
        "#             continue\n",
        "#         try:\n",
        "#             cid = int(float(parts[0]))\n",
        "#         except ValueError:\n",
        "#             continue\n",
        "#\n",
        "#         # Swap Fire ↔ Smoke\n",
        "#         if cid == 0:\n",
        "#             parts[0] = \"1\"   # Fire\n",
        "#             changed = True\n",
        "#         elif cid == 1:\n",
        "#             parts[0] = \"0\"   # Smoke\n",
        "#             changed = True\n",
        "#\n",
        "#         new_lines.append(\" \".join(parts))\n",
        "#\n",
        "#     if changed:\n",
        "#         with open(path, \"w\") as f:\n",
        "#             f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "#         swapped += 1\n",
        "#\n",
        "# print(f\"Swapped class IDs in {swapped} label files inside {labels_dir}\")\n",
        "# print(\"Label correction complete — 0 = Smoke, 1 = Fire.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uUbdoRzbvE4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "debug\n"
      ],
      "metadata": {
        "id": "faZRQ5WFBb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "debug finish"
      ],
      "metadata": {
        "id": "D1yMpIwJBdKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "permanentfix txt for class swap"
      ],
      "metadata": {
        "id": "fZn2lqUSC07-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Ju0LDXPTGw"
      },
      "outputs": [],
      "source": [
        "import os, random, glob, json\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# PATHS — DATASET 1_2 (merged)\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/dataset 1 2/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/dataset 1 2/labels\"\n",
        "swap_log = \"/content/drive/MyDrive/dataset_1_2_label_swap.json\"  # marker file to prevent re-swapping\n",
        "\n",
        "\n",
        "# PERMANENT FIX — ONE-TIME 0↔1 SWAP\n",
        "\n",
        "def swap_labels_once(label_folder, log_path):\n",
        "    # Check if swap has already been performed\n",
        "    if os.path.exists(log_path):\n",
        "        with open(log_path, \"r\") as f:\n",
        "            log = json.load(f)\n",
        "        if log.get(\"swapped_once\", False):\n",
        "            print(\"Swap already performed previously — skipping re-swap.\")\n",
        "            return False\n",
        "\n",
        "    swapped = 0\n",
        "    for fname in os.listdir(label_folder):\n",
        "        if not fname.endswith(\".txt\"):\n",
        "            continue\n",
        "        path = os.path.join(label_folder, fname)\n",
        "\n",
        "        with open(path, \"r\") as f:\n",
        "            lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "        new_lines, changed = [], False\n",
        "        for ln in lines:\n",
        "            parts = ln.split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            try:\n",
        "                cid = int(float(parts[0]))\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            # Swap 0 ↔ 1 only once\n",
        "            if cid == 0:\n",
        "                parts[0] = \"1\"\n",
        "                changed = True\n",
        "            elif cid == 1:\n",
        "                parts[0] = \"0\"\n",
        "                changed = True\n",
        "\n",
        "            new_lines.append(\" \".join(parts))\n",
        "\n",
        "        if changed:\n",
        "            with open(path, \"w\") as f:\n",
        "                f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "            swapped += 1\n",
        "\n",
        "    # Save log so swap won't run again\n",
        "    with open(log_path, \"w\") as f:\n",
        "        json.dump({\"swapped_once\": True, \"files_updated\": swapped}, f)\n",
        "\n",
        "    print(f\"Permanently swapped class IDs in {swapped} label files inside {label_folder}\")\n",
        "    return True\n",
        "\n",
        "swap_labels_once(labels_dir, swap_log)\n",
        "\n",
        "\n",
        "# CLASS LABELS\n",
        "\n",
        "class_labels = {0: \"Smoke\", 1: \"Fire\"}\n",
        "\n",
        "\n",
        "# Count bounding boxes by class across all label files\n",
        "\n",
        "def count_label_boxes(label_folder):\n",
        "    counts = {0: 0, 1: 0, \"other\": 0}\n",
        "    for path in glob.glob(os.path.join(label_folder, \"*.txt\")):\n",
        "        with open(path) as f:\n",
        "            for ln in f:\n",
        "                if not ln.strip():\n",
        "                    continue\n",
        "                try:\n",
        "                    cid = int(float(ln.split()[0]))\n",
        "                    if cid == 0:\n",
        "                        counts[0] += 1\n",
        "                    elif cid == 1:\n",
        "                        counts[1] += 1\n",
        "                    else:\n",
        "                        counts[\"other\"] += 1\n",
        "                except Exception:\n",
        "                    continue\n",
        "    print(\"Bounding-box counts across all labels:\")\n",
        "    print(f\"   0 (Smoke): {counts[0]} boxes\")\n",
        "    print(f\"   1 (Fire):  {counts[1]} boxes\")\n",
        "    print(f\"   Other IDs: {counts['other']} boxes\\n\")\n",
        "\n",
        "count_label_boxes(labels_dir)\n",
        "\n",
        "\n",
        "# YOLO TXT → BBox\n",
        "\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw / 2), int(yc - bh / 2),\n",
        "                      int(xc + bw / 2), int(yc + bh / 2))\n",
        "\n",
        "\n",
        "# Brightness & Contrast Analyzer\n",
        "\n",
        "def analyze_visibility(img, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean) / (3 * 255)\n",
        "    contrast = sum(stat.stddev) / (3 * 128)\n",
        "    return brightness, contrast\n",
        "\n",
        "\n",
        "#Intensity Classification\n",
        "\n",
        "def classify_intensity(cid, brightness, contrast):\n",
        "    if cid == 1:  # Fire\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            return \"High Intensity (Flames Visible)\"\n",
        "        elif brightness > 0.45:\n",
        "            return \"Moderate Intensity (Active Burn)\"\n",
        "        else:\n",
        "            return \"Low Intensity (Smoldering Fire)\"\n",
        "    elif cid == 0:  # Smoke\n",
        "        if brightness < 0.25 and contrast < 0.3:\n",
        "            return \"Dense Smoke (Low Visibility)\"\n",
        "        elif brightness < 0.5:\n",
        "            return \"Moderate Smoke (Partial Visibility)\"\n",
        "        else:\n",
        "            return \"Light Smoke (Thin Haze)\"\n",
        "    return \"Unclassified\"\n",
        "\n",
        "\n",
        "# DISPLAY FUNCTION\n",
        "def display_clean_labels(images_dir, labels_dir, n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir)\n",
        "                   if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir)\n",
        "                   if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    print(f\"\\nDisplaying {min(n, len(matched))} annotated samples \"\n",
        "          f\"(of {len(matched)} total)…\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next((os.path.join(images_dir, stem + ext)\n",
        "                         for ext in image_exts\n",
        "                         if os.path.exists(os.path.join(images_dir, stem + ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        with open(txt_path) as f:\n",
        "            for line in f.readlines():\n",
        "                cid, bbox = yolo_to_bbox(line, w, h)\n",
        "                if not bbox:\n",
        "                    continue\n",
        "                brightness, contrast = analyze_visibility(img, bbox)\n",
        "                cname = class_labels.get(cid, \"Unknown\")\n",
        "                intensity = classify_intensity(cid, brightness, contrast)\n",
        "                label_text = f\"{cname} — {intensity}\"\n",
        "                color = (255, 60, 0) if cid == 1 else (180, 180, 180)\n",
        "                draw.rectangle(bbox, outline=color, width=3)\n",
        "                draw.text((bbox[0] + 2, bbox[1] - 14),\n",
        "                          label_text, fill=color)\n",
        "\n",
        "        display(img)\n",
        "        print(f\"{stem}.jpg | {label_text}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# RUN VISUALIZATION\n",
        "display_clean_labels(images_dir, labels_dir, n=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_path = f\"{dataset_root}/annotations/instances_train2017.json\"\n",
        "images_dir = Path(f\"{dataset_root}/train2017\")\n",
        "labels_dir = Path(f\"{dataset_root}/labels/train\")\n"
      ],
      "metadata": {
        "id": "_SCsH_j46cRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Paths\n",
        "dataset_root = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "json_path = f\"{dataset_root}/annotations/instances_val2017.json\"\n",
        "images_dir = Path(f\"{dataset_root}/val2017\")\n",
        "labels_dir = Path(f\"{dataset_root}/labels/val\")\n",
        "\n",
        "labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# Load COCO Annotations\n",
        "with open(json_path, \"r\") as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "# Map category names → IDs\n",
        "cat_map = {c[\"name\"].lower(): c[\"id\"] for c in coco[\"categories\"]}\n",
        "print(\"COCO Categories Found:\", list(cat_map.keys()))\n",
        "\n",
        "# Define which classes to keep\n",
        "keep_cats = {\n",
        "    cat_map.get(\"smoke\"),\n",
        "    cat_map.get(\"fire\")\n",
        "}\n",
        "keep_cats = {c for c in keep_cats if c is not None}\n",
        "print(f\"Keeping only categories: {keep_cats} (Fire & Smoke)\")\n",
        "\n",
        "# Group annotations by image_id\n",
        "img_to_annos = {}\n",
        "for ann in coco[\"annotations\"]:\n",
        "    if ann.get(\"bbox\") and ann[\"bbox\"][2] > 0 and ann[\"bbox\"][3] > 0:\n",
        "        if ann[\"category_id\"] in keep_cats:\n",
        "            img_to_annos.setdefault(ann[\"image_id\"], []).append(ann)\n",
        "\n",
        "# Map image_id → filename + size\n",
        "img_id_to_info = {im[\"id\"]: im for im in coco[\"images\"]}\n",
        "\n",
        "print(f\"{len(img_id_to_info)} total images in JSON.\")\n",
        "print(f\"{len(coco['annotations'])} total annotations (filtered to Fire/Smoke only).\")\n",
        "\n",
        "\n",
        "# Convert to YOLO Format\n",
        "converted = 0\n",
        "skipped = 0\n",
        "\n",
        "for img_id, info in img_id_to_info.items():\n",
        "    img_name = info[\"file_name\"]\n",
        "    label_path = labels_dir / f\"{Path(img_name).stem}.txt\"\n",
        "    img_path = images_dir / img_name\n",
        "\n",
        "    if not img_path.exists():\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with Image.open(img_path) as im:\n",
        "            W, H = im.size\n",
        "    except Exception as e:\n",
        "        print(f\"Skipped {img_name}: {e}\")\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    annos = img_to_annos.get(img_id, [])\n",
        "    if not annos:\n",
        "        # Write empty file for YOLO compatibility\n",
        "        label_path.write_text(\"\")\n",
        "        continue\n",
        "\n",
        "    with open(label_path, \"w\") as f:\n",
        "        for a in annos:\n",
        "            x, y, w, h = a[\"bbox\"]\n",
        "            x_c, y_c = (x + w / 2) / W, (y + h / 2) / H\n",
        "            w_n, h_n = w / W, h / H\n",
        "\n",
        "            # Map COCO → YOLO class IDs\n",
        "            if a[\"category_id\"] == cat_map.get(\"smoke\"):\n",
        "                cid = 0  # Smoke\n",
        "            elif a[\"category_id\"] == cat_map.get(\"fire\"):\n",
        "                cid = 1  # Fire\n",
        "            else:\n",
        "                continue  # Skip any others (safety)\n",
        "\n",
        "            f.write(f\"{cid} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\\n\")\n",
        "\n",
        "    converted += 1\n",
        "\n",
        "print(f\"Recreated {converted} YOLO label files (Fire/Smoke only).\")\n",
        "print(f\"Skipped {skipped} missing or unreadable images.\")\n",
        "\n",
        "\n",
        "# Sanity Check\n",
        "txt_files = sorted([f.name for f in labels_dir.glob('*.txt')])\n",
        "if txt_files:\n",
        "    print(f\"\\nExample label file ({txt_files[0]}):\")\n",
        "    print((labels_dir / txt_files[0]).read_text()[:200])\n",
        "else:\n",
        "    print(\"No label files generated — check category names in JSON.\")\n"
      ],
      "metadata": {
        "id": "dMKMxS_X3QaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MegzRT78_GK9"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# GLOBAL SETTINGS — ALL DATASETS\n",
        "\n",
        "datasets = {\n",
        "    \"Fire_Smoke_COCO\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\"\n",
        "    },\n",
        "    \"Home_Fire_Test\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Home fire dataset/test/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "    },\n",
        "    \"Dataset_1V2\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 1 2/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 1 2/labels\"\n",
        "    }\n",
        "}\n",
        "\n",
        "class_labels = {\n",
        "    0: \"Smoke\",\n",
        "    1: \"Fire\"\n",
        "}\n",
        "\n",
        "\n",
        "# HELPERS — YOLO PARSING + BRIGHTNESS ANALYSIS\n",
        "\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) < 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts[:5])\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (\n",
        "        int(xc - bw/2),\n",
        "        int(yc - bh/2),\n",
        "        int(xc + bw/2),\n",
        "        int(yc + bh/2)\n",
        "    )\n",
        "\n",
        "def analyze_region(img, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"L\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = stat.mean[0] / 255\n",
        "    contrast = stat.stddev[0] / 128\n",
        "    return brightness, contrast\n",
        "\n",
        "\n",
        "# INTENSITY CLASSIFIER (Final – 2 classes: 0=Smoke, 1=Fire)\n",
        "\n",
        "def classify_intensity(cid, brightness, contrast):\n",
        "    \"\"\"Classify Fire/Smoke intensity based on brightness & contrast only.\"\"\"\n",
        "    if cid == 1:  # Fire\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            return \"High Intensity (Flames Visible)\"\n",
        "        elif brightness > 0.45:\n",
        "            return \"Moderate Intensity (Active Burn)\"\n",
        "        else:\n",
        "            return \"Low Intensity (Smoldering Fire)\"\n",
        "    elif cid == 0:  # Smoke\n",
        "        if brightness < 0.25 and contrast < 0.3:\n",
        "            return \"Dense Smoke (Low Visibility)\"\n",
        "        elif brightness < 0.5:\n",
        "            return \"Moderate Smoke (Partial Visibility)\"\n",
        "        else:\n",
        "            return \"Light Smoke (Thin Haze)\"\n",
        "    return \"Unclassified\"\n",
        "\n",
        "\n",
        "# OBJECT DETECTION + TEXT LABEL DISPLAY\n",
        "\n",
        "def display_detections(images_dir, labels_dir, dataset_name, n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    print(f\"\\nDataset: {dataset_name}\")\n",
        "    print(f\"Found {len(matched)} valid image–label pairs.\\n\")\n",
        "\n",
        "    for stem in random.sample(matched, min(n, len(matched))):\n",
        "        img_path = next((os.path.join(images_dir, stem + ext)\n",
        "                         for ext in image_exts if os.path.exists(os.path.join(images_dir, stem + ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        detections = []\n",
        "        with open(txt_path) as f:\n",
        "            for line in f.readlines():\n",
        "                cid, bbox = yolo_to_bbox(line, w, h)\n",
        "                if not bbox:\n",
        "                    continue\n",
        "\n",
        "                brightness, contrast = analyze_region(img, bbox)\n",
        "                cname = class_labels.get(cid, \"Unknown\")\n",
        "                intensity = classify_intensity(cid, brightness, contrast)\n",
        "                detections.append((cname, intensity, bbox))\n",
        "\n",
        "        # Draw detections (text only)\n",
        "        for cname, intensity, bbox in detections:\n",
        "            label_text = f\"{cname} — {intensity}\"\n",
        "            draw.rectangle(bbox, outline=(255, 255, 255), width=2)\n",
        "            draw.text((bbox[0] + 2, bbox[1] - 14), label_text, fill=(255, 255, 255))\n",
        "\n",
        "        # Display annotated image\n",
        "        display(img)\n",
        "\n",
        "        # Print summary in terminal\n",
        "        print(f\"{stem}.jpg | {len(detections)} objects detected\")\n",
        "        for cname, intensity, bbox in detections:\n",
        "            print(f\"   - {cname}: {intensity}  |  bbox={bbox}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# RUN DETECTIONS FOR ALL DATASETS\n",
        "\n",
        "for name, paths in datasets.items():\n",
        "    display_detections(paths[\"images\"], paths[\"labels\"], name, n=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKD1VpsSbpt3"
      },
      "source": [
        "The funtion \"draw_yolo_box\", takes input an image path and its corresponding label path. Then, draws the bounding boxes and write the object's label in each box. Finally it displays the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1G3t3yXcVOl"
      },
      "outputs": [],
      "source": [
        "def draw_yolo_bbox(image_path, label_path):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read label file\n",
        "    with open(label_path, 'r') as file:\n",
        "        bboxes = file.readlines()\n",
        "\n",
        "    # Draw each bbox\n",
        "    for bbox in bboxes:\n",
        "        cls, x_center, y_center, w, h = map(float, bbox.strip().split())\n",
        "        x1 = int((x_center - w / 2) * width)\n",
        "        y1 = int((y_center - h / 2) * height)\n",
        "        x2 = int((x_center + w / 2) * width)\n",
        "        y2 = int((y_center + h / 2) * height)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QcDHeIZcbuS"
      },
      "source": [
        "The function \"print_random_images\" takes in input the list of images' paths, a number defining how much images we want to print. So it randomly selects the images to display and calls \"draw_yolo_bbox\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9L8MkvV-EBh"
      },
      "outputs": [],
      "source": [
        "def print_random_imagesFireandSmoke(image_paths, n=30):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCmyf-A-pgZN"
      },
      "outputs": [],
      "source": [
        "def print_random_imagesHomeFire(image_paths, n=30):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-qPj7DNoZTH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6TvL9xMmpcx"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# CLASS LABELS\n",
        "class_labels = {0: \"Smoke\", 1: \"Fire\"}\n",
        "\n",
        "\n",
        "# YOLO TXT → Bounding Box\n",
        "\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw/2), int(yc - bh/2), int(xc + bw/2), int(yc + bh/2))\n",
        "\n",
        "\n",
        "# Intensity & Visibility Analyzer\n",
        "\n",
        "def analyze_conditions(img, bbox, cid):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"L\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    mean_brightness = stat.mean[0] / 255\n",
        "    stddev = stat.stddev[0] / 255\n",
        "\n",
        "    if stddev < 0.25:\n",
        "        visibility = \"Low Visibility\"\n",
        "    elif stddev < 0.45:\n",
        "        visibility = \"Partial Visibility\"\n",
        "    else:\n",
        "        visibility = \"Clear Details\"\n",
        "\n",
        "    if cid == 1:  # Fire\n",
        "        if mean_brightness > 0.75 and stddev > 0.5:\n",
        "            label = f\"Fire — High Intensity (Flames Visible, {visibility})\"\n",
        "        elif mean_brightness > 0.55:\n",
        "            label = f\"Fire — Medium Intensity (Active Burn, {visibility})\"\n",
        "        else:\n",
        "            label = f\"Fire — Low Intensity (Smoldering, {visibility})\"\n",
        "    elif cid == 0:  # Smoke\n",
        "        if mean_brightness < 0.25:\n",
        "            label = f\"Smoke — Dense (Toxic, {visibility})\"\n",
        "        elif mean_brightness < 0.45:\n",
        "            label = f\"Smoke — Moderate (Thick, {visibility})\"\n",
        "        else:\n",
        "            label = f\"Smoke — Light (Thin Haze, {visibility})\"\n",
        "    else:\n",
        "        label = f\"Unknown ({visibility})\"\n",
        "\n",
        "    return (255, 60, 0) if cid == 1 else (180, 180, 180), label\n",
        "\n",
        "\n",
        "# Draw YOLO Bounding Boxes\n",
        "\n",
        "def draw_yolo_bbox(img_path, label_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    w, h = img.size\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        return img\n",
        "\n",
        "    with open(label_path) as f:\n",
        "        lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "    for line in lines:\n",
        "        cid, bbox = yolo_to_bbox(line, w, h)\n",
        "        if not bbox:\n",
        "            continue\n",
        "        color, text = analyze_conditions(img, bbox, cid)\n",
        "        draw.rectangle(bbox, outline=color, width=2)\n",
        "        draw.text((bbox[0] + 3, max(0, bbox[1] - 14)), text, fill=color)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "# Show Random Images (separate dataset view)\n",
        "def show_random_images(image_dir, label_dir, title, n=12):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_dir, label_dir = Path(image_dir), Path(label_dir)\n",
        "\n",
        "    # Match images and labels\n",
        "    all_images = [p for p in image_dir.glob(\"*\") if p.suffix.lower() in image_exts]\n",
        "    valid_images = []\n",
        "    for img in all_images:\n",
        "        stem = img.stem.replace(\"_annotation\", \"\")\n",
        "        label_path = label_dir / f\"{stem}.txt\"\n",
        "        if label_path.exists():\n",
        "            valid_images.append((img, label_path))\n",
        "\n",
        "    if not valid_images:\n",
        "        print(f\"No valid image-label pairs found in {title}\")\n",
        "        return\n",
        "\n",
        "    selected = random.sample(valid_images, min(n, len(valid_images)))\n",
        "\n",
        "    # Create separate figure per dataset\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, (img_path, label_path) in enumerate(selected):\n",
        "        img = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(3, 4, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(img_path.name, fontsize=8)\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# RUN SEPARATE VISUALIZATIONS\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\",\n",
        "    \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\",\n",
        "    \" Fire + Smoke Dataset (COCO128)\", n=12)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/Home fire dataset/test/images\",\n",
        "    \"/content/drive/MyDrive/Home fire dataset/test/labels\",\n",
        "    \"Home Fire Test Dataset\", n=12)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/dataset 1 2/images\",\n",
        "    \"/content/drive/MyDrive/dataset 1 2/labels\",\n",
        "    \"Dataset 1_2 — Annotated Merged Dataset\", n=12)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VFdGX9kqjXU"
      },
      "source": [
        "Dataset label setup annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF77_6vG2AoF"
      },
      "outputs": [],
      "source": [
        "import os, re, random, shutil\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "\n",
        "# Naming helpers\n",
        "def clean_stem(stem: str) -> str:\n",
        "    \"\"\"Normalize filenames by removing suffixes and numeric duplicates.\"\"\"\n",
        "    s = stem\n",
        "    for suf in (\"_annotation\", \"_annotated\"):\n",
        "        while s.lower().endswith(suf):\n",
        "            s = s[: -len(suf)]\n",
        "    s = re.sub(r\"\\s*\\(\\d+\\)$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def canonicalize_folder(folder: str):\n",
        "    \"\"\"Rename messy *_annotation_annotated... files to clean versions.\"\"\"\n",
        "    root = Path(folder)\n",
        "    for p in root.glob(\"*\"):\n",
        "        if not p.is_file() or p.suffix.lower() not in (\".jpg\", \".jpeg\", \".png\", \".txt\"):\n",
        "            continue\n",
        "        new_name = f\"{clean_stem(p.stem)}{p.suffix.lower()}\"\n",
        "        target = p.with_name(new_name)\n",
        "        if target != p:\n",
        "            try:\n",
        "                if target.exists():\n",
        "                    p.unlink()\n",
        "                else:\n",
        "                    p.rename(target)\n",
        "            except Exception as e:\n",
        "                print(f\"rename skipped for {p.name}: {e}\")\n",
        "\n",
        "\n",
        "# Class Labels & Colors\n",
        "class_labels = {\n",
        "    0: \"Smoke\",\n",
        "    1: \"Fire\"\n",
        "}\n",
        "base_colors = {\n",
        "    0: (80, 80, 80),   # Smoke = gray\n",
        "    1: (255, 60, 0)    # Fire = red-orange\n",
        "}\n",
        "\n",
        "\n",
        "# YOLO parsing + drawing\n",
        "def _is_float(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def parse_label_file(label_path, w, h, default_conf=1.0):\n",
        "    \"\"\"Universal YOLO label parser for normalized or absolute coordinates.\"\"\"\n",
        "    items = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return items\n",
        "\n",
        "    with open(label_path) as f:\n",
        "        lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "    for ln in lines:\n",
        "        ln = re.sub(r\"[,;\\t]+\", \" \", ln.strip())\n",
        "        parts = ln.split()\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "\n",
        "        # --- Parse class ID or name ---\n",
        "        first = parts[0]\n",
        "        if _is_float(first):\n",
        "            cid = int(float(first))\n",
        "        else:\n",
        "            name_match = first.lower()\n",
        "            cid = next((k for k, v in class_labels.items() if v.lower().startswith(name_match)), 0)\n",
        "\n",
        "        # --- Parse coordinates ---\n",
        "        coords = list(map(float, parts[1:5]))\n",
        "        if all(0 <= c <= 1 for c in coords):\n",
        "            # normalized YOLO format\n",
        "            xc, yc, bw, bh = coords\n",
        "            x1 = int((xc - bw / 2) * w)\n",
        "            y1 = int((yc - bh / 2) * h)\n",
        "            x2 = int((xc + bw / 2) * w)\n",
        "            y2 = int((yc + bh / 2) * h)\n",
        "        else:\n",
        "            x1, y1, x2, y2 = map(int, coords)\n",
        "\n",
        "        conf = float(parts[5]) if len(parts) > 5 and _is_float(parts[5]) else default_conf\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
        "\n",
        "        items.append((cid, (x1, y1, x2, y2), conf))\n",
        "    return items\n",
        "\n",
        "\n",
        "def draw_items_on_image(img_path, items):\n",
        "    \"\"\"Draw bounding boxes and class labels on an image.\"\"\"\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    d = ImageDraw.Draw(img)\n",
        "    for cid, (x1, y1, x2, y2), conf in items:\n",
        "        color = base_colors.get(cid, (0, 255, 0))\n",
        "        d.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
        "        label = f\"{class_labels.get(cid, cid)} {conf:.2f}\"\n",
        "        tw, th = len(label) * 6, 14\n",
        "        d.rectangle([x1, y1 - th, x1 + tw + 4, y1], fill=color)\n",
        "        d.text((x1 + 2, y1 - th + 1), label, fill=(255, 255, 255))\n",
        "    return img\n",
        "\n",
        "\n",
        "# Label setup\n",
        "def ensure_label_files_exist(image_dir, label_dir):\n",
        "    \"\"\"Create empty .txt label files for missing images.\"\"\"\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    Path(label_dir).mkdir(parents=True, exist_ok=True)\n",
        "    created = 0\n",
        "    for img_path in Path(image_dir).glob(\"*\"):\n",
        "        if img_path.suffix.lower() not in image_exts:\n",
        "            continue\n",
        "        lbl_path = Path(label_dir) / f\"{clean_stem(img_path.stem)}.txt\"\n",
        "        if not lbl_path.exists():\n",
        "            lbl_path.write_text(\"\")\n",
        "            created += 1\n",
        "    print(f\"Ensured label files for {image_dir} (created {created} new empty labels).\")\n",
        "\n",
        "\n",
        "# Annotation generator\n",
        "import time\n",
        "\n",
        "def annotate_dataset(image_dir, label_dir, output_dir, title):\n",
        "    canonicalize_folder(image_dir)\n",
        "    canonicalize_folder(label_dir)\n",
        "\n",
        "    output_dir = Path(output_dir)\n",
        "    output_images = output_dir / \"images\"\n",
        "    output_labels = output_dir / \"labels\"\n",
        "    output_images.mkdir(parents=True, exist_ok=True)\n",
        "    output_labels.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    imgs = [p for p in Path(image_dir).glob(\"*\") if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")]\n",
        "    if not imgs:\n",
        "        print(f\"No images found in {image_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nAnnotating {len(imgs)} from {title}\")\n",
        "    saved, blank, errors = 0, 0, 0\n",
        "\n",
        "    for i, img in enumerate(imgs, 1):\n",
        "        try:\n",
        "            stem = clean_stem(img.stem)\n",
        "            lbl = Path(label_dir) / f\"{stem}.txt\"\n",
        "            if not lbl.exists() or lbl.stat().st_size == 0:\n",
        "                blank += 1\n",
        "                continue\n",
        "\n",
        "            im = Image.open(img).convert(\"RGB\")\n",
        "            w, h = im.size\n",
        "            items = parse_label_file(lbl, w, h)\n",
        "\n",
        "            # Skip if label empty\n",
        "            if not items:\n",
        "                blank += 1\n",
        "                im.save(output_images / f\"{stem}_annotation.jpg\")\n",
        "            else:\n",
        "                out_img = draw_items_on_image(img, items)\n",
        "                out_img.save(output_images / f\"{stem}_annotation.jpg\")\n",
        "                shutil.copy(lbl, output_labels / lbl.name)\n",
        "                saved += 1\n",
        "\n",
        "            # progress every 100 files\n",
        "            if i % 100 == 0:\n",
        "                print(f\"   Processed {i}/{len(imgs)} images so far...\")\n",
        "                time.sleep(0.1)\n",
        "\n",
        "        except Exception as e:\n",
        "            errors += 1\n",
        "            print(f\"{img.name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Saved {saved} annotated | ⚪ {blank} empty | {errors} errors | {output_dir}\")\n",
        "\n",
        "\n",
        "# Dataset definitions\n",
        "\n",
        "DATASETS = {\n",
        "    \"Home Fire (Original)\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Home fire dataset/test/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Home fire dataset/test/labels\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\"\n",
        "    },\n",
        "    \"Fire + Smoke\": {\n",
        "        \"images\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/val2017\",\n",
        "        \"labels\": \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\"\n",
        "    },\n",
        "    \"Dataset 1 2 (Merged)\": {\n",
        "        \"images\": \"/content/drive/MyDrive/dataset 1 2/images\",\n",
        "        \"labels\": \"/content/drive/MyDrive/dataset 1 2/labels\",\n",
        "        \"output\": \"/content/drive/MyDrive/fire_smoke_previews/dataset1_2_output\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Run annotation pipeline\n",
        "\n",
        "for name, cfg in DATASETS.items():\n",
        "    annotate_dataset(cfg[\"images\"], cfg[\"labels\"], cfg[\"output\"], name)\n",
        "\n",
        "print(\"\\n All datasets processed — every valid label now visualized.\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqydWhGISWVF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT8HnKRUETsk"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "img_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/images\")\n",
        "lbl_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/labels\")\n",
        "\n",
        "image_files = sorted([p.name for p in img_dir.glob(\"*.jpg\")])\n",
        "label_files = sorted([p.name for p in lbl_dir.glob(\"*.txt\")])\n",
        "\n",
        "print(f\" {len(image_files)} images | 🗒️ {len(label_files)} labels\\n\")\n",
        "\n",
        "for i, img in enumerate(image_files[:75]):\n",
        "    stem = Path(img).stem\n",
        "    has_label = any(f.startswith(stem) for f in label_files)\n",
        "    print(f\"{i+1:02d}. {img:<25}  -->  {'label found' if has_label else ' missing label'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMNP2yWZsA5s"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path, os\n",
        "lbl_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/labels\")\n",
        "\n",
        "empty = [p for p in lbl_dir.glob(\"*.txt\") if p.stat().st_size == 0]\n",
        "print(f\" Fire + Smoke: {len(empty)} empty labels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnlxY_VymiZQ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def remove_empty_or_non_numeric_txt(dirpath):\n",
        "    p = Path(dirpath)\n",
        "    removed = 0\n",
        "    for f in p.glob(\"*.txt\"):\n",
        "        txt = f.read_text().strip()\n",
        "        has_numeric = any(ln and ln[0].isdigit() for ln in txt.splitlines())\n",
        "        if (not txt) or (not has_numeric):\n",
        "            f.unlink()\n",
        "            removed += 1\n",
        "    print(f\" Removed {removed} empty/invalid txt files from {dirpath}\")\n",
        "\n",
        "remove_empty_or_non_numeric_txt(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\")\n",
        "remove_empty_or_non_numeric_txt(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4AN1GG7FfoF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "label_dir = \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/labels\"\n",
        "print(\"Number of TXT label files:\", sum(1 for f in os.listdir(label_dir) if f.endswith(\".txt\")))\n",
        "print(\"Sample label filenames:\")\n",
        "for f in sorted(os.listdir(label_dir))[:10]:\n",
        "    print(\" -\", f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5KCOOvedKoT"
      },
      "source": [
        "Now, finally calling the function to display 30 images randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ox7JnU9qj1o"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "ANNOTATED_SUFFIXES = (\"_annotated\", \"_annotation\")\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "def display_all_annotated_images(title, root_dir, per_page=30, cols=6, recursive=True):\n",
        "    \"\"\"\n",
        "    Show ALL annotated images in `root_dir`, paged `per_page` at a time.\n",
        "    Looks for files whose stem ends with _annotated or _annotation.\n",
        "    \"\"\"\n",
        "    root = Path(root_dir)\n",
        "    it = root.rglob(\"*\") if recursive else root.glob(\"*\")\n",
        "    imgs = sorted(\n",
        "        [p for p in it if p.suffix.lower() in IMG_EXTS\n",
        "         and p.stem.endswith(ANNOTATED_SUFFIXES)]\n",
        "    )\n",
        "\n",
        "    if not imgs:\n",
        "        print(f\" No annotated images found in {root_dir} (expected *{ANNOTATED_SUFFIXES}.[jpg|png]).\")\n",
        "        return\n",
        "\n",
        "    print(f\" {title}: showing {len(imgs)} annotated images from {root_dir}\")\n",
        "\n",
        "    for i in range(0, len(imgs), per_page):\n",
        "        batch = imgs[i:i+per_page]\n",
        "        rows = math.ceil(len(batch) / cols)\n",
        "        plt.figure(figsize=(3.2*cols, 3.2*rows))\n",
        "        for j, p in enumerate(batch, 1):\n",
        "            plt.subplot(rows, cols, j)\n",
        "            plt.imshow(Image.open(p))\n",
        "            plt.title(p.name, fontsize=8)\n",
        "            plt.axis(\"off\")\n",
        "        plt.suptitle(f\"{title} — {i+1}–{i+len(batch)} of {len(imgs)}\", fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "repair"
      ],
      "metadata": {
        "id": "u-XjZ1XOR_y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# FINAL FIX — Apply only to Fire + Smoke Output Folder\n",
        "labels_dir = \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/labels\"\n",
        "\n",
        "total_files, modified = 0, 0\n",
        "print(f\"Checking labels inside: {labels_dir}\")\n",
        "\n",
        "for fname in os.listdir(labels_dir):\n",
        "    if not fname.endswith(\".txt\"):\n",
        "        continue\n",
        "    path = os.path.join(labels_dir, fname)\n",
        "\n",
        "    with open(path, \"r\") as f:\n",
        "        lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "    if not lines:\n",
        "        continue\n",
        "\n",
        "    new_lines, changed = [], False\n",
        "    for ln in lines:\n",
        "        parts = ln.split()\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            cid = int(float(parts[0]))\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        # Normalize label IDs\n",
        "        if cid == 0:\n",
        "            # likely misassigned Fire → switch to Fire (1)\n",
        "            parts[0] = \"1\"\n",
        "            changed = True\n",
        "        elif cid == 1:\n",
        "            # likely misassigned Smoke → switch to Smoke (0)\n",
        "            parts[0] = \"0\"\n",
        "            changed = True\n",
        "        elif cid > 1:\n",
        "            # drop legacy class to Smoke\n",
        "            parts[0] = \"0\"\n",
        "            changed = True\n",
        "\n",
        "        new_lines.append(\" \".join(parts))\n",
        "\n",
        "    if changed:\n",
        "        with open(path, \"w\") as f:\n",
        "            f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "        modified += 1\n",
        "\n",
        "    total_files += 1\n",
        "\n",
        "print(f\"\\n Processed {total_files} files.\")\n",
        "print(f\" Updated {modified} files with corrected 0=Smoke, 1=Fire mapping.\")\n"
      ],
      "metadata": {
        "id": "i6aA6wTnRkjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re\n",
        "from pathlib import Path\n",
        "\n",
        "base_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\")\n",
        "labels_dir = base_dir / \"labels\"\n",
        "images_dir = base_dir / \"images\"\n",
        "\n",
        "\n",
        "# Remove duplicated annotated images\n",
        "\n",
        "duplicates = [p for p in images_dir.glob(\"*_annotated_annotated*\")]\n",
        "for p in duplicates:\n",
        "    try:\n",
        "        p.unlink()\n",
        "    except Exception as e:\n",
        "        print(f\" Skipped {p.name}: {e}\")\n",
        "print(f\" Removed {len(duplicates)} duplicate annotated images.\")\n",
        "\n",
        "\n",
        "# Enforce correct label mapping: 0 = Smoke, 1 = Fire\n",
        "\n",
        "fixed = 0\n",
        "for file in labels_dir.glob(\"*.txt\"):\n",
        "    lines = [ln.strip() for ln in file.read_text().splitlines() if ln.strip()]\n",
        "    new_lines = []\n",
        "    for ln in lines:\n",
        "        parts = ln.split()\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "        try:\n",
        "            cid = int(float(parts[0]))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        # Ensure valid binary labels only\n",
        "        if cid == 0:\n",
        "            parts[0] = \"0\"  # Smoke stays Smoke\n",
        "        elif cid == 1:\n",
        "            parts[0] = \"1\"  # Fire stays Fire\n",
        "        elif cid > 1:\n",
        "            parts[0] = \"0\"  # legacy → Smoke\n",
        "        new_lines.append(\" \".join(parts))\n",
        "\n",
        "    file.write_text(\"\\n\".join(new_lines) + \"\\n\")\n",
        "    fixed += 1\n",
        "\n",
        "print(f\" Updated {fixed} label files — enforced 0=Smoke, 1=Fire.\")\n",
        "\n",
        "\n",
        "# Verify counts\n",
        "count_0 = count_1 = other = 0\n",
        "for file in labels_dir.glob(\"*.txt\"):\n",
        "    for ln in file.read_text().splitlines():\n",
        "        if not ln.strip():\n",
        "            continue\n",
        "        try:\n",
        "            cid = int(float(ln.split()[0]))\n",
        "            if cid == 0:\n",
        "                count_0 += 1\n",
        "            elif cid == 1:\n",
        "                count_1 += 1\n",
        "            else:\n",
        "                other += 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "print(f\"\\n Final verification:\")\n",
        "print(f\"   0 (Smoke): {count_0}\")\n",
        "print(f\"   1 (Fire):  {count_1}\")\n",
        "print(f\"   Other IDs: {other}\")\n"
      ],
      "metadata": {
        "id": "IhdKfBk3SEFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Define directories\n",
        "base_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\")\n",
        "labels_dir = base_dir / \"labels\"\n",
        "images_dir = base_dir / \"images\"\n",
        "\n",
        "\n",
        "# Normalize filenames (remove duplicate suffixes)\n",
        "\n",
        "def normalize_name(p: Path):\n",
        "    \"\"\"Removes repeated '_annotated' suffixes or weird numbering.\"\"\"\n",
        "    new_stem = re.sub(r\"(_annotated)+$\", \"_annotation\", p.stem)\n",
        "    return p.with_name(new_stem + p.suffix)\n",
        "\n",
        "renamed = 0\n",
        "for f in list(images_dir.glob(\"*_annotated_annotated*\")) + list(images_dir.glob(\"*_annotated_annotated_annotated*\")):\n",
        "    target = normalize_name(f)\n",
        "    try:\n",
        "        if target.exists():\n",
        "            f.unlink()  # remove duplicates\n",
        "        else:\n",
        "            f.rename(target)\n",
        "            renamed += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Skip rename {f.name}: {e}\")\n",
        "print(f\" Renamed or cleaned {renamed} redundant image files.\")\n",
        "\n",
        "\n",
        "# Remove labels with no corresponding image\n",
        "\n",
        "image_stems = {p.stem for p in images_dir.glob(\"*\") if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")}\n",
        "label_stems = {p.stem for p in labels_dir.glob(\"*.txt\")}\n",
        "\n",
        "missing_labels = sorted(image_stems - label_stems)\n",
        "orphan_labels = sorted(label_stems - image_stems)\n",
        "\n",
        "for stem in orphan_labels:\n",
        "    file = labels_dir / f\"{stem}.txt\"\n",
        "    if file.exists():\n",
        "        file.unlink()\n",
        "print(f\" Removed {len(orphan_labels)} orphan label files (no matching image).\")\n",
        "\n",
        "\n",
        "# Verify all labels contain only valid classes (0=Smoke, 1=Fire)\n",
        "fixed = 0\n",
        "for file in labels_dir.glob(\"*.txt\"):\n",
        "    lines = [ln.strip() for ln in file.read_text().splitlines() if ln.strip()]\n",
        "    new_lines = []\n",
        "    for ln in lines:\n",
        "        parts = ln.split()\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "        try:\n",
        "            cid = int(float(parts[0]))\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        # Correct wrong IDs or legacy classes\n",
        "        if cid == 0:\n",
        "            parts[0] = \"0\"  # Smoke\n",
        "        elif cid == 1:\n",
        "            parts[0] = \"1\"  # Fire\n",
        "        else:\n",
        "            parts[0] = \"0\"  # Legacy → Smoke\n",
        "        new_lines.append(\" \".join(parts))\n",
        "\n",
        "    if new_lines:\n",
        "        file.write_text(\"\\n\".join(new_lines) + \"\\n\")\n",
        "        fixed += 1\n",
        "\n",
        "print(f\"Fixed {fixed} label files — enforced 0=Smoke, 1=Fire consistency.\")\n",
        "\n",
        "# Remove empty or broken label files\n",
        "empties = 0\n",
        "for file in labels_dir.glob(\"*.txt\"):\n",
        "    if not file.read_text().strip():\n",
        "        file.unlink()\n",
        "        empties += 1\n",
        "print(f\" Deleted {empties} empty or invalid label files.\")\n",
        "\n",
        "\n",
        "# Final verification — count stats\n",
        "count_0 = count_1 = other = 0\n",
        "for file in labels_dir.glob(\"*.txt\"):\n",
        "    for ln in file.read_text().splitlines():\n",
        "        if not ln.strip():\n",
        "            continue\n",
        "        try:\n",
        "            cid = int(float(ln.split()[0]))\n",
        "            if cid == 0:\n",
        "                count_0 += 1\n",
        "            elif cid == 1:\n",
        "                count_1 += 1\n",
        "            else:\n",
        "                other += 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "print(f\"\\n Final Verification Summary:\")\n",
        "print(f\"   0 (Smoke): {count_0}\")\n",
        "print(f\"   1 (Fire):  {count_1}\")\n",
        "print(f\"   Other IDs: {other}\")\n",
        "print(f\"   Total valid label files: {len(list(labels_dir.glob('*.txt')))}\")\n"
      ],
      "metadata": {
        "id": "6BOwdw3DScya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Paths\n",
        "src_base = Path(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output(OLD)\")\n",
        "src_images = src_base / \"images\"\n",
        "src_labels = src_base / \"labels\"\n",
        "\n",
        "dst_base = Path(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\")\n",
        "dst_images = dst_base / \"images\"\n",
        "dst_labels = dst_base / \"labels\"\n",
        "\n",
        "dst_images.mkdir(parents=True, exist_ok=True)\n",
        "dst_labels.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# Helper — Normalize filenames\n",
        "def normalize_stem(stem: str):\n",
        "    \"\"\"\n",
        "    Normalize filename by removing duplicate suffixes and appending '_annotation' once.\n",
        "    e.g. test_001_annotated_annotated -> test_001_annotation\n",
        "    \"\"\"\n",
        "    stem = re.sub(r\"(_annotated)+$\", \"\", stem)\n",
        "    stem = re.sub(r\"(_annotation)+$\", \"\", stem)\n",
        "    return f\"{stem}_annotation\"\n",
        "\n",
        "\n",
        "# Collect valid image–label pairs\n",
        "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "image_files = {normalize_stem(p.stem): p for p in src_images.glob(\"*\") if p.suffix.lower() in image_exts}\n",
        "label_files = {normalize_stem(p.stem): p for p in src_labels.glob(\"*.txt\")}\n",
        "\n",
        "matched = sorted(set(image_files.keys()) & set(label_files.keys()))\n",
        "print(f\" Found {len(matched)} valid image–label pairs in source folder.\")\n",
        "\n",
        "# Limit to 30 random samples\n",
        "matched = matched[:30]\n",
        "print(f\" Copying {len(matched)} image–label pairs to clean folder...\")\n",
        "\n",
        "\n",
        "# Clean & rewrite label files\n",
        "fixed = 0\n",
        "for stem in matched:\n",
        "    img_path = image_files[stem]\n",
        "    lbl_path = label_files[stem]\n",
        "\n",
        "    lines = [ln.strip() for ln in lbl_path.read_text().splitlines() if ln.strip()]\n",
        "    new_lines = []\n",
        "    for ln in lines:\n",
        "        parts = ln.split()\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "        try:\n",
        "            cid = int(float(parts[0]))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        # Enforce binary classes: 0=Smoke, 1=Fire\n",
        "        if cid == 0:\n",
        "            parts[0] = \"0\"\n",
        "        elif cid == 1:\n",
        "            parts[0] = \"1\"\n",
        "        else:\n",
        "            parts[0] = \"0\"  # any invalid class → Smoke\n",
        "\n",
        "        new_lines.append(\" \".join(parts))\n",
        "\n",
        "    if not new_lines:\n",
        "        continue\n",
        "\n",
        "\n",
        "    # Copy valid images and labels into new folder\n",
        "    new_img_name = f\"{stem}.jpg\"\n",
        "    new_lbl_name = f\"{stem}.txt\"\n",
        "\n",
        "    shutil.copy(img_path, dst_images / new_img_name)\n",
        "    (dst_labels / new_lbl_name).write_text(\"\\n\".join(new_lines) + \"\\n\")\n",
        "    fixed += 1\n",
        "\n",
        "print(f\"Copied and cleaned {fixed} valid image–label pairs to {dst_base}\")\n",
        "\n",
        "\n",
        "# Remove duplicates (if any remain)\n",
        "dups = [p for p in dst_images.glob(\"*_annotation_*.jpg\")]\n",
        "for p in dups:\n",
        "    try:\n",
        "        p.unlink()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not remove {p.name}: {e}\")\n",
        "print(f\"Removed {len(dups)} duplicate annotated images.\")\n",
        "\n",
        "\n",
        "# Final verification\n",
        "count_0 = count_1 = 0\n",
        "for lbl in dst_labels.glob(\"*.txt\"):\n",
        "    for ln in lbl.read_text().splitlines():\n",
        "        if not ln.strip():\n",
        "            continue\n",
        "        cid = int(float(ln.split()[0]))\n",
        "        if cid == 0:\n",
        "            count_0 += 1\n",
        "        elif cid == 1:\n",
        "            count_1 += 1\n",
        "\n",
        "print(f\"\\nFinal Verification Summary:\")\n",
        "print(f\"    0 (Smoke): {count_0}\")\n",
        "print(f\"    1 (Fire):  {count_1}\")\n",
        "print(f\"    Total cleaned label files: {len(list(dst_labels.glob('*.txt')))}\")\n",
        "print(f\"\\n 30 clean image–label pairs saved to: {dst_base}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6JzbBhAsTdCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "repair end"
      ],
      "metadata": {
        "id": "4bSmC7ciSBie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSceYTRWoCO4"
      },
      "outputs": [],
      "source": [
        "display_all_annotated_images(\" Fire + Smoke (annotated)\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\")\n",
        "\n",
        "display_all_annotated_images(\" Home Fire Test (annotated)\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\")\n",
        "\n",
        "display_all_annotated_images(\" Dataset 1 2 (annotated)\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/dataset1_2_output\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2XL5eBUGs61"
      },
      "source": [
        "## Dataset Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VphL1Y3eDBT"
      },
      "source": [
        "Interestingly, we found out that this dataset is not clean. i.e. labels of some of the images are missing and there are extra labels. So, we need to find out the missing labels files and remove that from the labels folder. Also, we need to find out missing images, which we also need to remove from the images folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp-MBacMgDlx"
      },
      "outputs": [],
      "source": [
        "#we already have a list of images' paths and labels' path, stored in variables : image_paths and label_paths\n",
        "print(image_paths)\n",
        "print(label_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URBrBcojgRPf"
      },
      "source": [
        "Now, we make a list of only the names of images' files and labels' files.\n",
        "\n",
        "e.g.  only  000000000531 without the extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5E_Pw6dgOMO"
      },
      "outputs": [],
      "source": [
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "\n",
        "print(image_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJKT0PFHhk5Y"
      },
      "outputs": [],
      "source": [
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd53OlLafsVP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Corrected removal loop\n",
        "for file in extra_images:\n",
        "    # Get only the filename without any folder\n",
        "    filename = os.path.basename(file)\n",
        "    image_path = os.path.join(dataset_path, \"images\", filename)\n",
        "    if os.path.exists(image_path):\n",
        "        os.remove(image_path)\n",
        "        print(f\"Removed: {image_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {image_path}\")\n",
        "\n",
        "for file in extra_labels:\n",
        "    filename = os.path.basename(file)\n",
        "    label_path = os.path.join(dataset_path, \"labels\", filename)\n",
        "    if os.path.exists(label_path):\n",
        "        os.remove(label_path)\n",
        "        print(f\"Removed: {label_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {label_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFC1RmdVhter"
      },
      "source": [
        "Now removing them from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akqYMfZJjBop"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfqxKksXihaM"
      },
      "source": [
        "Check again if it worked:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cluJu0Hqioo7"
      },
      "outputs": [],
      "source": [
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a29fd86c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7LJCLrTI_69"
      },
      "source": [
        "There are none! great!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnmYJdry2L5h"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install numpy torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbsPYfjcFigH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# YOLOv8 Fire/Smoke Trainer + Annotator (Dataset 1_2 + External Datasets)\n",
        "\n",
        "import os, sys, yaml, glob, subprocess, importlib, torch, multiprocessing, shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Utilities\n",
        "def force_numpy():\n",
        "    \"\"\"Ensure NumPy works even in limited environments.\"\"\"\n",
        "    try:\n",
        "        import numpy as np\n",
        "        _ = np.zeros((1, 1))\n",
        "        print(\" NumPy working fine.\")\n",
        "    except Exception as e:\n",
        "        print(f\" NumPy issue: {e} — reinstalling…\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"numpy\"])\n",
        "        import numpy as np\n",
        "    globals()[\"np\"] = importlib.import_module(\"numpy\")\n",
        "    return globals()[\"np\"]\n",
        "\n",
        "np = force_numpy()\n",
        "\n",
        "def ensure_dir(path: str):\n",
        "    Path(path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# Dataset Paths\n",
        "dataset_root = Path(\"/content/drive/MyDrive/fire_smoke_previews/dataset1_2_output\")\n",
        "images_train_dir = dataset_root / \"images/train\"\n",
        "labels_train_dir = dataset_root / \"labels/train\"\n",
        "\n",
        "# External datasets\n",
        "HOME_FIRE = \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/images\"\n",
        "FIRE_SMOKE = \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/images\"\n",
        "\n",
        "yaml_path = \"/content/drive/MyDrive/fire_smoke/data.yaml\"\n",
        "\n",
        "\n",
        "# Dataset Validation & Cache Cleanup\n",
        "def check_dataset(img_dir, lbl_dir):\n",
        "    \"\"\"Verify dataset integrity before training.\"\"\"\n",
        "    img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    imgs = [f for ext in img_exts for f in glob.glob(os.path.join(img_dir, f\"*{ext}\"))]\n",
        "    lbls = glob.glob(os.path.join(lbl_dir, \"*.txt\"))\n",
        "    print(f\" {Path(img_dir).name}: {len(imgs)} images | {len(lbls)} labels\")\n",
        "    return len(imgs), len(lbls)\n",
        "\n",
        "img_count, lbl_count = check_dataset(str(images_train_dir), str(labels_train_dir))\n",
        "\n",
        "# Clear YOLO cache safely\n",
        "for cache_file in [labels_train_dir / \"train.cache\", dataset_root / \"labels.cache\"]:\n",
        "    if cache_file.exists():\n",
        "        os.remove(cache_file)\n",
        "        print(f\"Removed cache file: {cache_file}\")\n",
        "print(\" YOLO cache cleanup completed.\")\n",
        "\n",
        "if img_count == 0:\n",
        "    print(\" No images found in dataset path. Please check your folders.\")\n",
        "elif lbl_count == 0:\n",
        "    print(\" No labels found in dataset path. Please verify labeling.\")\n",
        "elif img_count != lbl_count:\n",
        "    print(\" Mismatch between image and label count — some files may be missing.\")\n",
        "else:\n",
        "    print(\" Dataset validated and balanced.\")\n",
        "\n",
        "\n",
        "# YAML File (YOLO expects direct paths)\n",
        "os.makedirs(os.path.dirname(yaml_path), exist_ok=True)\n",
        "\n",
        "yaml_config = {\n",
        "    # Main dataset\n",
        "    \"train\": str(images_train_dir),\n",
        "    \"val\": str(images_train_dir),  # reuse train if val missing\n",
        "    \"nc\": 2,\n",
        "    \"names\": {0: \"Smoke\", 1: \"Fire\"},\n",
        "\n",
        "    # Add external datasets (for extra evaluation or prediction)\n",
        "    \"additional_sets\": {\n",
        "        \"HOME_FIRE\": HOME_FIRE,\n",
        "        \"FIRE_SMOKE\": FIRE_SMOKE\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(yaml_config, f, sort_keys=False)\n",
        "\n",
        "print(f\" Dataset YAML created → {yaml_path}\")\n",
        "\n",
        "print(\"\"\"\n",
        " Corrected YOLO Folder Layout:\n",
        "fire_smoke_previews/\n",
        "├── dataset1_2_output/\n",
        "│   ├── images/train/\n",
        "│   ├── labels/train/\n",
        "├── home_fire_output/images/\n",
        "├── fire_and_smoke_output/images/\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# Verify with Ultralytics internal check\n",
        "print(\"🔍 Running YOLO internal dataset check...\")\n",
        "try:\n",
        "    check_det_dataset(yaml_path)\n",
        "    print(\" YOLO verified dataset successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(\" YOLO dataset check failed:\")\n",
        "    print(e)\n",
        "    raise SystemExit(\"Stopping training — please verify dataset paths.\")\n",
        "\n",
        "\n",
        "# System Info\n",
        "import ultralytics\n",
        "print(f\"\\n YOLOv8 version: {ultralytics.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA detected: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Running on CPU only — this may be slower.\")\n",
        "\n",
        "\n",
        "# Training (Final Clean Run)\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "train_args = dict(\n",
        "    data=yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=416,\n",
        "    batch=4,\n",
        "    workers=0,\n",
        "    name=\"fire_smoke_yolov8n_dataset1_2_final_with_external\"\n",
        ")\n",
        "\n",
        "print(\"\\n Starting YOLOv8 training on unified Dataset 1_2 + external data...\")\n",
        "results = model.train(**train_args)\n",
        "print(\"\\n Training completed successfully.\")\n",
        "\n",
        "\n",
        "# Post-Training Evaluation\n",
        "print(\"\\n🔍 Running model validation on trained weights...\")\n",
        "model.val(data=yaml_path, split=\"val\")\n",
        "\n",
        "\n",
        "# Optional — Visualization of Random Predictions\n",
        "OUTPUT_BASE = Path(\"/content/drive/MyDrive/fire_smoke_previews/predictions_v83_dataset1_2_final\")\n",
        "ensure_dir(OUTPUT_BASE)\n",
        "\n",
        "print(\"\\n Generating example predictions...\")\n",
        "model.predict(\n",
        "    source=str(images_train_dir),\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    conf=0.25,\n",
        "    project=str(OUTPUT_BASE),\n",
        "    name=\"sample_preds\"\n",
        ")\n",
        "\n",
        "# Additional predictions for HOME_FIRE & FIRE_SMOKE datasets\n",
        "for external_name, external_path in {\"HOME_FIRE\": HOME_FIRE, \"FIRE_SMOKE\": FIRE_SMOKE}.items():\n",
        "    print(f\"\\n Running predictions for {external_name} dataset...\")\n",
        "    model.predict(\n",
        "        source=external_path,\n",
        "        save=True,\n",
        "        save_txt=True,\n",
        "        conf=0.25,\n",
        "        project=str(OUTPUT_BASE),\n",
        "        name=f\"preds_{external_name.lower()}\"\n",
        "    )\n",
        "\n",
        "print(\"\\n Predictions saved under:\", OUTPUT_BASE)\n",
        "\n",
        "\n",
        "# Save trained model weights permanently to Google Drive\n",
        "best_weight_path = Path(model.trainer.save_dir) / \"weights\" / \"best.pt\"\n",
        "last_weight_path = Path(model.trainer.save_dir) / \"weights\" / \"last.pt\"\n",
        "\n",
        "print(f\"\\n Best model weights located at: {best_weight_path}\")\n",
        "print(f\" Last checkpoint located at: {last_weight_path}\")\n",
        "\n",
        "final_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/models\")\n",
        "final_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "final_pt_path = final_dir / \"best_fire_smoke_yolov8n_dataset1_2.pt\"\n",
        "shutil.copy(best_weight_path, final_pt_path)\n",
        "\n",
        "print(f\" Copied best model weights to Google Drive → {final_pt_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "debug"
      ],
      "metadata": {
        "id": "zt4i8RyV3Wtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os, glob, shutil\n",
        "# from pathlib import Path\n",
        "# from ultralytics import YOLO\n",
        "# from ultralytics.data.utils import check_det_dataset\n",
        "# import yaml, multiprocessing, torch\n",
        "\n",
        "\n",
        "# #  Merge all datasets into a unified training folder\n",
        "\n",
        "# # Source roots\n",
        "# sources = [\n",
        "#     \"/content/drive/MyDrive/fire_smoke_previews/dataset1_2_output/images/train\",\n",
        "#     \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/images\",\n",
        "#     \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/images\"\n",
        "# ]\n",
        "\n",
        "# labels_sources = [\n",
        "#     \"/content/drive/MyDrive/fire_smoke_previews/dataset1_2_output/labels/train\",\n",
        "#     \"/content/drive/MyDrive/Home fire dataset/test/labels\",  # optional\n",
        "#     \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/labels/val\"\n",
        "# ]\n",
        "\n",
        "# # Destination\n",
        "# final_root = Path(\"/content/drive/MyDrive/fire_smoke_previews/final_merged_dataset\")\n",
        "# img_dst = final_root / \"images/train\"\n",
        "# lbl_dst = final_root / \"labels/train\"\n",
        "# img_dst.mkdir(parents=True, exist_ok=True)\n",
        "# lbl_dst.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# # Copy function\n",
        "# def copy_pairs(img_dir, lbl_dir, dst_img, dst_lbl):\n",
        "#     count = 0\n",
        "#     img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "#     for img_path in glob.glob(os.path.join(img_dir, \"*\")):\n",
        "#         if not img_path.lower().endswith(img_exts):\n",
        "#             continue\n",
        "#         name = Path(img_path).stem\n",
        "#         lbl_path = os.path.join(lbl_dir, f\"{name}.txt\")\n",
        "#         if os.path.exists(lbl_path):\n",
        "#             shutil.copy(img_path, dst_img / Path(img_path).name)\n",
        "#             shutil.copy(lbl_path, dst_lbl / Path(lbl_path).name)\n",
        "#             count += 1\n",
        "#     return count\n",
        "\n",
        "# total = 0\n",
        "# for imgs, lbls in zip(sources, labels_sources):\n",
        "#     if os.path.exists(imgs) and os.path.exists(lbls):\n",
        "#         added = copy_pairs(imgs, lbls, img_dst, lbl_dst)\n",
        "#         print(f\" Copied {added} pairs from {imgs}\")\n",
        "#         total += added\n",
        "#     else:\n",
        "#         print(f\" Skipped invalid source: {imgs}\")\n",
        "\n",
        "# print(f\"\\n Merged total of {total} image/label pairs into {final_root}\")\n",
        "\n",
        "\n",
        "# # Prepare YAML\n",
        "# yaml_path = \"/content/drive/MyDrive/fire_smoke_previews/final_merged_dataset/data.yaml\"\n",
        "\n",
        "# yaml_config = {\n",
        "#     \"train\": str(final_root / \"images/train\"),\n",
        "#     \"val\": str(final_root / \"images/train\"),\n",
        "#     \"nc\": 2,\n",
        "#     \"names\": {0: \"Smoke\", 1: \"Fire\"}\n",
        "# }\n",
        "\n",
        "# with open(yaml_path, \"w\") as f:\n",
        "#     yaml.safe_dump(yaml_config, f)\n",
        "# print(f\" YAML written to {yaml_path}\")\n",
        "\n",
        "\n",
        "# # Verify dataset\n",
        "# print(\"🔍 Running YOLO dataset check...\")\n",
        "# check_det_dataset(yaml_path)\n",
        "# print(\" Dataset verified.\")\n",
        "\n",
        "\n",
        "# # Train YOLOv8\n",
        "# multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "# model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# train_args = dict(\n",
        "#     data=yaml_path,\n",
        "#     epochs=10,\n",
        "#     imgsz=416,\n",
        "#     batch=4,\n",
        "#     workers=0,\n",
        "#     name=\"fire_smoke_final_merged_training\"\n",
        "# )\n",
        "\n",
        "# print(\"\\n Training YOLOv8 on merged dataset...\")\n",
        "# results = model.train(**train_args)\n",
        "# print(\"\\n Training finished successfully!\")\n",
        "\n",
        "\n",
        "# # Save trained weights\n",
        "\n",
        "# best_pt = Path(model.trainer.save_dir) / \"weights\" / \"best.pt\"\n",
        "# final_model_dir = Path(\"/content/drive/MyDrive/fire_smoke_previews/models\")\n",
        "# final_model_dir.mkdir(parents=True, exist_ok=True)\n",
        "# shutil.copy(best_pt, final_model_dir / \"best_fire_smoke_merged.pt\")\n",
        "# print(f\" Best model saved to {final_model_dir/'best_fire_smoke_merged.pt'}\")\n"
      ],
      "metadata": {
        "id": "z00cIu976Y1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "debug finish"
      ],
      "metadata": {
        "id": "L8IrVSZf3rFm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QA7O9_88drP"
      },
      "outputs": [],
      "source": [
        "\n",
        "#  YOLOv8 Fire/Smoke Visualization Matrix (Post-Training v8.3)\n",
        "\n",
        "\n",
        "import os, glob, shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Model and Dataset Paths\n",
        "MODEL_PATH = \"/content/drive/MyDrive/fire_smoke_previews/models/best_fire_smoke_yolov8n_dataset1_2.pt\"\n",
        "  #  update if saved elsewhere\n",
        "OUTPUT_BASE = \"/content/drive/MyDrive/fire_smoke_previews/predictions_matrix_v83\"\n",
        "\n",
        "DATASETS = {\n",
        "    \"TRAIN\": \"/content/drive/MyDrive/dataset 1/images/train\",\n",
        "    \"VAL\": \"/content/drive/MyDrive/dataset 2/images/val\",\n",
        "    \"HOME_FIRE\": \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/images\",\n",
        "    \"FIRE_SMOKE\": \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/images\"\n",
        "}\n",
        "\n",
        "def ensure_dir(p): Path(p).mkdir(parents=True, exist_ok=True)\n",
        "ensure_dir(OUTPUT_BASE)\n",
        "\n",
        "\n",
        "#  Load Model\n",
        "\n",
        "model = YOLO(MODEL_PATH)\n",
        "print(f\" Loaded trained model → {MODEL_PATH}\")\n",
        "\n",
        "\n",
        "# Run Predictions & Save Outputs\n",
        "def predict_and_save(model, img_dir, out_root, conf=0.25):\n",
        "    \"\"\"Predict on dataset, save annotated JPGs and YOLO TXT labels.\"\"\"\n",
        "    img_dir, out_root = Path(img_dir), Path(out_root)\n",
        "    out_images, out_labels = out_root / \"images\", out_root / \"labels\"\n",
        "    ensure_dir(out_images); ensure_dir(out_labels)\n",
        "\n",
        "    print(f\"\\n Predicting on → {img_dir.name}\")\n",
        "    for img_path in img_dir.glob(\"*.jpg\"):\n",
        "        results = model.predict(source=str(img_path), save=True, save_txt=True, conf=conf)\n",
        "        ann_src = Path(results[0].save_dir) / img_path.name\n",
        "        ann_dst = out_images / f\"{img_path.stem}_annotated.jpg\"\n",
        "        if ann_src.exists():\n",
        "            shutil.move(str(ann_src), ann_dst)\n",
        "        pred_txt = Path(results[0].save_dir) / \"labels\" / f\"{img_path.stem}.txt\"\n",
        "        if pred_txt.exists():\n",
        "            shutil.move(str(pred_txt), out_labels / f\"{img_path.stem}.txt\")\n",
        "    print(f\" Annotated predictions saved in: {out_root}\")\n",
        "\n",
        "for name, img_dir in DATASETS.items():\n",
        "    predict_and_save(model, img_dir, Path(OUTPUT_BASE) / name.lower())\n",
        "\n",
        "\n",
        "# Visual Preview Inline\n",
        "preview_dirs = [f\"{OUTPUT_BASE}/{n.lower()}/images\" for n in DATASETS.keys()]\n",
        "samples = []\n",
        "for d in preview_dirs:\n",
        "    samples += glob.glob(os.path.join(d, \"*_annotated.jpg\"))[:2]\n",
        "\n",
        "if samples:\n",
        "    plt.figure(figsize=(16,10))\n",
        "    for i, path in enumerate(samples):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(2,4,i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(Path(path).parent.parent.name + \" – \" + Path(path).name)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\" No annotated images found for preview.\")\n",
        "\n",
        "print(f\"\"\"\n",
        " Visualization complete!\n",
        " All predictions saved under:\n",
        "{OUTPUT_BASE}/\n",
        "├── train/\n",
        "├── val/\n",
        "├── home_fire/\n",
        "└── fire_smoke/\n",
        "\"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate YOLOv8 Fire/Smoke Model & Visualize Confusion Matrix\n",
        "\n",
        "\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"\\n Evaluating trained model and generating confusion matrix...\")\n",
        "\n",
        "\n",
        "# Load Best Model\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/fire_smoke_previews/models/best_fire_smoke_yolov8n_dataset1_2.pt\"  # Updated path\n",
        "DATA_YAML = \"/content/drive/MyDrive/fire_smoke/data.yaml\"\n",
        "\n",
        "assert os.path.exists(MODEL_PATH), f\" Model not found at {MODEL_PATH}\"\n",
        "assert os.path.exists(DATA_YAML), f\" Dataset YAML not found at {DATA_YAML}\"\n",
        "\n",
        "model = YOLO(MODEL_PATH)\n",
        "print(f\" Loaded trained model → {MODEL_PATH}\")\n",
        "\n",
        "\n",
        "# Validate Model (Generate Metrics + Confusion Matrix)\n",
        "results = model.val(data=DATA_YAML, conf=0.25, imgsz=416)\n",
        "print(\"\\n Validation complete — extracting metrics...\")\n",
        "\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "try:\n",
        "    cm = results.confusion_matrix.matrix  # (num_classes x num_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, cmap=\"Reds\")\n",
        "    plt.title(\"Fire & Smoke Detection — Confusion Matrix\", fontsize=14)\n",
        "    plt.xlabel(\"Predicted Label\", fontsize=12)\n",
        "    plt.ylabel(\"True Label\", fontsize=12)\n",
        "    plt.colorbar(label=\"Count\")\n",
        "    plt.xticks(\n",
        "        ticks=np.arange(len(results.names)),\n",
        "        labels=list(results.names.values()),\n",
        "        rotation=45\n",
        "    )\n",
        "    plt.yticks(\n",
        "        ticks=np.arange(len(results.names)),\n",
        "        labels=list(results.names.values())\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Could not plot confusion matrix:\", e)\n",
        "\n",
        "\n",
        "# Print Summary Metrics\n",
        "print(\"\\n Evaluation Summary:\")\n",
        "try:\n",
        "    p = float(np.mean(results.box.p)) if hasattr(results.box, \"p\") else results.metrics.get(\"precision\", 0)\n",
        "    r = float(np.mean(results.box.r)) if hasattr(results.box, \"r\") else results.metrics.get(\"recall\", 0)\n",
        "    map50 = float(np.mean(results.box.map50)) if hasattr(results.box, \"map50\") else results.metrics.get(\"map50\", 0)\n",
        "    map95 = float(np.mean(results.box.map)) if hasattr(results.box, \"map\") else results.metrics.get(\"map\", 0)\n",
        "    print(f\"Precision: {p:.3f}\")\n",
        "    print(f\"Recall:    {r:.3f}\")\n",
        "    print(f\"mAP50:     {map50:.3f}\")\n",
        "    print(f\"mAP50-95:  {map95:.3f}\")\n",
        "except Exception as e:\n",
        "    print(\" Could not summarize metrics:\", e)\n",
        "    print(results)\n",
        "\n",
        "print(\"\\n Confusion matrix and evaluation summary complete.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0k22EVXkmZPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# YOLOv8 Fire/Smoke Training Loss Curves (Indexed Epochs)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Automatically locate the latest YOLO run folder\n",
        "runs_dir = Path(\"/content/runs/detect\")\n",
        "latest_run = max(runs_dir.glob(\"fire_smoke_yolov8n_dataset1_2_final_with_external*\"), key=os.path.getmtime)\n",
        "results_path = latest_run / \"results.csv\"\n",
        "\n",
        "# Confirm path\n",
        "print(f\" Using training log: {results_path}\")\n",
        "\n",
        "# Load YOLO training log\n",
        "df = pd.read_csv(results_path)\n",
        "\n",
        "# Add 1-based epoch index\n",
        "df[\"epoch_index\"] = df.index + 1\n",
        "\n",
        "\n",
        "# Plot Overall Training & Validation Losses\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df[\"epoch_index\"], df[\"train/box_loss\"], label=\"Train Box Loss\")\n",
        "plt.plot(df[\"epoch_index\"], df[\"train/cls_loss\"], label=\"Train Class Loss\")\n",
        "plt.plot(df[\"epoch_index\"], df[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\")\n",
        "plt.plot(df[\"epoch_index\"], df[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\")\n",
        "plt.title(\" Fire & Smoke Detection — YOLOv8 Training Losses\", fontsize=14)\n",
        "plt.xlabel(\"Epoch (1-indexed)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save loss plot to Drive\n",
        "loss_path = \"/content/drive/MyDrive/fire_smoke_previews/predictions_matrix_v83/training_losses.png\"\n",
        "plt.savefig(loss_path, dpi=300)\n",
        "print(f\"Saved loss curves → {loss_path}\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot Precision, Recall, and mAP50 Trends\n",
        "metrics = [\"metrics/precision(B)\", \"metrics/recall(B)\", \"metrics/mAP50(B)\", \"metrics/mAP50-95(B)\"]\n",
        "available = [m for m in metrics if m in df.columns]\n",
        "\n",
        "if available:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for metric in available:\n",
        "        plt.plot(df[\"epoch_index\"], df[metric], label=metric.replace(\"metrics/\", \"\"))\n",
        "    plt.title(\" Precision, Recall & mAP Progress (YOLOv8)\", fontsize=14)\n",
        "    plt.xlabel(\"Epoch (1-indexed)\")\n",
        "    plt.ylabel(\"Metric Value\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    metric_path = \"/content/drive/MyDrive/fire_smoke_previews/predictions_matrix_v83/training_metrics.png\"\n",
        "    plt.savefig(metric_path, dpi=300)\n",
        "    print(f\" Saved metric trends → {metric_path}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\" No metric columns found in results.csv — precision/recall may not have logged.\")\n"
      ],
      "metadata": {
        "id": "8XSeeEBbpd-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-oVT-0tbRCf"
      },
      "source": [
        "after training, all of the precision confusion matrix and everything, check to see if results are satisfactory"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcvancity2022/Computer-Vision-Project-Overview/blob/main/Week_6(TrainingworkBaseCode).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvIx0KGWlPtp"
      },
      "source": [
        "<center><h1> <b>Image Dataset Analysis and Project Development with YOLO </b> </center> </h1>\n",
        "\n",
        "In this tutorial, we will see how image datasets with different types of tasks such as detection , segmentation etc. look like, and how they are labelled, specifically in YOLO format.\n",
        "\n",
        "Then, we will download one dataset to explore it and clean it if required.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLUWE8gn9_RB"
      },
      "source": [
        "## **Classification**\n",
        "\n",
        "Image classification is the simplest and involves classifying an entire image into one of a set of predefined classes.\n",
        "\n",
        "The output of an image classifier is a single class label and a confidence score. Image classification is useful when you need to know only what class an image belongs to and don't need to know where objects of that class are located or what their exact shape is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSkOCZxt-ZAO"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418606-adf35c62-2e11-405d-84c6-b84e7d013804.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OstzhA30B2tK"
      },
      "source": [
        "Usually each image has a single object in it, which is its class> Following image shows CIFAR10 Dataset.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://datagen.tech/wp-content/uploads/2022/11/image1.png\" width=\"600\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcIc5sJBCx2S"
      },
      "source": [
        "The dataset should be labelled by arranging them in the following folders heirarchy.\n",
        "\n",
        "              root/\n",
        "              |-- class1/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class2/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class3/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- ...\n",
        "\n",
        "In this folder structure, the root directory contains one subdirectory for each class in the dataset. Each subdirectory is named after the corresponding class and contains all the images for that class.\n",
        "\n",
        "For example:\n",
        "\n",
        "              cifar-10-/\n",
        "              |\n",
        "              |-- train/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10008_airplane.png\n",
        "              |   |   |-- 10009_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 1000_automobile.png\n",
        "              |   |   |-- 1001_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 10014_bird.png\n",
        "              |   |   |-- 10015_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- test/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10_airplane.png\n",
        "              |   |   |-- 11_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 100_automobile.png\n",
        "              |   |   |-- 101_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 1000_bird.png\n",
        "              |   |   |-- 1001_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTjx8pXEB1B5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cZ9e5J4zvF9"
      },
      "source": [
        "## **Object Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52PMPO-rgZq-"
      },
      "source": [
        "Object detection is a task that involves identifying the location and class of objects in an image or video stream.\n",
        "\n",
        "The output of an object detector is a set of bounding boxes that enclose the objects in the image, along with class labels and confidence scores for each box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDruPnQMi315"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418624-5785cb93-74c9-4541-9179-d5c6782d491a.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFz-X3Zx1xKn"
      },
      "source": [
        "**Labelling format**\n",
        "\n",
        "In object detection tasks, various labeling formats are used to annotate images with information about the objects present. These formats typically include details about the object's class and location within the image. Here are some of the most common labeling formats:\n",
        "\n",
        "1. COCO\n",
        "2. YOLO\n",
        "3. CSV  \n",
        "5. XML\n",
        "6. PASCAL VOC\n",
        "\n",
        "We will be discussing only YOLO format, as you will be using YOLO framework for your project:\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "\n",
        "      class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "- Box coordinates must be normalized between 0 and 1\n",
        "\n",
        "\n",
        "An example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6es7DWt75YTf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/91506361-c7965000-e886-11ea-8291-c72b98c25eec.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDeb1gEM5uIT"
      },
      "source": [
        "Corresponding label text file should look like:\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/112467037-d2568c00-8d66-11eb-8796-55402ac0d62f.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0brGPZa4oRk7"
      },
      "source": [
        "## **Segmentation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56IDqcG6mNw"
      },
      "source": [
        "Instance segmentation goes a step further than object detection and involves identifying individual objects in an image and segmenting them from the rest of the image.\n",
        "\n",
        "The output of an instance segmentation model is a set of masks or contours that outline each object in the image, along with class labels and confidence scores for each object. Instance segmentation is useful when you need to know not only where objects are in an image, but also what their exact shape is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oItmHrqo8qLM"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418644-7df320b8-098d-47f1-85c5-26604d761286.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2C24Fz389GY"
      },
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - bounding coordinates: The bounding coordinates around the mask area, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "      <class-index> <x1> <y1> <x2> <y2> ... <xn> <yn>\n",
        "\n",
        "\n",
        "Here is an example of the YOLO dataset format for a single image with two objects made up of a 3-point segment and a 5-point segment.\n",
        "\n",
        "\n",
        "      0 0.681 0.485 0.670 0.487 0.676 0.487\n",
        "      1 0.504 0.000 0.501 0.004 0.498 0.004 0.493 0.010 0.492 0.0104\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPFHkCO8-2mW"
      },
      "source": [
        "## **Pose Estimation**\n",
        "Pose estimation is a task that involves identifying the location of specific points in an image, usually referred to as keypoints. The keypoints can represent various parts of the object such as joints, landmarks, or other distinctive features. The locations of the keypoints are usually represented as a set of 2D [x, y] or 3D [x, y, visible] coordinates.\n",
        "\n",
        "The output of a pose estimation model is a set of points that represent the keypoints on an object in the image, usually along with the confidence scores for each point. Pose estimation is a good choice when you need to identify specific parts of an object in a scene, and their location in relation to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zebzQ_Z6_CB9"
      },
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418616-9811ac0b-a4a7-452a-8aba-484ba32bb4a8.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9M4kU8P_QWU"
      },
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - Object class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - Object center coordinates: The x and y coordinates of the center of the object, normalized to be between 0 and 1.\n",
        "  - Object width and height: The width and height of the object, normalized to be between 0 and 1.\n",
        "  - Object keypoint coordinates: The keypoints of the object, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "Here is an example of the label format for pose estimation task:\n",
        "\n",
        "Format with Dim = 2\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <px2> <py2> ... <pxn> <pyn>\n",
        "Format with Dim = 3\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <p1-visibility> <px2> <py2> <p2-visibility> ... <pxn> <pyn> <p2-visibility>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jCdTqcVbN4h"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsAvGgxxHAS3"
      },
      "source": [
        "## FOLDERS HEIRARCHY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt4h9bFXjV9V"
      },
      "source": [
        "\n",
        "\n",
        " We need to convert the dataset into a specific heirarchy of folders for all the tasks except for task of classification.\n",
        "\n",
        "\n",
        "The directories should be in the following format:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKyjblYvb8fW"
      },
      "source": [
        "# **COCO128 Dataset**\n",
        "\n",
        "This section aims to introduce you to COCO dataset frequently used in Artificial Intelligence (AI).It is a foundational dataset in AI, widely used for tasks like object detection, segmentation, and image captioning.\n",
        "\n",
        "\n",
        "It Contains over 330,000 images with more than 200,000 labeled across 80 object categories. Unique for its richly annotated images, including object segmentation.It is widely used in computer vision research and has been used to train and evaluate many state-of-the-art object detection and segmentation models.\n",
        "\n",
        "Link to full dataset: https://cocodataset.org/#home\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G11PH4xOo8zO"
      },
      "source": [
        "We are going using coco128 dataset.This dataset contains the first 128 images of COCO train 2017. It is used as the tutorial dataset for YOLO.\n",
        "\n",
        "Download the dataset from:\n",
        "https://www.kaggle.com/datasets/ultralytics/coco128/data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DUeZCUkSwkG"
      },
      "source": [
        "## Dataset Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJe53Fzd1mZn"
      },
      "source": [
        "\n",
        "To draw bounding boxes on images we need to understand the labelling format used by this dataset. The labels for this dataset are stored in YOLO format. i.e.\n",
        "\n",
        "        class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvPN5o_jSKgK"
      },
      "source": [
        "The class_id is the numerical number assigned to different class labels as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qry8OPsHG3GK"
      },
      "outputs": [],
      "source": [
        "# Only fire and smoke classes\n",
        "class_labels = {\n",
        "    0: \"Fire\",   # originally \"Smoke\" if your labels are swapped\n",
        "    1: \"Smoke\"   # originally \"Fire\" if your labels are swapped\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8tH0PySW4n"
      },
      "source": [
        "The rest of the four values i.e.\n",
        "\n",
        "    0.479492 0.688771 0.955609 0.5955\n",
        "\n",
        "indidicate the location of the bounding box.\n",
        "\n",
        "These values are normalized, which should be converted to a format that can be used as coordinate values of rectangle function (of cv2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQbCyFCMaueA"
      },
      "source": [
        "First import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoPPaZu5a4Fp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEcvixvYa-A8"
      },
      "source": [
        "Set all the paths of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xS3INAjbPTr"
      },
      "outputs": [],
      "source": [
        "# Set the path to the dataset\n",
        "dataset_path = \"/content/drive/MyDrive/Home fire dataset/test\"\n",
        "\n",
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "print (image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpP4yE5-sitI"
      },
      "source": [
        "\n",
        "\n",
        "Set all the paths of the dataset of Fire and Smoke:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrVyXbVushbR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_root = \"/content/drive/MyDrive/Fire_and_Smoke_BBox_COCO_Dateset/coco128\"\n",
        "annotations_json = os.path.join(dataset_root, \"annotations\", \"instances_val2017.json\")\n",
        "\n",
        "# Check if JSON exists\n",
        "if os.path.exists(annotations_json):\n",
        "    print(f\"‚úÖ JSON found at: {annotations_json}\")\n",
        "else:\n",
        "    print(f\"‚ùå JSON NOT found! Current working dir: {os.getcwd()}\")\n",
        "    # List contents of dataset_root to see folder names\n",
        "    print(\"Contents of dataset_root:\", os.listdir(dataset_root))\n",
        "    # List contents of annotations folder\n",
        "    annotations_folder = os.path.join(dataset_root, \"annotations\")\n",
        "    if os.path.exists(annotations_folder):\n",
        "        print(\"Contents of annotations folder:\", os.listdir(annotations_folder))\n",
        "    else:\n",
        "        print(\"Annotations folder not found!\")\n",
        "\n",
        "dataset_root = \"Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    for file in files:\n",
        "        if file.endswith(\".json\"):\n",
        "            print(\"Found JSON:\", os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZFQeneewaFY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Dataset Paths ‚Äî Auto Setup\n",
        "# ============================================================\n",
        "dataset_root = \"/content/drive/MyDrive/Fire_and_Smoke_BBox_COCO_Dateset/coco128\"\n",
        "\n",
        "images_dir = os.path.join(dataset_root, \"train2017\")\n",
        "annotations_dir = os.path.join(dataset_root, \"annotations\")\n",
        "json_file = os.path.join(annotations_dir, \"instances_train2017.json\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\", \"train\")\n",
        "\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# Sanity checks\n",
        "if not os.path.exists(images_dir):\n",
        "    raise FileNotFoundError(f\"‚ùå Image folder missing: {images_dir}\")\n",
        "if not os.path.exists(json_file):\n",
        "    raise FileNotFoundError(f\"‚ùå COCO JSON not found: {json_file}\")\n",
        "\n",
        "print(f\"‚úÖ Image path: {images_dir}\")\n",
        "print(f\"‚úÖ JSON file:  {json_file}\")\n",
        "print(f\"‚úÖ Output dir: {labels_dir}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Load COCO JSON\n",
        "# ============================================================\n",
        "with open(json_file, \"r\") as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "# Validate COCO structure\n",
        "required_keys = {\"images\", \"annotations\", \"categories\"}\n",
        "if not required_keys.issubset(coco.keys()):\n",
        "    raise ValueError(f\"‚ùå Invalid COCO structure. Missing keys: {required_keys - set(coco.keys())}\")\n",
        "\n",
        "# Map image_id ‚Üí filename and size\n",
        "img_id2file = {img['id']: img['file_name'] for img in coco['images']}\n",
        "img_id2size = {img['id']: (img['width'], img['height']) for img in coco['images']}\n",
        "\n",
        "# Group annotations per image\n",
        "img_annotations = defaultdict(list)\n",
        "for ann in coco['annotations']:\n",
        "    if ann.get('bbox') and ann['bbox'][2] > 0 and ann['bbox'][3] > 0:\n",
        "        img_annotations[ann['image_id']].append(ann)\n",
        "\n",
        "print(f\"üìä Total images in JSON:      {len(img_id2file)}\")\n",
        "print(f\"üìä Images with annotations:   {len(img_annotations)}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Convert COCO ‚Üí YOLO format\n",
        "# ============================================================\n",
        "for img_id, anns in tqdm(img_annotations.items(), desc=\"Converting COCO ‚Üí YOLO TXT\"):\n",
        "    img_name = img_id2file[img_id]\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    txt_path = os.path.join(labels_dir, Path(img_name).stem + \".txt\")\n",
        "\n",
        "    # Retrieve image dimensions\n",
        "    if os.path.exists(img_path):\n",
        "        try:\n",
        "            with Image.open(img_path) as im:\n",
        "                w, h = im.size\n",
        "        except Exception:\n",
        "            w, h = img_id2size.get(img_id, (640, 480))\n",
        "    else:\n",
        "        w, h = img_id2size.get(img_id, (640, 480))\n",
        "\n",
        "    # Write YOLO annotation file\n",
        "    with open(txt_path, \"w\") as f:\n",
        "        for ann in anns:\n",
        "            cid = ann[\"category_id\"] - 1  # COCO is 1-indexed\n",
        "            x_min, y_min, box_w, box_h = ann[\"bbox\"]\n",
        "\n",
        "            if box_w <= 0 or box_h <= 0:\n",
        "                continue\n",
        "\n",
        "            x_center = (x_min + box_w / 2) / w\n",
        "            y_center = (y_min + box_h / 2) / h\n",
        "            width_norm = box_w / w\n",
        "            height_norm = box_h / h\n",
        "\n",
        "            f.write(f\"{cid} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Verify results (no display)\n",
        "# ============================================================\n",
        "txt_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
        "if not txt_files:\n",
        "    raise RuntimeError(\"‚ùå No YOLO .txt labels were generated. Check your JSON data.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Successfully created {len(txt_files)} YOLO label files.\")\n",
        "\n",
        "print(\"üéØ Conversion complete. All annotations exported cleanly.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5FKTOKTjNiS"
      },
      "outputs": [],
      "source": [
        "import os, random, time\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Dataset Paths\n",
        "# ============================================================\n",
        "dataset_root = \"/content/drive/MyDrive/Fire_and_Smoke_BBox_COCO_Dateset/coco128\"\n",
        "images_dir = os.path.join(dataset_root, \"train2017\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\", \"train\")\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Base Class Labels and Colors\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"üî• Fire\",\n",
        "    1: \"üí® Serious Smoke\",\n",
        "    2: \"üå´Ô∏è Moderate Smoke\",\n",
        "    3: \"‚òÅÔ∏è Mild Smoke\",\n",
        "    4: \"üíß Steam / False Alarm\",\n",
        "    5: \"üö´ Non-Fire Smoke\",\n",
        "    6: \"üïØÔ∏è Incense / Non-Threat Smoke\"\n",
        "}\n",
        "\n",
        "base_colors = {\n",
        "    0: (255, 60, 0),     # Fire\n",
        "    1: (40, 40, 40),     # Serious Smoke\n",
        "    2: (180, 100, 20),   # Moderate Smoke\n",
        "    3: (255, 220, 50),   # Mild Smoke\n",
        "    4: (150, 150, 150),  # Steam\n",
        "    5: (200, 200, 200),  # Non-fire Smoke\n",
        "    6: (130, 200, 255)   # Incense\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ YOLO ‚Üí BBox\n",
        "# ============================================================\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5: return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc*w, yc*h, bw*w, bh*h\n",
        "    return int(cid), (int(xc-bw/2), int(yc-bh/2), int(xc+bw/2), int(yc+bh/2))\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Analyze Brightness and Contrast\n",
        "# ============================================================\n",
        "def analyze_visibility(img, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean)/(3*255)\n",
        "    contrast = sum(stat.stddev)/(3*128)\n",
        "    return brightness, contrast\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Adaptive Visual Logic ‚Äî Fire + Smoke Titles\n",
        "# ============================================================\n",
        "def adaptive_visuals(cid, brightness, contrast):\n",
        "    \"\"\"Adjust color and label title dynamically based on B and C.\"\"\"\n",
        "    r, g, b = base_colors[cid]\n",
        "    desc = \"\"\n",
        "    visibility = \"\"\n",
        "    color = (r, g, b)\n",
        "\n",
        "    # ---------------- FIRE ----------------\n",
        "    if cid == 0:\n",
        "        if brightness > 0.7 and contrast > 0.5:\n",
        "            desc, color = \"üî• Inferno-Level Fire (Blinding Brightness)\", (255, 0, 0)\n",
        "        elif brightness > 0.5:\n",
        "            desc, color = \"üî• Intense Flames (Strong Contrast)\", (255, 80, 20)\n",
        "        elif brightness > 0.3:\n",
        "            desc, color = \"üî• Controlled Fire (Moderate Light)\", (255, 140, 40)\n",
        "        else:\n",
        "            desc, color = \"üî• Smoldering Fire (Low Visibility)\", (180, 70, 30)\n",
        "\n",
        "    # ---------------- SMOKE ----------------\n",
        "    elif cid in [1, 2, 3, 4, 5]:\n",
        "        # Brightness and contrast map to visibility severity\n",
        "        if brightness < 0.25 and contrast < 0.25:\n",
        "            desc, color = \"üí® Dense Opaque Smoke (Zero Visibility)\", (50, 50, 50)\n",
        "            visibility = \"‚ùå Poor Visibility\"\n",
        "        elif brightness < 0.4:\n",
        "            desc, color = \"üí® Heavy Smoke (Low Visibility)\", (90, 90, 90)\n",
        "            visibility = \"‚ö†Ô∏è Reduced Visibility\"\n",
        "        elif brightness < 0.6:\n",
        "            desc, color = \"üå´Ô∏è Moderate Haze (Partially Clear)\", (150, 120, 80)\n",
        "            visibility = \"üü† Moderate Visibility\"\n",
        "        else:\n",
        "            desc, color = \"‚òÅÔ∏è Thin Smoke (Easily Visible)\", (200, 180, 130)\n",
        "            visibility = \"‚úÖ Good Visibility\"\n",
        "\n",
        "        desc += f\" ‚Äî {visibility}\"\n",
        "\n",
        "    # ---------------- INCENSE / NON-THREAT ----------------\n",
        "    elif cid == 6:\n",
        "        if brightness > 0.7:\n",
        "            desc, color = \"üïØÔ∏è Gentle Glow (Soft Light Diffusion)\", (150, 220, 255)\n",
        "        else:\n",
        "            desc, color = \"üïØÔ∏è Subtle Incense Haze\", (100, 180, 255)\n",
        "\n",
        "    return color, f\"{desc}\"\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Display Annotated Images\n",
        "# ============================================================\n",
        "shown = set()\n",
        "\n",
        "def display_dynamic_annotations(n=30):\n",
        "    global shown\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "    unseen = list(set(matched) - shown)\n",
        "\n",
        "    if not unseen:\n",
        "        print(\"‚úÖ All annotated images already shown.\")\n",
        "        return\n",
        "\n",
        "    random.seed(time.time())\n",
        "    sample = random.sample(unseen, min(n, len(unseen)))\n",
        "    shown.update(sample)\n",
        "\n",
        "    print(f\"\\nüì∏ Displaying {len(sample)} annotated images (remaining: {len(unseen)-len(sample)})...\\n\")\n",
        "\n",
        "    for stem in sample:\n",
        "        img_path = next((os.path.join(images_dir, stem+ext) for ext in image_exts if os.path.exists(os.path.join(images_dir, stem+ext))), None)\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not img_path or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        # üü® Legend\n",
        "        y = 10\n",
        "        for cid, cname in class_labels.items():\n",
        "            draw.rectangle([10, y, 30, y+20], fill=base_colors[cid])\n",
        "            draw.text((40, y), cname, fill=base_colors[cid])\n",
        "            y += 22\n",
        "\n",
        "        # üü• Draw dynamic annotation boxes\n",
        "        with open(txt_path) as f:\n",
        "            for line in f.readlines():\n",
        "                cid, bbox = yolo_to_bbox(line, w, h)\n",
        "                if not bbox: continue\n",
        "                bright, cont = analyze_visibility(img, bbox)\n",
        "                color, new_label = adaptive_visuals(cid, bright, cont)\n",
        "\n",
        "                text_color = (255, 255, 255) if bright < 0.5 else (0, 0, 0)\n",
        "                draw.rectangle(bbox, outline=color, width=4)\n",
        "                draw.text((bbox[0] + 2, bbox[1] - 16),\n",
        "                          f\"{new_label} | B={bright:.2f}, C={cont:.2f}\",\n",
        "                          fill=text_color)\n",
        "                print(f\"{stem}.jpg ‚Äî {new_label} | Bright={bright:.2f}, Contrast={cont:.2f}\")\n",
        "\n",
        "        display(img)\n",
        "        print(f\"‚úÖ Displayed: {stem}.jpg\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Run\n",
        "# ============================================================\n",
        "display_dynamic_annotations(n=30)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW5VzMIeVJY9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/Home fire dataset/test/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "\n",
        "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "\n",
        "missing_images = sorted(label_stems - image_stems)\n",
        "extra_images = sorted(image_stems - label_stems)\n",
        "\n",
        "# Delete YOLO txts that don‚Äôt match an image\n",
        "for stem in missing_images:\n",
        "    os.remove(os.path.join(labels_dir, f\"{stem}.txt\"))\n",
        "\n",
        "print(f\"‚úÖ Kept {len(image_stems & label_stems)} valid image‚Äìlabel pairs.\")\n",
        "print(f\"üóëÔ∏è Removed {len(missing_images)} orphan label files (no matching image).\")\n",
        "if extra_images:\n",
        "    print(f\"‚ö†Ô∏è {len(extra_images)} images have no label files (you can auto-generate later).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwQmsHS_a4vX"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "image_stems = {Path(f).stem for f in os.listdir(images_dir)}\n",
        "label_stems = {Path(f).stem for f in os.listdir(labels_dir)}\n",
        "matched = image_stems & label_stems\n",
        "print(f\"‚úÖ Matched pairs: {len(matched)} / {len(image_stems)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT_aa_4NVLOg"
      },
      "outputs": [],
      "source": [
        "import os, random, time\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageStat, ImageDraw\n",
        "from IPython.display import display\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Paths\n",
        "# ============================================================\n",
        "images_dir = \"/content/drive/MyDrive/Home fire dataset/test/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Base Labels + Colors\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"üî• Fire\",\n",
        "    1: \"üí® Serious Smoke\",\n",
        "    2: \"üå´Ô∏è Moderate Smoke\",\n",
        "    3: \"‚òÅÔ∏è Mild Smoke\",\n",
        "    4: \"üíß Steam / False Alarm\",\n",
        "    5: \"üö´ Non-Fire Smoke\",\n",
        "    6: \"üïØÔ∏è Incense / Non-Threat Smoke\"\n",
        "}\n",
        "\n",
        "base_colors = {\n",
        "    0: (255, 70, 0),\n",
        "    1: (45, 45, 45),\n",
        "    2: (200, 110, 20),\n",
        "    3: (255, 220, 40),\n",
        "    4: (170, 170, 170),\n",
        "    5: (210, 210, 210),\n",
        "    6: (130, 200, 255)\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ YOLO TXT ‚Üí BBox\n",
        "# ============================================================\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc*w, yc*h, bw*w, bh*h\n",
        "    return int(cid), (int(xc-bw/2), int(yc-bh/2), int(xc+bw/2), int(yc+bh/2))\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Brightness & Contrast Analyzer\n",
        "# ============================================================\n",
        "def analyze_visibility(img, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    stat = ImageStat.Stat(region)\n",
        "    brightness = sum(stat.mean)/(3*255)\n",
        "    contrast = sum(stat.stddev)/(3*128)\n",
        "    return brightness, contrast\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Dynamic Label System (Physics-Based)\n",
        "# ============================================================\n",
        "def dynamic_indicator(cid, brightness, contrast):\n",
        "    \"\"\"Assign severity labels and colors based on real fire/smoke brightness‚Äìcontrast relations.\"\"\"\n",
        "    r, g, b = base_colors[cid]\n",
        "    desc, color = \"\", (r, g, b)\n",
        "\n",
        "    # üî• FIRE PHYSICS MAPPING\n",
        "    if cid == 0:\n",
        "        # Bright = high combustion temperature; contrast = flame flicker visibility\n",
        "        if brightness > 0.75 and contrast > 0.6:\n",
        "            desc, color = \"üî• Inferno (High Heat, Violent Combustion)\", (255, 0, 0)\n",
        "        elif brightness > 0.55 and contrast > 0.45:\n",
        "            desc, color = \"üî• Active Flames (High Heat, Turbulent Fire)\", (255, 80, 20)\n",
        "        elif brightness > 0.35:\n",
        "            desc, color = \"üî• Moderate Fire (Stable Burn)\", (255, 130, 40)\n",
        "        else:\n",
        "            desc, color = \"üî• Smoldering (Low Heat, Oxygen-Starved)\", (160, 70, 30)\n",
        "\n",
        "    # üí® SMOKE DYNAMICS\n",
        "    elif cid in [1, 2, 3, 4, 5]:\n",
        "        # Brightness = light penetration through smoke\n",
        "        # Contrast = smoke particle density\n",
        "        if brightness < 0.2 and contrast < 0.25:\n",
        "            desc, color = \"üí® Black Thick Smoke (Toxic, Zero Visibility)\", (25, 25, 25)\n",
        "        elif brightness < 0.4 and contrast < 0.4:\n",
        "            desc, color = \"üí® Dense Gray Smoke (Poor Visibility)\", (80, 80, 80)\n",
        "        elif brightness < 0.55:\n",
        "            desc, color = \"üå´Ô∏è Light Gray Haze (Moderate Visibility)\", (160, 130, 90)\n",
        "        else:\n",
        "            desc, color = \"‚òÅÔ∏è Thin Smoke (Dispersing)\", (220, 200, 120)\n",
        "\n",
        "        # Add detail classification based on contrast levels\n",
        "        if contrast < 0.3:\n",
        "            desc += \" ‚Äî ‚ö†Ô∏è Low Definition (Particle Saturation)\"\n",
        "        elif contrast < 0.6:\n",
        "            desc += \" ‚Äî üü† Medium Definition (Partial Visibility)\"\n",
        "        else:\n",
        "            desc += \" ‚Äî ‚úÖ Clear Definition (Dispersed Particles)\"\n",
        "\n",
        "    # üíß STEAM & NON-FIRE SOURCES\n",
        "    elif cid == 4:\n",
        "        if brightness > 0.6:\n",
        "            desc, color = \"üíß Bright Steam Cloud (Reflected Light)\", (190, 190, 190)\n",
        "        else:\n",
        "            desc, color = \"üíß Damp Mist (Low Reflection)\", (120, 120, 120)\n",
        "    elif cid == 5:\n",
        "        desc, color = \"üö´ Non-Fire Smoke (Cool Source)\", (190, 190, 190)\n",
        "    elif cid == 6:\n",
        "        if brightness > 0.7:\n",
        "            desc, color = \"üïØÔ∏è Incense Glow (Light Diffusion)\", (160, 220, 255)\n",
        "        else:\n",
        "            desc, color = \"üïØÔ∏è Subtle Blue Haze\", (100, 180, 255)\n",
        "\n",
        "    return color, desc\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Display Annotated Images\n",
        "# ============================================================\n",
        "def display_dynamic_annotations(images_dir, labels_dir, n=10):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_stems = {Path(f).stem for f in os.listdir(images_dir) if f.lower().endswith(image_exts)}\n",
        "    label_stems = {Path(f).stem for f in os.listdir(labels_dir) if f.endswith(\".txt\")}\n",
        "    matched = sorted(image_stems & label_stems)\n",
        "\n",
        "    print(f\"\\nüìÇ Displaying {min(n, len(matched))} annotated samples (of {len(matched)} total)...\\n\")\n",
        "\n",
        "    sampled = random.sample(matched, min(n, len(matched)))\n",
        "    for stem in sampled:\n",
        "        img_path = os.path.join(images_dir, stem + \".jpg\")\n",
        "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
        "        if not os.path.exists(img_path) or not os.path.exists(txt_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "\n",
        "        # üü® Legend\n",
        "        y = 10\n",
        "        for cid, cname in class_labels.items():\n",
        "            draw.rectangle([10, y, 30, y+20], fill=base_colors[cid])\n",
        "            draw.text((40, y), cname, fill=base_colors[cid])\n",
        "            y += 22\n",
        "\n",
        "        # üü• Draw Adaptive Bounding Boxes\n",
        "        with open(txt_path) as f:\n",
        "            for line in f:\n",
        "                class_id, bbox = yolo_to_bbox(line, w, h)\n",
        "                if not bbox: continue\n",
        "                brightness, contrast = analyze_visibility(img, bbox)\n",
        "                color, title = dynamic_indicator(class_id, brightness, contrast)\n",
        "\n",
        "                draw.rectangle(bbox, outline=color, width=4)\n",
        "                text_color = (255, 255, 255) if brightness < 0.5 else (0, 0, 0)\n",
        "                label_text = f\"{title} | B={brightness:.2f}, C={contrast:.2f}\"\n",
        "                draw.text((bbox[0] + 2, bbox[1] - 14), label_text, fill=text_color)\n",
        "                print(f\"{stem}.jpg ‚Äî {label_text}\")\n",
        "\n",
        "        display(img)\n",
        "        print(f\"‚úÖ Displayed: {stem}.jpg\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Run\n",
        "# ============================================================\n",
        "display_dynamic_annotations(images_dir, labels_dir, n=30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKD1VpsSbpt3"
      },
      "source": [
        "The funtion \"draw_yolo_box\", takes input an image path and its corresponding label path. Then, draws the bounding boxes and write the object's label in each box. Finally it displays the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1G3t3yXcVOl"
      },
      "outputs": [],
      "source": [
        "def draw_yolo_bbox(image_path, label_path):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read label file\n",
        "    with open(label_path, 'r') as file:\n",
        "        bboxes = file.readlines()\n",
        "\n",
        "    # Draw each bbox\n",
        "    for bbox in bboxes:\n",
        "        cls, x_center, y_center, w, h = map(float, bbox.strip().split())\n",
        "        x1 = int((x_center - w / 2) * width)\n",
        "        y1 = int((y_center - h / 2) * height)\n",
        "        x2 = int((x_center + w / 2) * width)\n",
        "        y2 = int((y_center + h / 2) * height)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QcDHeIZcbuS"
      },
      "source": [
        "The function \"print_random_images\" takes in input the list of images' paths, a number defining how much images we want to print. So it randomly selects the images to display and calls \"draw_yolo_bbox\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9L8MkvV-EBh"
      },
      "outputs": [],
      "source": [
        "def print_random_imagesFireandSmoke(image_paths, n=30):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCmyf-A-pgZN"
      },
      "outputs": [],
      "source": [
        "def print_random_imagesHomeFire(image_paths, n=30):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-qPj7DNoZTH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6TvL9xMmpcx"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Class Labels & Colors\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"üî• Fire\",\n",
        "    1: \"üí® Serious Smoke\",\n",
        "    2: \"üå´Ô∏è Moderate Smoke\",\n",
        "    3: \"‚òÅÔ∏è Mild Smoke\",\n",
        "    4: \"üíß Steam / False Alarm\",\n",
        "    5: \"üö´ Non-Fire Smoke\",\n",
        "    6: \"üïØÔ∏è Incense / Non-Threat Smoke\"\n",
        "}\n",
        "base_colors = {\n",
        "    0: (255, 60, 0),\n",
        "    1: (40, 40, 40),\n",
        "    2: (180, 100, 20),\n",
        "    3: (255, 220, 50),\n",
        "    4: (150, 150, 150),\n",
        "    5: (200, 200, 200),\n",
        "    6: (130, 200, 255)\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ YOLO TXT ‚Üí BBox\n",
        "# ============================================================\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw / 2), int(yc - bh / 2), int(xc + bw / 2), int(yc + bh / 2))\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Condition Analyzer\n",
        "# ============================================================\n",
        "def analyze_conditions(img, bbox, cid):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    region = img.crop((x1, y1, x2, y2)).convert(\"RGB\")\n",
        "    gray = region.convert(\"L\")\n",
        "    mean_brightness = ImageStat.Stat(gray).mean[0] / 255\n",
        "    stddev = ImageStat.Stat(gray).stddev[0] / 255\n",
        "\n",
        "    if stddev < 0.25:\n",
        "        clarity = \"‚ö†Ô∏è Low Visibility\"\n",
        "    elif stddev < 0.45:\n",
        "        clarity = \"üü† Partial Visibility\"\n",
        "    else:\n",
        "        clarity = \"‚úÖ Clear Details\"\n",
        "\n",
        "    if cid == 0:\n",
        "        if mean_brightness > 0.75 and stddev > 0.5:\n",
        "            return (255, 0, 0), f\"üî• Inferno-Level Fire ‚Äî {clarity}\"\n",
        "        elif mean_brightness > 0.55:\n",
        "            return (255, 90, 20), f\"üî• Intense Flames ‚Äî {clarity}\"\n",
        "        elif mean_brightness > 0.35:\n",
        "            return (255, 160, 60), f\"üî• Moderate Fire ‚Äî {clarity}\"\n",
        "        else:\n",
        "            return (180, 70, 30), f\"üî• Smoldering Fire ‚Äî {clarity}\"\n",
        "\n",
        "    elif cid in [1, 2, 3, 5]:\n",
        "        if mean_brightness < 0.25:\n",
        "            return (30, 30, 30), f\"üí® Dense Smoke ‚Äî {clarity}\"\n",
        "        elif mean_brightness < 0.35:\n",
        "            return (80, 80, 80), f\"üí® Heavy Smoke ‚Äî {clarity}\"\n",
        "        elif mean_brightness < 0.55:\n",
        "            return (160, 120, 70), f\"üå´Ô∏è Moderate Smoke ‚Äî {clarity}\"\n",
        "        else:\n",
        "            return (220, 200, 150), f\"‚òÅÔ∏è Light Smoke ‚Äî {clarity}\"\n",
        "\n",
        "    elif cid == 4:\n",
        "        return ((210,210,210) if mean_brightness>0.7 else (150,150,150),\n",
        "                f\"üíß {'Bright' if mean_brightness>0.7 else 'Dim'} Steam ‚Äî {clarity}\")\n",
        "    elif cid == 6:\n",
        "        return ((160,220,255) if mean_brightness>0.6 else (100,160,255),\n",
        "                f\"üïØÔ∏è {'Gentle' if mean_brightness>0.6 else 'Subtle'} Incense ‚Äî {clarity}\")\n",
        "\n",
        "    return base_colors.get(cid, (255,255,255)), f\"Unknown ‚Äî {clarity}\"\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Draw Bounding Boxes\n",
        "# ============================================================\n",
        "def draw_yolo_bbox(img_path, label_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    w, h = img.size\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        print(f\"‚ö†Ô∏è Missing label for {os.path.basename(img_path)}\")\n",
        "        return img\n",
        "\n",
        "    with open(label_path) as f:\n",
        "        for line in f.readlines():\n",
        "            cid, bbox = yolo_to_bbox(line, w, h)\n",
        "            if not bbox: continue\n",
        "            color, label = analyze_conditions(img, bbox, cid)\n",
        "            draw.rectangle(bbox, outline=color, width=3)\n",
        "            draw.text((bbox[0] + 3, max(0, bbox[1] - 15)), label, fill=color)\n",
        "    return img\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Non-Repeating Logic (Persistent Tracker)\n",
        "# ============================================================\n",
        "shown_FireSmoke = set()\n",
        "shown_HomeFire_Test = set()\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Visualization Function ‚Äî With File Name Below Image\n",
        "# ============================================================\n",
        "def show_random_images(image_dir, label_dir, shown_set, title, n=30):\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_paths = [p for p in Path(image_dir).glob(\"*\") if p.suffix.lower() in image_exts and (Path(label_dir) / (p.stem + \".txt\")).exists()]\n",
        "    unseen = [p for p in image_paths if p.stem not in shown_set]\n",
        "\n",
        "    if not unseen:\n",
        "        print(f\"‚úÖ All {title} images have been shown. Resetting.\")\n",
        "        shown_set.clear()\n",
        "        unseen = image_paths\n",
        "\n",
        "    selected = random.sample(unseen, min(n, len(unseen)))\n",
        "    shown_set.update(p.stem for p in selected)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected):\n",
        "        label_path = Path(label_dir) / f\"{img_path.stem}.txt\"\n",
        "        img = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(5, 6, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.text(0.5, -0.15, img_path.stem, fontsize=9, ha=\"center\", transform=plt.gca().transAxes)  # ‚úÖ filename below each image\n",
        "    plt.suptitle(f\"{title} ‚Äî {len(selected)} Images\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Wrapper Function ‚Äî Full-Content, Non-Grid Display\n",
        "# ============================================================\n",
        "def display_random_images(dataset_name, image_dir, n=30):\n",
        "    \"\"\"\n",
        "    Displays full annotated images one by one (not in grid).\n",
        "    Each image shows its bounding boxes and prints label text content below.\n",
        "    \"\"\"\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "    # üî• Detect dataset and set correct label folder\n",
        "    if \"Fire and Smoke\" in dataset_name:\n",
        "        label_dir = \"/content/drive/MyDrive/Fire_and_Smoke_BBox_COCO_Dateset/coco128/labels/train\"\n",
        "        shown_set = shown_FireSmoke\n",
        "        dataset_title = \"üî• Fire + Smoke Dataset\"\n",
        "\n",
        "    elif \"Home Fire\" in dataset_name:\n",
        "        if \"test\" in image_dir:\n",
        "            label_dir = \"/content/drive/MyDrive/Home fire dataset/test/labels\"\n",
        "            shown_set = shown_HomeFire_Test\n",
        "            dataset_title = \"üè† Home Fire Test Dataset\"\n",
        "        else:\n",
        "            label_dir = \"/content/drive/MyDrive/Home fire dataset/train/labels\"\n",
        "            shown_set = shown_HomeFire_Test\n",
        "            dataset_title = \"üè† Home Fire Train Dataset\"\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Unknown dataset name: {dataset_name}\")\n",
        "        return\n",
        "\n",
        "    # üîé Gather valid image paths with labels\n",
        "    image_paths = [\n",
        "        p for p in Path(image_dir).glob(\"*\")\n",
        "        if p.suffix.lower() in image_exts and (Path(label_dir) / (p.stem + \".txt\")).exists()\n",
        "    ]\n",
        "\n",
        "    unseen = [p for p in image_paths if p.stem not in shown_set]\n",
        "    if not unseen:\n",
        "        print(f\"‚úÖ All {dataset_title} images have been shown. Resetting.\")\n",
        "        shown_set.clear()\n",
        "        unseen = image_paths\n",
        "\n",
        "    selected = random.sample(unseen, min(n, len(unseen)))\n",
        "    shown_set.update(p.stem for p in selected)\n",
        "\n",
        "    print(f\"\\nüì∏ Displaying {len(selected)} annotated samples from {dataset_title}\\n\")\n",
        "\n",
        "    # üñºÔ∏è Display images one by one\n",
        "    for img_path in selected:\n",
        "        label_path = Path(label_dir) / f\"{img_path.stem}.txt\"\n",
        "        img = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        #===================================\n",
        "       # plt.title(f\"{dataset_title} ‚Äî {img_path.stem}\", fontsize=13, pad=10)\n",
        "        #plt.show()\n",
        "\n",
        "#        print(f\"‚úÖ Displayed: {img_path.stem}.jpg\")\n",
        " #       print(f\"üìÑ Label file: {label_path.name}\\n\")\n",
        "#===========\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Run ‚Äî FireSmoke (Train) + HomeFire (Test)\n",
        "# ============================================================\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/Fire_and_Smoke_BBox_COCO_Dateset/coco128/train2017\",\n",
        "    \"/content/drive/MyDrive/Fire_and_Smoke_BBox_COCO_Dateset/coco128/labels/train\",\n",
        "    shown_FireSmoke, \"üî• Fire + Smoke Dataset\", n=30)\n",
        "\n",
        "show_random_images(\n",
        "    \"/content/drive/MyDrive/Home fire dataset/test/images\",\n",
        "    \"/content/drive/MyDrive/Home fire dataset/test/labels\",\n",
        "    shown_HomeFire_Test, \"üè† Home Fire Test Dataset\", n=30)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF77_6vG2AoF"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£  Class Labels & Colors\n",
        "# ============================================================\n",
        "class_labels = {\n",
        "    0: \"üî• Fire\",\n",
        "    1: \"üí® Serious Smoke\",\n",
        "    2: \"üå´Ô∏è Moderate Smoke\",\n",
        "    3: \"‚òÅÔ∏è Mild Smoke\",\n",
        "    4: \"üíß Steam / False Alarm\",\n",
        "    5: \"üö´ Non-Fire Smoke\",\n",
        "    6: \"üïØÔ∏è Incense / Non-Threat Smoke\"\n",
        "}\n",
        "base_colors = {\n",
        "    0: (255, 60, 0),\n",
        "    1: (40, 40, 40),\n",
        "    2: (180, 100, 20),\n",
        "    3: (255, 220, 50),\n",
        "    4: (150, 150, 150),\n",
        "    5: (200, 200, 200),\n",
        "    6: (130, 200, 255)\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ YOLO TXT ‚Üí BBox\n",
        "# ============================================================\n",
        "def yolo_to_bbox(line, w, h):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) != 5:\n",
        "        return None, None\n",
        "    cid, xc, yc, bw, bh = map(float, parts)\n",
        "    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "    return int(cid), (int(xc - bw / 2), int(yc - bh / 2), int(xc + bw / 2), int(yc + bh / 2))\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Draw Bounding Boxes\n",
        "# ============================================================\n",
        "def draw_yolo_bbox(img_path, label_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    w, h = img.size\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        # Silent fail ‚Äî will still save as no-box image\n",
        "        return img\n",
        "\n",
        "    with open(label_path) as f:\n",
        "        for line in f.readlines():\n",
        "            cid, bbox = yolo_to_bbox(line, w, h)\n",
        "            if not bbox:\n",
        "                continue\n",
        "            color = base_colors.get(cid, (255, 255, 255))\n",
        "            label = class_labels.get(cid, \"Unknown\")\n",
        "            draw.rectangle(bbox, outline=color, width=3)\n",
        "            draw.text((bbox[0] + 3, max(0, bbox[1] - 15)), label, fill=color)\n",
        "    return img\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Display + Save Annotated Images (handles missing labels too)\n",
        "# ============================================================\n",
        "def display_and_save_random_images(image_dir, label_dir, shown_set, title, save_subdir, n=30):\n",
        "    save_root = Path(\"/content/drive/MyDrive/fire_smoke_previews\")\n",
        "    save_dir = save_root / save_subdir\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    image_paths = [p for p in Path(image_dir).glob(\"*\") if p.suffix.lower() in image_exts]\n",
        "\n",
        "    if not image_paths:\n",
        "        print(f\"üö´ No images found in {image_dir}\")\n",
        "        return\n",
        "\n",
        "    unseen = [p for p in image_paths if p.stem not in shown_set]\n",
        "    if not unseen:\n",
        "        print(f\"‚úÖ All {title} images have been shown. Resetting.\")\n",
        "        shown_set.clear()\n",
        "        unseen = image_paths\n",
        "\n",
        "    selected = random.sample(unseen, min(n, len(unseen)))\n",
        "    shown_set.update(p.stem for p in selected)\n",
        "\n",
        "    labeled_count = 0\n",
        "    missing_labels = []\n",
        "\n",
        "    print(f\"\\nüì∏ Displaying & saving {len(selected)} annotated samples from {title}\\n\")\n",
        "\n",
        "    for img_path in selected:\n",
        "        base_name = img_path.stem.replace(\"_annotated\", \"\")\n",
        "        label_path = Path(label_dir) / f\"{base_name}.txt\"\n",
        "\n",
        "        img = draw_yolo_bbox(img_path, label_path)\n",
        "\n",
        "        # Display inline\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"{title} ‚Äî {base_name}\", fontsize=11)\n",
        "        plt.show()\n",
        "\n",
        "        # Save annotated image\n",
        "        save_img_path = save_dir / f\"{base_name}_annotated.jpg\"\n",
        "        img.save(save_img_path)\n",
        "\n",
        "        # Copy or create corresponding label file\n",
        "        save_lbl_path = save_dir / f\"{base_name}_annotated.txt\"\n",
        "        if label_path.exists():\n",
        "            with open(label_path, \"r\") as src, open(save_lbl_path, \"w\") as dst:\n",
        "                dst.write(src.read())\n",
        "            labeled_count += 1\n",
        "        else:\n",
        "            open(save_lbl_path, \"w\").close()\n",
        "            missing_labels.append(base_name)\n",
        "\n",
        "    # Summary report\n",
        "    print(f\"\\n‚úÖ Done saving {len(selected)} images from {title}\")\n",
        "    print(f\"üü¢ {labeled_count} images had labels, ‚ö™ {len(missing_labels)} had none.\")\n",
        "    if missing_labels:\n",
        "        print(\"Examples of unlabeled images:\", missing_labels[:5])\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Run ‚Äî Matching Annotated TXT Names\n",
        "# ============================================================\n",
        "shown_FireSmoke = set()\n",
        "shown_HomeFire_Test = set()\n",
        "\n",
        "display_and_save_random_images(\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\",\n",
        "    shown_FireSmoke, \"üî• Fire + Smoke Dataset\", \"fire_and_smoke_output_fixed\", n=30\n",
        ")\n",
        "\n",
        "display_and_save_random_images(\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\",\n",
        "    \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\",\n",
        "    shown_HomeFire_Test, \"üè† Home Fire Test Dataset\", \"home_fire_output_fixed\", n=30\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5KCOOvedKoT"
      },
      "source": [
        "Now, finally calling the function to display 30 images randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUb1DZnodJnc"
      },
      "outputs": [],
      "source": [
        "# Display 30 random images from Fire and Smoke dataset\n",
        "display_random_images(\"Fire and Smoke\", \"/content/drive/MyDrive/Fire_and_Smoke_BBox_COCO_Dateset/coco128/train2017\", n=30)\n",
        "\n",
        "# Display 30 random images from Home Fire dataset\n",
        "display_random_images(\"Home Fire dataset\", \"/content/drive/MyDrive/Home fire dataset/test/images\", n=30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ox7JnU9qj1o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2XL5eBUGs61"
      },
      "source": [
        "## Dataset Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VphL1Y3eDBT"
      },
      "source": [
        "Interestingly, we found out that this dataset is not clean. i.e. labels of some of the images are missing and there are extra labels. So, we need to find out the missing labels files and remove that from the labels folder. Also, we need to find out missing images, which we also need to remove from the images folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp-MBacMgDlx"
      },
      "outputs": [],
      "source": [
        "#we already have a list of images' paths and labels' path, stored in variables : image_paths and label_paths\n",
        "print(image_paths)\n",
        "print(label_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URBrBcojgRPf"
      },
      "source": [
        "Now, we make a list of only the names of images' files and labels' files.\n",
        "\n",
        "e.g.  only  000000000531 without the extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5E_Pw6dgOMO"
      },
      "outputs": [],
      "source": [
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "\n",
        "print(image_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJKT0PFHhk5Y"
      },
      "outputs": [],
      "source": [
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd53OlLafsVP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Corrected removal loop\n",
        "for file in extra_images:\n",
        "    # Get only the filename without any folder\n",
        "    filename = os.path.basename(file)\n",
        "    image_path = os.path.join(dataset_path, \"images\", filename)\n",
        "    if os.path.exists(image_path):\n",
        "        os.remove(image_path)\n",
        "        print(f\"Removed: {image_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {image_path}\")\n",
        "\n",
        "for file in extra_labels:\n",
        "    filename = os.path.basename(file)\n",
        "    label_path = os.path.join(dataset_path, \"labels\", filename)\n",
        "    if os.path.exists(label_path):\n",
        "        os.remove(label_path)\n",
        "        print(f\"Removed: {label_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {label_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFC1RmdVhter"
      },
      "source": [
        "Now removing them from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akqYMfZJjBop"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfqxKksXihaM"
      },
      "source": [
        "Check again if it worked:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cluJu0Hqioo7"
      },
      "outputs": [],
      "source": [
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a29fd86c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7LJCLrTI_69"
      },
      "source": [
        "There are none! great!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-RqYz7GeYUW"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ao_GrDeelx7"
      },
      "outputs": [],
      "source": [
        "train_images = \"/content/drive/MyDrive/Fire and Smoke BBox COCO Dateset/coco128/train2017\"\n",
        "val_images   = \"/content/drive/MyDrive/Home fire dataset/test/images\"\n",
        "import os\n",
        "print(os.path.exists(train_images))\n",
        "print(os.path.exists(val_images))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0SXxWDDyZpr"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade numpy torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnmYJdry2L5h"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install numpy torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM9DG8dRrfwn"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall \"numpy<2\" --quiet\n",
        "import importlib, numpy as np\n",
        "importlib.reload(np)\n",
        "print(\"‚úÖ NumPy reloaded cleanly:\", np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbsPYfjcFigH"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ YOLOv8 Fire/Smoke CPU-Stable Trainer (v7.4 ‚Äî Using fire_and_smoke_output folders)\n",
        "import os, sys, yaml, glob, subprocess, importlib, torch, multiprocessing\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£  Force NumPy\n",
        "# ============================================================\n",
        "def force_numpy():\n",
        "    try:\n",
        "        import numpy as np\n",
        "        _ = np.zeros((1, 1))\n",
        "        print(\"‚úÖ NumPy working fine.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è NumPy issue: {e} ‚Äî reinstalling‚Ä¶\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"numpy\"])\n",
        "        import numpy as np\n",
        "    globals()[\"np\"] = importlib.import_module(\"numpy\")\n",
        "    return globals()[\"np\"]\n",
        "\n",
        "np = force_numpy()\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Dataset Paths (updated)\n",
        "# ============================================================\n",
        "train_images = \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\"\n",
        "train_labels = \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\"\n",
        "val_images   = \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\"\n",
        "val_labels   = \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\"\n",
        "yaml_path    = \"/content/drive/MyDrive/fire_smoke/data.yaml\"\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Check images + labels\n",
        "# ============================================================\n",
        "def check_images_labels(image_dir):\n",
        "    img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    imgs = [f for ext in img_exts for f in glob.glob(os.path.join(image_dir, f\"*{ext}\"))]\n",
        "    lbls = [f for f in glob.glob(os.path.join(image_dir, \"*.txt\"))]\n",
        "    print(f\"‚úÖ Found {len(imgs)} images and {len(lbls)} labels in {os.path.basename(image_dir)}\")\n",
        "    return imgs, lbls\n",
        "\n",
        "train_imgs, train_lbls = check_images_labels(train_images)\n",
        "val_imgs, val_lbls = check_images_labels(val_images)\n",
        "\n",
        "if len(train_lbls) == 0:\n",
        "    print(\"üö® WARNING: No training labels found. Ensure your .txt annotations exist in:\")\n",
        "    print(train_labels)\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ YAML File (using the new output folders)\n",
        "# ============================================================\n",
        "os.makedirs(os.path.dirname(yaml_path), exist_ok=True)\n",
        "yaml.safe_dump({\n",
        "    \"train\": train_images,\n",
        "    \"val\": val_images,\n",
        "    \"names\": [\n",
        "        \"Fire\",\n",
        "        \"Serious Smoke\",\n",
        "        \"Moderate Smoke\",\n",
        "        \"Mild Smoke\",\n",
        "        \"Steam / False Alarm\",\n",
        "        \"Non-Fire Smoke\",\n",
        "        \"Incense / Non-Threat Smoke\"\n",
        "    ],\n",
        "    \"nc\": 7\n",
        "}, open(yaml_path, \"w\"))\n",
        "print(f\"‚úÖ Dataset YAML created ‚Üí {yaml_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ System Info\n",
        "# ============================================================\n",
        "import ultralytics\n",
        "print(f\"\\nüîé YOLOv8 version: {ultralytics.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ CUDA: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Running on CPU only.\")\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Training\n",
        "# ============================================================\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "train_args = dict(\n",
        "    data=yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=416,\n",
        "    batch=4,\n",
        "    workers=0,\n",
        "    freeze=0,\n",
        "    patience=5,\n",
        "    lr0=0.005,\n",
        "    weight_decay=0.0005,\n",
        "    exist_ok=True,\n",
        "    name=\"fire_smoke_yolov8n_cpu_stable_v74\"\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Starting YOLOv8 training using fire_and_smoke_output + home_fire_output dataset‚Ä¶\\n\")\n",
        "results = model.train(**train_args)\n",
        "print(\"\\n‚úÖ Training completed successfully (v7.4).\")\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Annotated Predictions ‚Äî Save Back to the Same Folders (Fixed)\n",
        "# ============================================================\n",
        "import shutil\n",
        "\n",
        "print(\"\\nüé® Generating annotated predictions and saving into the same folders‚Ä¶\")\n",
        "\n",
        "for img_dir, label in [\n",
        "    (\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\", \"TRAIN\"),\n",
        "    (\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\", \"VAL\")\n",
        "]:\n",
        "    sample_imgs = glob.glob(os.path.join(img_dir, \"*.jpg\"))\n",
        "    for img_path in sample_imgs:\n",
        "        results = model.predict(source=img_path, save=True, save_txt=False, conf=0.3)\n",
        "        annotated_path = Path(results[0].save_dir) / os.path.basename(img_path)\n",
        "        new_path = os.path.join(\n",
        "            img_dir,\n",
        "            f\"{os.path.splitext(os.path.basename(img_path))[0]}_annotated.jpg\"\n",
        "        )\n",
        "\n",
        "        if os.path.exists(annotated_path):\n",
        "            try:\n",
        "                shutil.move(str(annotated_path), new_path)  # ‚úÖ works across drives\n",
        "                print(f\"‚úÖ Saved {label} annotated image ‚Üí {new_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Could not move {annotated_path}: {e}\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è No detection result for: {img_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8Ô∏è‚É£ Display Preview Inline\n",
        "# ============================================================\n",
        "preview_samples = glob.glob(os.path.join(train_images, \"*_annotated.jpg\"))[:3] + \\\n",
        "                  glob.glob(os.path.join(val_images, \"*_annotated.jpg\"))[:3]\n",
        "\n",
        "if preview_samples:\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, path in enumerate(preview_samples):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(2, 3, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(os.path.basename(path))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No annotated preview images found.\")\n",
        "\n",
        "print(f\"\\nüéâ All annotated predictions saved into:\\nüî• {train_images}\\nüè† {val_images}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QA7O9_88drP"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üöÄ YOLOv8 Fire/Smoke Full Training + Evaluation Pipeline (v8.1 FIXED)\n",
        "# Compatible with Ultralytics v8.3.x (no plot_confusion_matrix)\n",
        "# ============================================================\n",
        "\n",
        "import os, sys, glob, yaml, subprocess, importlib, torch, shutil, random, multiprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£  Force NumPy\n",
        "# ============================================================\n",
        "def force_numpy():\n",
        "    try:\n",
        "        import numpy as np\n",
        "        _ = np.zeros((1, 1))\n",
        "        print(\"‚úÖ NumPy loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è NumPy issue: {e} ‚Äî reinstalling‚Ä¶\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"numpy\"])\n",
        "        import numpy as np\n",
        "    globals()[\"np\"] = importlib.import_module(\"numpy\")\n",
        "    return globals()[\"np\"]\n",
        "\n",
        "np = force_numpy()\n",
        "\n",
        "import ultralytics\n",
        "print(f\"üîç YOLOv8 version: {ultralytics.__version__}\")\n",
        "print(f\"üíª Torch CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Dataset Paths\n",
        "# ============================================================\n",
        "train_images = \"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output\"\n",
        "val_images   = \"/content/drive/MyDrive/fire_smoke_previews/home_fire_output\"\n",
        "yaml_path    = \"/content/drive/MyDrive/fire_smoke/data.yaml\"\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Verify Images & Labels\n",
        "# ============================================================\n",
        "def check_images_labels(image_dir):\n",
        "    img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    imgs = [f for ext in img_exts for f in glob.glob(os.path.join(image_dir, f\"*{ext}\"))]\n",
        "    lbls = [f for f in glob.glob(os.path.join(image_dir, \"*.txt\"))]\n",
        "    print(f\"üìÅ {os.path.basename(image_dir)} ‚Üí {len(imgs)} images, {len(lbls)} labels\")\n",
        "    return imgs, lbls\n",
        "\n",
        "train_imgs, train_lbls = check_images_labels(train_images)\n",
        "val_imgs, val_lbls = check_images_labels(val_images)\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Create YAML Config\n",
        "# ============================================================\n",
        "os.makedirs(os.path.dirname(yaml_path), exist_ok=True)\n",
        "yaml.safe_dump({\n",
        "    \"train\": train_images,\n",
        "    \"val\": val_images,\n",
        "    \"nc\": 7,\n",
        "    \"names\": [\n",
        "        \"Fire\",\n",
        "        \"Serious Smoke\",\n",
        "        \"Moderate Smoke\",\n",
        "        \"Mild Smoke\",\n",
        "        \"Steam / False Alarm\",\n",
        "        \"Non-Fire Smoke\",\n",
        "        \"Incense / Non-Threat Smoke\"\n",
        "    ]\n",
        "}, open(yaml_path, \"w\"))\n",
        "print(f\"‚úÖ YAML written ‚Üí {yaml_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Train Model\n",
        "# ============================================================\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "\n",
        "train_args = dict(\n",
        "    data=yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=416,\n",
        "    batch=4,\n",
        "    workers=0,\n",
        "    freeze=10,\n",
        "    patience=5,\n",
        "    lr0=0.005,\n",
        "    weight_decay=0.0005,\n",
        "    name=\"fire_smoke_yolov8n_v8full\",\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Starting training...\\n\")\n",
        "results = model.train(**train_args)\n",
        "print(\"\\n‚úÖ Training complete!\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Evaluate and Compute Metrics\n",
        "# ============================================================\n",
        "print(\"üìä Evaluating model...\")\n",
        "metrics = model.val(data=yaml_path, split=\"val\")\n",
        "\n",
        "print(\"\\nüßÆ Evaluation summary:\")\n",
        "try:\n",
        "    p = float(metrics.box.p.mean()) if hasattr(metrics.box.p, \"mean\") else float(metrics.box.p)\n",
        "    r = float(metrics.box.r.mean()) if hasattr(metrics.box.r, \"mean\") else float(metrics.box.r)\n",
        "    map50 = float(metrics.box.map50.mean()) if hasattr(metrics.box.map50, \"mean\") else float(metrics.box.map50)\n",
        "    map95 = float(metrics.box.map.mean()) if hasattr(metrics.box.map, \"mean\") else float(metrics.box.map)\n",
        "    print(f\"Precision: {p:.3f}\")\n",
        "    print(f\"Recall:    {r:.3f}\")\n",
        "    print(f\"mAP50:     {map50:.3f}\")\n",
        "    print(f\"mAP50-95:  {map95:.3f}\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Could not summarize metrics:\", e)\n",
        "    print(metrics)\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Confusion Matrix (Manual, Compatible with v8.3.x)\n",
        "# ============================================================\n",
        "print(\"\\nüéØ Generating confusion matrix...\")\n",
        "\n",
        "try:\n",
        "    true_classes = np.concatenate(metrics.box.tcls)\n",
        "    pred_classes = np.concatenate(metrics.box.pred_cls)\n",
        "    class_names = list(metrics.names.values())\n",
        "\n",
        "    if len(true_classes) > 0 and len(pred_classes) > 0:\n",
        "        cm = confusion_matrix(true_classes, pred_classes, normalize=\"true\")\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "                    xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title(\"üî• Fire & Smoke Detection ‚Äî Normalized Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted Class\")\n",
        "        plt.ylabel(\"True Class\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"/content/confusion_matrix.png\")\n",
        "        plt.show()\n",
        "        print(\"‚úÖ Confusion matrix saved ‚Üí /content/confusion_matrix.png\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Not enough data to generate confusion matrix.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Error while generating confusion matrix:\", e)\n",
        "\n",
        "# ============================================================\n",
        "# 8Ô∏è‚É£ Precision-Recall Curve (Manual)\n",
        "# ============================================================\n",
        "print(\"\\nüìà Generating Precision-Recall curve...\")\n",
        "try:\n",
        "    y_true = np.concatenate(metrics.box.tcls)\n",
        "    y_conf = np.concatenate(metrics.box.conf)\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_conf)\n",
        "    ap = average_precision_score(y_true, y_conf)\n",
        "\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.plot(recall, precision, color=\"purple\", lw=2, label=f\"AP = {ap:.3f}\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Precision-Recall Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"/content/precision_recall_curve.png\")\n",
        "    plt.show()\n",
        "    print(\"‚úÖ PR curve saved ‚Üí /content/precision_recall_curve.png\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Could not compute PR curve:\", e)\n",
        "\n",
        "# ============================================================\n",
        "# 9Ô∏è‚É£ Annotated Predictions\n",
        "# ============================================================\n",
        "print(\"\\nüé® Generating annotated predictions...\")\n",
        "for img_dir, label in [\n",
        "    (train_images, \"TRAIN\"),\n",
        "    (val_images, \"VAL\")\n",
        "]:\n",
        "    sample_imgs = glob.glob(os.path.join(img_dir, \"*.jpg\"))\n",
        "    for img_path in sample_imgs:\n",
        "        results = model.predict(source=img_path, save=True, save_txt=False, conf=0.3)\n",
        "        annotated_path = Path(results[0].save_dir) / os.path.basename(img_path)\n",
        "        new_path = os.path.join(\n",
        "            img_dir,\n",
        "            f\"{os.path.splitext(os.path.basename(img_path))[0]}_annotated.jpg\"\n",
        "        )\n",
        "        try:\n",
        "            shutil.move(str(annotated_path), new_path)\n",
        "            print(f\"‚úÖ Saved {label} annotated image ‚Üí {new_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not move {annotated_path}: {e}\")\n",
        "\n",
        "# ============================================================\n",
        "# üîü Display 30 Annotated Samples\n",
        "# ============================================================\n",
        "def display_random_annotated_images(img_dir, title, n=30):\n",
        "    annotated_imgs = glob.glob(os.path.join(img_dir, \"*_annotated.jpg\"))\n",
        "    if not annotated_imgs:\n",
        "        print(f\"‚ö†Ô∏è No annotated images found in {img_dir}\")\n",
        "        return\n",
        "    sample_imgs = random.sample(annotated_imgs, min(n, len(annotated_imgs)))\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i, path in enumerate(sample_imgs[:30]):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(6, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(os.path.basename(path), fontsize=8)\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_random_annotated_images(train_images, \"üî• Fire + Smoke Dataset (30 Samples)\")\n",
        "display_random_annotated_images(val_images, \"üè† Home Fire Dataset (30 Samples)\")\n",
        "\n",
        "print(\"\\nüéâ All steps completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9OYGZJGuxxR"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "train_files = glob.glob(\"/content/drive/MyDrive/fire_smoke_previews/fire_and_smoke_output/*_annotated*.jpg\")\n",
        "val_files = glob.glob(\"/content/drive/MyDrive/fire_smoke_previews/home_fire_output/*_annotated*.jpg\")\n",
        "\n",
        "print(f\"TRAIN annotated images saved: {len(train_files)}\")\n",
        "print(f\"VAL annotated images saved:   {len(val_files)}\")\n",
        "print(f\"Total annotated files:         {len(train_files) + len(val_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MXAB20pxa-9"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 9Ô∏è‚É£ Evaluate model and visualize confusion matrix\n",
        "# ============================================================\n",
        "from ultralytics.utils import ops\n",
        "from ultralytics.utils.plotting import plot_results\n",
        "from ultralytics.utils.metrics import ConfusionMatrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nüìä Evaluating trained model and generating confusion matrix...\")\n",
        "\n",
        "# Load best model from training\n",
        "model_path = \"/content/runs/detect/fire_smoke_yolov8n_cpu_stable_v74/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Run validation to get metrics and confusion matrix data\n",
        "metrics = model.val(conf=0.25, imgsz=416)\n",
        "\n",
        "# Compute and display confusion matrix\n",
        "cm = metrics.confusion_matrix.matrix  # numpy array (num_classes x num_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.title(\"üî• Fire & Smoke Detection Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Print summarized results\n",
        "print(\"\\nüßÆ Evaluation Summary:\")\n",
        "try:\n",
        "    p = float(np.mean(metrics.box.p))\n",
        "    r = float(np.mean(metrics.box.r))\n",
        "    map50 = float(np.mean(metrics.box.map50))\n",
        "    map95 = float(np.mean(metrics.box.map))\n",
        "    print(f\"Precision: {p:.3f}\")\n",
        "    print(f\"Recall:    {r:.3f}\")\n",
        "    print(f\"mAP50:     {map50:.3f}\")\n",
        "    print(f\"mAP50-95:  {map95:.3f}\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Could not summarize metrics:\", e)\n",
        "    print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8TXGGeQxdRD"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìà Plotting training and validation curves...\")\n",
        "plot_results(\"/content/runs/detect/fire_smoke_yolov8n_cpu_stable_v74/results.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vb_Mvp7xeiY"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üîç Test on New Images/Videos\n",
        "# ============================================================\n",
        "test_source = \"/content/drive/MyDrive/fire_smoke_previews/new_test_data\"  # üîÅ your folder\n",
        "os.makedirs(test_source, exist_ok=True)\n",
        "\n",
        "print(\"\\nüé• Testing model on new data...\")\n",
        "results = model.predict(source=test_source, conf=0.3, save=True, save_txt=True)\n",
        "\n",
        "print(\"‚úÖ Predictions complete. Check annotated results in /runs/detect/predict/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-oVT-0tbRCf"
      },
      "source": [
        "after training, all of the precision confusion matrix and everything, check to see if results are satisfactory"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
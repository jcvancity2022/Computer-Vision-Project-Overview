{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcvancity2022/Computer-Vision-Project-Overview/blob/JeffreyBranch/Week_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> <b>Image Dataset Analysis and Project Development with YOLO </b> </center> </h1>\n",
        "\n",
        "In this tutorial, we will see how image datasets with different types of tasks such as detection , segmentation etc. look like, and how they are labelled, specifically in YOLO format.\n",
        "\n",
        "Then, we will download one dataset to explore it and clean it if required.\n",
        "\n"
      ],
      "metadata": {
        "id": "CvIx0KGWlPtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Classification**\n",
        "\n",
        "Image classification is the simplest and involves classifying an entire image into one of a set of predefined classes.\n",
        "\n",
        "The output of an image classifier is a single class label and a confidence score. Image classification is useful when you need to know only what class an image belongs to and don't need to know where objects of that class are located or what their exact shape is.\n",
        "\n"
      ],
      "metadata": {
        "id": "qLUWE8gn9_RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418606-adf35c62-2e11-405d-84c6-b84e7d013804.png\" width=\"600\">"
      ],
      "metadata": {
        "id": "DSkOCZxt-ZAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually each image has a single object in it, which is its class> Following image shows CIFAR10 Dataset.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://datagen.tech/wp-content/uploads/2022/11/image1.png\" width=\"600\">\n",
        "\n"
      ],
      "metadata": {
        "id": "OstzhA30B2tK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset should be labelled by arranging them in the following folders heirarchy.\n",
        "\n",
        "              root/\n",
        "              |-- class1/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class2/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- class3/\n",
        "              |   |-- img1.jpg\n",
        "              |   |-- img2.jpg\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- ...\n",
        "\n",
        "In this folder structure, the root directory contains one subdirectory for each class in the dataset. Each subdirectory is named after the corresponding class and contains all the images for that class.\n",
        "\n",
        "For example:\n",
        "\n",
        "              cifar-10-/\n",
        "              |\n",
        "              |-- train/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10008_airplane.png\n",
        "              |   |   |-- 10009_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 1000_automobile.png\n",
        "              |   |   |-- 1001_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 10014_bird.png\n",
        "              |   |   |-- 10015_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ...\n",
        "              |\n",
        "              |-- test/\n",
        "              |   |-- airplane/\n",
        "              |   |   |-- 10_airplane.png\n",
        "              |   |   |-- 11_airplane.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- automobile/\n",
        "              |   |   |-- 100_automobile.png\n",
        "              |   |   |-- 101_automobile.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- bird/\n",
        "              |   |   |-- 1000_bird.png\n",
        "              |   |   |-- 1001_bird.png\n",
        "              |   |   |-- ...\n",
        "              |   |\n",
        "              |   |-- ..."
      ],
      "metadata": {
        "id": "hcIc5sJBCx2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vTjx8pXEB1B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Object Detection**"
      ],
      "metadata": {
        "id": "5cZ9e5J4zvF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object detection is a task that involves identifying the location and class of objects in an image or video stream.\n",
        "\n",
        "The output of an object detector is a set of bounding boxes that enclose the objects in the image, along with class labels and confidence scores for each box."
      ],
      "metadata": {
        "id": "52PMPO-rgZq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418624-5785cb93-74c9-4541-9179-d5c6782d491a.png\" width=\"600\">"
      ],
      "metadata": {
        "id": "lDruPnQMi315"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Labelling format**\n",
        "\n",
        "In object detection tasks, various labeling formats are used to annotate images with information about the objects present. These formats typically include details about the object's class and location within the image. Here are some of the most common labeling formats:\n",
        "\n",
        "1. COCO\n",
        "2. YOLO\n",
        "3. CSV  \n",
        "5. XML\n",
        "6. PASCAL VOC\n",
        "\n",
        "We will be discussing only YOLO format, as you will be using YOLO framework for your project:\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "\n",
        "      class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "- Box coordinates must be normalized between 0 and 1\n",
        "\n",
        "\n",
        "An example:"
      ],
      "metadata": {
        "id": "kFz-X3Zx1xKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/91506361-c7965000-e886-11ea-8291-c72b98c25eec.jpg\" width=\"600\">"
      ],
      "metadata": {
        "id": "6es7DWt75YTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corresponding label text file should look like:\n",
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/112467037-d2568c00-8d66-11eb-8796-55402ac0d62f.png\" width=\"600\">"
      ],
      "metadata": {
        "id": "KDeb1gEM5uIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Segmentation**\n"
      ],
      "metadata": {
        "id": "0brGPZa4oRk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instance segmentation goes a step further than object detection and involves identifying individual objects in an image and segmenting them from the rest of the image.\n",
        "\n",
        "The output of an instance segmentation model is a set of masks or contours that outline each object in the image, along with class labels and confidence scores for each object. Instance segmentation is useful when you need to know not only where objects are in an image, but also what their exact shape is.\n",
        "\n"
      ],
      "metadata": {
        "id": "_56IDqcG6mNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418644-7df320b8-098d-47f1-85c5-26604d761286.png\" width=\"600\">"
      ],
      "metadata": {
        "id": "oItmHrqo8qLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - bounding coordinates: The bounding coordinates around the mask area, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "      <class-index> <x1> <y1> <x2> <y2> ... <xn> <yn>\n",
        "\n",
        "\n",
        "Here is an example of the YOLO dataset format for a single image with two objects made up of a 3-point segment and a 5-point segment.\n",
        "\n",
        "\n",
        "      0 0.681 0.485 0.670 0.487 0.676 0.487\n",
        "      1 0.504 0.000 0.501 0.004 0.498 0.004 0.493 0.010 0.492 0.0104\n"
      ],
      "metadata": {
        "id": "M2C24Fz389GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pose Estimation**\n",
        "Pose estimation is a task that involves identifying the location of specific points in an image, usually referred to as keypoints. The keypoints can represent various parts of the object such as joints, landmarks, or other distinctive features. The locations of the keypoints are usually represented as a set of 2D [x, y] or 3D [x, y, visible] coordinates.\n",
        "\n",
        "The output of a pose estimation model is a set of points that represent the keypoints on an object in the image, usually along with the confidence scores for each point. Pose estimation is a good choice when you need to identify specific parts of an object in a scene, and their location in relation to each other."
      ],
      "metadata": {
        "id": "CPFHkCO8-2mW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/243418616-9811ac0b-a4a7-452a-8aba-484ba32bb4a8.png\" width=\"600\">"
      ],
      "metadata": {
        "id": "zebzQ_Z6_CB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Labelling format for YOLO**\n",
        "\n",
        "\n",
        "- One .txt file with labels file per image\n",
        "- One row per object\n",
        "- Each row contains:\n",
        "  - Object class index: An integer representing the class of the object (e.g., 0 for person, 1 for car, etc.).\n",
        "  - Object center coordinates: The x and y coordinates of the center of the object, normalized to be between 0 and 1.\n",
        "  - Object width and height: The width and height of the object, normalized to be between 0 and 1.\n",
        "  - Object keypoint coordinates: The keypoints of the object, normalized to be between 0 and 1.\n",
        "\n",
        "\n",
        "Here is an example of the label format for pose estimation task:\n",
        "\n",
        "Format with Dim = 2\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <px2> <py2> ... <pxn> <pyn>\n",
        "Format with Dim = 3\n",
        "\n",
        "      <class-index> <x> <y> <width> <height> <px1> <py1> <p1-visibility> <px2> <py2> <p2-visibility> ... <pxn> <pyn> <p2-visibility>"
      ],
      "metadata": {
        "id": "z9M4kU8P_QWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FOLDERS HEIRARCHY\n"
      ],
      "metadata": {
        "id": "hsAvGgxxHAS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        " We need to convert the dataset into a specific heirarchy of folders for all the tasks except for task of classification.\n",
        "\n",
        "\n",
        "The directories should be in the following format:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "gt4h9bFXjV9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COCO128 Dataset**\n",
        "\n",
        "This section aims to introduce you to COCO dataset frequently used in Artificial Intelligence (AI).It is a foundational dataset in AI, widely used for tasks like object detection, segmentation, and image captioning.\n",
        "\n",
        "\n",
        "It Contains over 330,000 images with more than 200,000 labeled across 80 object categories. Unique for its richly annotated images, including object segmentation.It is widely used in computer vision research and has been used to train and evaluate many state-of-the-art object detection and segmentation models.\n",
        "\n",
        "Link to full dataset: https://cocodataset.org/#home\n"
      ],
      "metadata": {
        "id": "ZKyjblYvb8fW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going using coco128 dataset.This dataset contains the first 128 images of COCO train 2017. It is used as the tutorial dataset for YOLO.\n",
        "\n",
        "Download the dataset from:\n",
        "https://www.kaggle.com/datasets/ultralytics/coco128/data\n"
      ],
      "metadata": {
        "id": "G11PH4xOo8zO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Visualization"
      ],
      "metadata": {
        "id": "_DUeZCUkSwkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To draw bounding boxes on images we need to understand the labelling format used by this dataset. The labels for this dataset are stored in YOLO format. i.e.\n",
        "\n",
        "        class_id bbox_x_center bbox_y_center bbox_width bbox_height\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NJe53Fzd1mZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class_id is the numerical number assigned to different class labels as shown below:"
      ],
      "metadata": {
        "id": "jvPN5o_jSKgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only fire and smoke classes\n",
        "class_labels = {\n",
        "    0: \"Fire\",   # originally \"Smoke\" if your labels are swapped\n",
        "    1: \"Smoke\"   # originally \"Fire\" if your labels are swapped\n",
        "}\n"
      ],
      "metadata": {
        "id": "Qry8OPsHG3GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rest of the four values i.e.\n",
        "\n",
        "    0.479492 0.688771 0.955609 0.5955\n",
        "\n",
        "indidicate the location of the bounding box.\n",
        "\n",
        "These values are normalized, which should be converted to a format that can be used as coordinate values of rectangle function (of cv2)."
      ],
      "metadata": {
        "id": "Tc8tH0PySW4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First import the required libraries:"
      ],
      "metadata": {
        "id": "DQbCyFCMaueA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import os"
      ],
      "metadata": {
        "id": "ZoPPaZu5a4Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set all the paths of the dataset:"
      ],
      "metadata": {
        "id": "GEcvixvYa-A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the dataset\n",
        "dataset_path = \"Home fire dataset/test\"\n",
        "\n",
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "print (image_paths)"
      ],
      "metadata": {
        "id": "6xS3INAjbPTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Set all the paths of the dataset of Fire and Smoke:\n",
        "\n"
      ],
      "metadata": {
        "id": "GpP4yE5-sitI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_root = \"Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "annotations_json = os.path.join(dataset_root, \"annotations\", \"instances_val2017.json\")\n",
        "\n",
        "# Check if JSON exists\n",
        "if os.path.exists(annotations_json):\n",
        "    print(f\"✅ JSON found at: {annotations_json}\")\n",
        "else:\n",
        "    print(f\"❌ JSON NOT found! Current working dir: {os.getcwd()}\")\n",
        "    # List contents of dataset_root to see folder names\n",
        "    print(\"Contents of dataset_root:\", os.listdir(dataset_root))\n",
        "    # List contents of annotations folder\n",
        "    annotations_folder = os.path.join(dataset_root, \"annotations\")\n",
        "    if os.path.exists(annotations_folder):\n",
        "        print(\"Contents of annotations folder:\", os.listdir(annotations_folder))\n",
        "    else:\n",
        "        print(\"Annotations folder not found!\")\n",
        "\n",
        "dataset_root = \"Fire and Smoke BBox COCO Dataset/coco128\"\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    for file in files:\n",
        "        if file.endswith(\".json\"):\n",
        "            print(\"Found JSON:\", os.path.join(root, file))\n"
      ],
      "metadata": {
        "id": "wrVyXbVushbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ----------------------------\n",
        "# 1️⃣ Dataset paths\n",
        "# ----------------------------\n",
        "dataset_root = \"Fire and Smoke BBox COCO Dateset/coco128\"\n",
        "images_dir = os.path.join(dataset_root, \"images\")  # put images here\n",
        "annotations_dir = os.path.join(dataset_root, \"annotations\")\n",
        "json_file = os.path.join(annotations_dir, \"instances_train2017.json\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\")\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 2️⃣ Load COCO JSON\n",
        "# ----------------------------\n",
        "if not os.path.exists(json_file):\n",
        "    raise FileNotFoundError(f\"JSON file not found: {json_file}\")\n",
        "\n",
        "with open(json_file, \"r\") as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "# Map image_id → file_name\n",
        "img_id2file = {img['id']: img['file_name'] for img in coco['images']}\n",
        "img_id2size = {img['id']: (img['width'], img['height']) for img in coco['images']}\n",
        "\n",
        "# Group annotations by image\n",
        "img_annotations = defaultdict(list)\n",
        "for ann in coco['annotations']:\n",
        "    img_annotations[ann['image_id']].append(ann)\n",
        "\n",
        "# ----------------------------\n",
        "# 3️⃣ Convert JSON → YOLO TXT\n",
        "# ----------------------------\n",
        "for img_id, anns in tqdm(img_annotations.items(), desc=\"Converting JSON → YOLO TXT\"):\n",
        "    img_name = img_id2file[img_id]\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    txt_path = os.path.join(labels_dir, Path(img_name).stem + \".txt\")\n",
        "\n",
        "    if os.path.exists(img_path):\n",
        "        # Open image to get width & height\n",
        "        with Image.open(img_path) as img:\n",
        "            w, h = img.size\n",
        "    else:\n",
        "        # If image missing, use width/height from JSON\n",
        "        w, h = img_id2size.get(img_id, (640, 480))  # default size if missing\n",
        "        print(f\"⚠️ Image not found, using placeholder size for: {img_path}\")\n",
        "\n",
        "    # Write YOLO TXT\n",
        "    with open(txt_path, 'w') as f:\n",
        "        for ann in anns:\n",
        "            class_id = ann['category_id'] - 1  # YOLO uses 0-indexed classes\n",
        "            x_min, y_min, box_w, box_h = ann['bbox']\n",
        "\n",
        "            # If bbox is all zeros, create placeholder bbox in center\n",
        "            if box_w == 0 or box_h == 0:\n",
        "                x_center = 0.5\n",
        "                y_center = 0.5\n",
        "                width_norm = 0.1\n",
        "                height_norm = 0.1\n",
        "            else:\n",
        "                x_center = (x_min + box_w / 2) / w\n",
        "                y_center = (y_min + box_h / 2) / h\n",
        "                width_norm = box_w / w\n",
        "                height_norm = box_h / h\n",
        "\n",
        "            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
        "\n",
        "# ----------------------------\n",
        "# 4️⃣ Verify TXT files\n",
        "# ----------------------------\n",
        "txt_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
        "print(f\"\\n✅ Total YOLO TXT files created: {len(txt_files)}\")\n",
        "print(\"First 5 TXT files:\", txt_files[:6])\n"
      ],
      "metadata": {
        "id": "_ZFQeneewaFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The funtion \"draw_yolo_box\", takes input an image path and its corresponding label path. Then, draws the bounding boxes and write the object's label in each box. Finally it displays the images"
      ],
      "metadata": {
        "id": "TKD1VpsSbpt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_yolo_bbox(image_path, label_path):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read label file\n",
        "    with open(label_path, 'r') as file:\n",
        "        bboxes = file.readlines()\n",
        "\n",
        "    # Draw each bbox\n",
        "    for bbox in bboxes:\n",
        "        cls, x_center, y_center, w, h = map(float, bbox.strip().split())\n",
        "        x1 = int((x_center - w / 2) * width)\n",
        "        y1 = int((y_center - h / 2) * height)\n",
        "        x2 = int((x_center + w / 2) * width)\n",
        "        y2 = int((y_center + h / 2) * height)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "u1G3t3yXcVOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------\n",
        "# 1️⃣ Dataset paths\n",
        "# ----------------------------\n",
        "dataset_root = \"Fire and Smoke BBox COCO Dataset/coco128\"\n",
        "image_extensions = (\".jpg\", \".jpeg\", \".png\")\n",
        "labels_dir = os.path.join(dataset_root, \"labels\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2️⃣ Function to convert YOLO TXT to absolute bbox\n",
        "# ----------------------------\n",
        "def yolo_to_bbox(yolo_line, img_w, img_h):\n",
        "    \"\"\"\n",
        "    Convert YOLO normalized bbox to absolute pixel coordinates.\n",
        "    \"\"\"\n",
        "    class_id, x_center, y_center, width, height = map(float, yolo_line.strip().split())\n",
        "    x_center *= img_w\n",
        "    y_center *= img_h\n",
        "    width *= img_w\n",
        "    height *= img_h\n",
        "    x_min = int(x_center - width / 2)\n",
        "    y_min = int(y_center - height / 2)\n",
        "    x_max = int(x_center + width / 2)\n",
        "    y_max = int(y_center + height / 2)\n",
        "    return int(class_id), (x_min, y_min, x_max, y_max)\n",
        "\n",
        "# ----------------------------\n",
        "# 3️⃣ Draw boxes for all TXT files\n",
        "# ----------------------------\n",
        "for txt_file in os.listdir(labels_dir):\n",
        "    if not txt_file.endswith(\".txt\"):\n",
        "        continue\n",
        "\n",
        "    img_name = txt_file.replace(\".txt\", \".png\")  # adjust extension if images are jpg/jpeg\n",
        "    img_path = os.path.join(dataset_root, img_name)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        # Try jpg if png doesn't exist\n",
        "        img_name = txt_file.replace(\".txt\", \".jpg\")\n",
        "        img_path = os.path.join(dataset_root, img_name)\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"⚠️ Image not found for {txt_file}, skipping...\")\n",
        "            continue\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    w, h = img.size\n",
        "\n",
        "    txt_path = os.path.join(labels_dir, txt_file)\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f.readlines():\n",
        "            class_id, bbox = yolo_to_bbox(line, w, h)\n",
        "            draw.rectangle(bbox, outline=\"red\", width=2)\n",
        "            draw.text((bbox[0], bbox[1]-10), f\"class {class_id}\", fill=\"red\")\n",
        "\n",
        "    # Display the image with boxes\n",
        "    display(img)\n",
        "\n",
        "    # Optional: save image with drawn boxes\n",
        "    # save_path = os.path.join(dataset_root, f\"bbox_{img_name}\")\n",
        "    # img.save(save_path)\n"
      ],
      "metadata": {
        "id": "c-XhINJImjBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function \"print_random_images\" takes in input the list of images' paths, a number defining how much images we want to print. So it randomly selects the images to display and calls \"draw_yolo_bbox\"."
      ],
      "metadata": {
        "id": "5QcDHeIZcbuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_random_imagesFireandSmoke(image_paths, n=6):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "H9L8MkvV-EBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_random_imagesHomeFire(image_paths, n=6):\n",
        "    selected_images = random.sample(image_paths, n)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(selected_images):\n",
        "        # get file name (without extension)\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        # construct label path correctly\n",
        "        label_path = os.path.join(os.path.dirname(os.path.dirname(img_path)), \"labels\", f\"{name}.txt\")\n",
        "\n",
        "        # draw boxes\n",
        "        image = draw_yolo_bbox(img_path, label_path)\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(name)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VCmyf-A-pgZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-qPj7DNoZTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ImageDraw, ImageStat\n",
        "from IPython.display import display\n",
        "import random\n",
        "\n",
        "# ----------------------------\n",
        "# Dataset folders\n",
        "# ----------------------------\n",
        "datasets = {\n",
        "    \"Fire and Smoke\": \"Fire and Smoke BBox COCO Dateset/coco128/train2017\",\n",
        "    \"Home Fire\": \"Home fire dataset/test\"\n",
        "}\n",
        "image_extensions = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "# ----------------------------\n",
        "# Collect image paths\n",
        "# ----------------------------\n",
        "def get_image_paths(dataset_path):\n",
        "    paths = []\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(image_extensions):\n",
        "                paths.append(os.path.join(root, f))\n",
        "    return paths\n",
        "\n",
        "# ----------------------------\n",
        "# YOLO bbox conversion\n",
        "# ----------------------------\n",
        "def yolo_to_bbox(yolo_line, img_w, img_h):\n",
        "    class_id, x_center, y_center, width, height = map(float, yolo_line.strip().split())\n",
        "    x_center *= img_w\n",
        "    y_center *= img_h\n",
        "    width *= img_w\n",
        "    height *= img_h\n",
        "    x_min = int(x_center - width / 2)\n",
        "    y_min = int(y_center - height / 2)\n",
        "    x_max = int(x_center + width / 2)\n",
        "    y_max = int(y_center + height / 2)\n",
        "    return int(class_id), (x_min, y_min, x_max, y_max)\n",
        "\n",
        "# ----------------------------\n",
        "# Class labels & colors\n",
        "# ----------------------------\n",
        "class_labels = {\n",
        "    0: \"Fire\",\n",
        "    1: \"Serious Smoke\",\n",
        "    2: \"Moderate Smoke\",\n",
        "    3: \"Mild Smoke\",\n",
        "    4: \"Steam / False Alarm\",\n",
        "    5: \"Non-Fire Smoke\",\n",
        "    6: \"Incense / Non-Threat Smoke\"\n",
        "}\n",
        "\n",
        "class_colors = {\n",
        "    0: (255, 0, 0, 180),\n",
        "    1: (0, 0, 0, 220),\n",
        "    2: (255, 140, 0, 150),\n",
        "    3: (255, 255, 153, 120),\n",
        "    4: (105, 105, 105, 100),\n",
        "    5: (128, 128, 128, 140),\n",
        "    6: (173, 216, 230, 130)\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# Enhanced smoke/fire detection\n",
        "# ----------------------------\n",
        "def detect_smoke_source(img, bbox, kitchen_area_ratio=0.15, high_risk_objects=[]):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    w = max(x_max - x_min, 1)\n",
        "    h = max(y_max - y_min, 1)\n",
        "\n",
        "    cropped_rgb = img.crop((x_min, y_min, x_max, y_max)).convert(\"RGB\")\n",
        "    cropped_gray = cropped_rgb.convert(\"L\")\n",
        "\n",
        "    if cropped_gray.width == 0 or cropped_gray.height == 0:\n",
        "        return 4  # Steam / False Alarm\n",
        "\n",
        "    mean_brightness = ImageStat.Stat(cropped_gray).mean[0] / 255\n",
        "    density = ImageStat.Stat(cropped_gray).stddev[0] / 255\n",
        "    area_ratio = (w * h) / (img.width * img.height)\n",
        "    aspect_ratio = h / max(w,1)\n",
        "\n",
        "    # Check for visible fire source (red/yellow pixels)\n",
        "    r, g, b = cropped_rgb.split()\n",
        "    red_pixels = sum([val for val in r.getdata() if val > 150 and val > g.getdata()[0] + b.getdata()[0]])\n",
        "    if red_pixels > 50:\n",
        "        return 0  # Fire detected\n",
        "\n",
        "    # High-risk object proximity (if provided) can escalate smoke severity\n",
        "    for obj_bbox in high_risk_objects:\n",
        "        ox_min, oy_min, ox_max, oy_max = obj_bbox\n",
        "        overlap_w = max(0, min(x_max, ox_max) - max(x_min, ox_min))\n",
        "        overlap_h = max(0, min(y_max, oy_max) - max(y_min, oy_min))\n",
        "        if overlap_w > 0 and overlap_h > 0:\n",
        "            return 1  # Escalate to Serious Smoke if near high-risk object\n",
        "\n",
        "    # 🔹 Dark or dense smoke → Serious Smoke\n",
        "    if mean_brightness < 0.3 or density > 0.4:\n",
        "        return 1\n",
        "\n",
        "    # 🔹 Fire detection by size + brightness\n",
        "    if mean_brightness < 0.5 and area_ratio > 0.1 and aspect_ratio > 0.7:\n",
        "        if area_ratio < kitchen_area_ratio and mean_brightness > 0.35:\n",
        "            return 3  # Mild smoke / safe kitchen\n",
        "        return 0  # Fire\n",
        "\n",
        "    # 🔹 Moderate / Mild Smoke\n",
        "    if area_ratio > 0.1:\n",
        "        if density > 0.25 and mean_brightness < 0.6:\n",
        "            return 2  # Moderate\n",
        "        else:\n",
        "            return 3  # Mild\n",
        "\n",
        "    # 🔹 Non-fire smoke\n",
        "    if mean_brightness > 0.65 or area_ratio < 0.05 or density < 0.08:\n",
        "        return 5\n",
        "\n",
        "    # 🔹 Incense / Non-Threat Smoke (thin/light)\n",
        "    if area_ratio < 0.05 and mean_brightness > 0.7 and density < 0.15:\n",
        "        return 6\n",
        "\n",
        "    # 🔹 Default Steam / False Alarm\n",
        "    return 4\n",
        "\n",
        "# ----------------------------\n",
        "# Display function (with more detailed labels & accuracy)\n",
        "# ----------------------------\n",
        "def display_random_images(dataset_name, dataset_path, n=6, high_risk_objects=[]):\n",
        "    print(f\"\\n📂 Dataset: {dataset_name}\")\n",
        "    image_paths = get_image_paths(dataset_path)\n",
        "    if not image_paths:\n",
        "        print(f\"⚠️ No images found in dataset path: {dataset_path}\")\n",
        "        return\n",
        "\n",
        "    sampled_images = random.sample(image_paths, min(n, len(image_paths)))\n",
        "\n",
        "    for img_path in sampled_images:\n",
        "        img = Image.open(img_path).convert(\"RGBA\")\n",
        "        overlay = Image.new(\"RGBA\", img.size, (0,0,0,0))\n",
        "        draw = ImageDraw.Draw(overlay)\n",
        "        w, h = img.size\n",
        "\n",
        "        # Draw legend\n",
        "        legend_y = 5\n",
        "        for cls_id, cls_name in class_labels.items():\n",
        "            draw.rectangle([5, legend_y, 25, legend_y + 20], fill=class_colors[cls_id])\n",
        "            draw.text((30, legend_y), cls_name, fill=\"white\")\n",
        "            legend_y += 25\n",
        "\n",
        "        # Draw YOLO boxes\n",
        "        img_dir = os.path.dirname(img_path)\n",
        "        labels_dir = os.path.join(os.path.dirname(img_dir), \"labels\")\n",
        "        txt_path = os.path.join(labels_dir, os.path.splitext(os.path.basename(img_path))[0] + \".txt\")\n",
        "        if os.path.exists(txt_path):\n",
        "            with open(txt_path, \"r\") as f:\n",
        "                for line in f.readlines():\n",
        "                    class_id, bbox = yolo_to_bbox(line, w, h)\n",
        "                    if class_id == 1:  # refine smoke\n",
        "                        class_id = detect_smoke_source(img, bbox, high_risk_objects=high_risk_objects)\n",
        "                    color = class_colors.get(class_id, (0,0,255,150))\n",
        "                    label_name = class_labels.get(class_id, f\"class {class_id}\")\n",
        "                    draw.rectangle(bbox, outline=color[:3]+(255,), width=3 if class_id in [0,1] else 2)\n",
        "                    draw.text((bbox[0], bbox[1]-10), label_name, fill=color[:3]+(255,))\n",
        "\n",
        "        combined = Image.alpha_composite(img, overlay)\n",
        "        display(combined.convert(\"RGB\"))\n",
        "        print(f\"📌 Displayed: {os.path.basename(img_path)}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Example usage\n",
        "# ----------------------------\n",
        "# high_risk_objects = [(50,50,150,150)]  # Optional: list of high-risk object bboxes\n",
        "# display_random_images(\"Fire and Smoke\", \"Fire and Smoke BBox COCO Dateset/coco128/train2017\", n=6, high_risk_objects=high_risk_objects)\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Run display\n",
        "# ----------------------------\n",
        "#for name, path in datasets.items():\n",
        "#    display_random_images(name, path, n=10)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p6TvL9xMmpcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JF77_6vG2AoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, finally calling the function to display 30 images randomly."
      ],
      "metadata": {
        "id": "z5KCOOvedKoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 30 random images from Fire and Smoke dataset\n",
        "display_random_images(\"Fire and Smoke\", \"Fire and Smoke BBox COCO Dateset/coco128/train2017\", n=30)\n",
        "\n",
        "# Display 30 random images from Home Fire dataset\n",
        "display_random_images(\"Home Fire dataset\", \"Home fire dataset/train/images\", n=30)\n"
      ],
      "metadata": {
        "id": "GUb1DZnodJnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ox7JnU9qj1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Cleaning"
      ],
      "metadata": {
        "id": "Y2XL5eBUGs61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, we found out that this dataset is not clean. i.e. labels of some of the images are missing and there are extra labels. So, we need to find out the missing labels files and remove that from the labels folder. Also, we need to find out missing images, which we also need to remove from the images folder.\n"
      ],
      "metadata": {
        "id": "8VphL1Y3eDBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we already have a list of images' paths and labels' path, stored in variables : image_paths and label_paths\n",
        "print(image_paths)\n",
        "print(label_paths)"
      ],
      "metadata": {
        "id": "hp-MBacMgDlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we make a list of only the names of images' files and labels' files.\n",
        "\n",
        "e.g.  only  000000000531 without the extension"
      ],
      "metadata": {
        "id": "URBrBcojgRPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "\n",
        "print(image_files)"
      ],
      "metadata": {
        "id": "a5E_Pw6dgOMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")"
      ],
      "metadata": {
        "id": "LJKT0PFHhk5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Corrected removal loop\n",
        "for file in extra_images:\n",
        "    # Get only the filename without any folder\n",
        "    filename = os.path.basename(file)\n",
        "    image_path = os.path.join(dataset_path, \"images\", filename)\n",
        "    if os.path.exists(image_path):\n",
        "        os.remove(image_path)\n",
        "        print(f\"Removed: {image_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {image_path}\")\n",
        "\n",
        "for file in extra_labels:\n",
        "    filename = os.path.basename(file)\n",
        "    label_path = os.path.join(dataset_path, \"labels\", filename)\n",
        "    if os.path.exists(label_path):\n",
        "        os.remove(label_path)\n",
        "        print(f\"Removed: {label_path}\")\n",
        "    else:\n",
        "        print(f\"Not found: {label_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bd53OlLafsVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now removing them from the dataset:"
      ],
      "metadata": {
        "id": "HFC1RmdVhter"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.join(dataset_path,\"images\", file + '.jpg')"
      ],
      "metadata": {
        "id": "akqYMfZJjBop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check again if it worked:"
      ],
      "metadata": {
        "id": "ZfqxKksXihaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of all images paths in the dataset\n",
        "image_paths = [os.path.join(dataset_path, \"images\", image_name) for image_name in os.listdir(os.path.join(dataset_path, \"images\"))]\n",
        "\n",
        "# Get the list of all labels paths in the dataset\n",
        "label_paths = [os.path.join(dataset_path, \"labels\", label_name) for label_name in os.listdir(os.path.join(dataset_path, \"labels\"))]\n",
        "\n",
        "# Get the list of filenames without extensions\n",
        "image_files = {file.split(\"/\")[-1].split(\".\")[0] for file in image_paths}\n",
        "label_files = {file.split(\"/\")[-1].split(\".\")[0] for file in label_paths}\n",
        "# Find extra files in each folder\n",
        "extra_images = image_files - label_files\n",
        "extra_labels = label_files - image_files\n",
        "\n",
        "# Output the results\n",
        "print(f\"Extra images (without corresponding labels): {extra_images}\")\n",
        "print(f\"Extra labels (without corresponding images): {extra_labels}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "cluJu0Hqioo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are none! great!\n"
      ],
      "metadata": {
        "id": "B7LJCLrTI_69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "z-RqYz7GeYUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists(r\"Home Fire dataset\\test\\images\"))\n",
        "print(os.path.exists(r\"Fire and Smoke BBox COCO Dataset\\coco128\\images\\train2017\"))\n"
      ],
      "metadata": {
        "id": "3ao_GrDeelx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade numpy torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "D0SXxWDDyZpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install numpy torch torchvision\n"
      ],
      "metadata": {
        "id": "fnmYJdry2L5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 YOLOv8 Fire/Smoke CPU-Safe Trainer (v5 – Fast-Track Full 50 Epochs)\n",
        "import os, sys, yaml, glob, subprocess, importlib, torch, builtins, multiprocessing\n",
        "from ultralytics import YOLO\n",
        "import ultralytics\n",
        "\n",
        "# ============================================================\n",
        "# 1️⃣  Force NumPy globally\n",
        "# ============================================================\n",
        "def force_numpy():\n",
        "    try:\n",
        "        import numpy as np\n",
        "        _ = np.zeros((1, 1))\n",
        "        print(\"✅ NumPy working in main process.\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ NumPy issue: {e} — reinstalling…\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"numpy\"])\n",
        "        import numpy as np\n",
        "    builtins.np = importlib.import_module(\"numpy\")\n",
        "    sys.modules[\"numpy\"] = builtins.np\n",
        "    return builtins.np\n",
        "np = force_numpy()\n",
        "\n",
        "# ============================================================\n",
        "# 2️⃣  Safe torch.from_numpy patch\n",
        "# ============================================================\n",
        "_real_from_numpy = torch.from_numpy\n",
        "def safe_from_numpy(x):\n",
        "    try:\n",
        "        import numpy as np\n",
        "        builtins.np = np\n",
        "        sys.modules[\"numpy\"] = np\n",
        "        return _real_from_numpy(x)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ NumPy reload inside torch.from_numpy:\", e)\n",
        "        import importlib, numpy\n",
        "        importlib.reload(numpy)\n",
        "        builtins.np = numpy\n",
        "        sys.modules[\"numpy\"] = numpy\n",
        "        return _real_from_numpy(x)\n",
        "torch.from_numpy = safe_from_numpy\n",
        "\n",
        "# ============================================================\n",
        "# 3️⃣  Paths\n",
        "# ============================================================\n",
        "train_images = r\"Fire and Smoke BBox COCO Dateset\\coco128\\train2017\"\n",
        "val_images   = r\"Home Fire dataset\\test\\images\"\n",
        "yaml_path    = r\"fire_smoke\\data.yaml\"\n",
        "\n",
        "# ============================================================\n",
        "# 4️⃣  Dataset sanity check\n",
        "# ============================================================\n",
        "def check_images(path):\n",
        "    imgs = [f for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\")\n",
        "            for f in glob.glob(os.path.join(path, ext))]\n",
        "    print(f\"✅ Found {len(imgs)} images in {path}\")\n",
        "    return len(imgs)\n",
        "check_images(train_images); check_images(val_images)\n",
        "\n",
        "train_labels = train_images.replace(\"images\", \"labels\")\n",
        "os.makedirs(train_labels, exist_ok=True)\n",
        "for img in glob.glob(os.path.join(train_images, \"*.jpg\")):\n",
        "    label = os.path.join(train_labels, os.path.splitext(os.path.basename(img))[0] + \".txt\")\n",
        "    if not os.path.exists(label):\n",
        "        open(label, \"w\").close()\n",
        "\n",
        "# ============================================================\n",
        "# 5️⃣  YAML\n",
        "# ============================================================\n",
        "os.makedirs(os.path.dirname(yaml_path), exist_ok=True)\n",
        "yaml.safe_dump({\n",
        "    \"train\": os.path.abspath(train_images).replace(\"\\\\\", \"/\"),\n",
        "    \"val\":   os.path.abspath(val_images).replace(\"\\\\\", \"/\"),\n",
        "    \"nc\": 7,\n",
        "    \"names\": [\n",
        "        \"Fire\",\"Serious Smoke\",\"Moderate Smoke\",\"Mild Smoke\",\n",
        "        \"Steam / False Alarm\",\"Non-Fire Smoke\",\"Incense / Non-Threat Smoke\"\n",
        "    ]\n",
        "}, open(yaml_path, \"w\"))\n",
        "print(f\"✅ YAML ready → {yaml_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# 6️⃣  Info\n",
        "# ============================================================\n",
        "print(f\"\\n🔎 YOLO version: {ultralytics.__version__}\")\n",
        "print(\"⚠️ CUDA not available — CPU mode only.\" if not torch.cuda.is_available()\n",
        "      else f\"✅ CUDA: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7️⃣  Training (Fast-Track but Full 50 Epochs)\n",
        "# ============================================================\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "train_args = dict(\n",
        "    data=yaml_path,\n",
        "    epochs=50,              # full length\n",
        "    imgsz=416,              # smaller images = faster\n",
        "    batch=4,                # CPU-friendly\n",
        "    workers=0,              # avoid Windows hang\n",
        "    exist_ok=True,\n",
        "    augment=False,          # skip heavy transforms\n",
        "    freeze=10,              # freeze early backbone layers\n",
        "    save_period=10,         # save every 10 epochs\n",
        "    patience=5,             # early-stop if plateau\n",
        "    lr0=0.005,              # slightly higher learning rate for quicker convergence\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "    name=\"fire_smoke_yolov8n_cpu_fasttrack_full\"\n",
        ")\n",
        "\n",
        "print(\"\\n🚀 Starting YOLOv8 training (CPU Fast-Track 50 Epochs)…\\n\")\n",
        "model.train(**train_args)\n",
        "print(\"\\n✅ Training completed successfully (Fast-Track Full 50 Epochs).\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FbsPYfjcFigH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 🧪 WEEK 3 (Oct 21–24): Test model on new images/videos\n",
        "# ============================================================\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2, os, glob, torch, shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 🔹 0. Auto-prepare test directory\n",
        "# ------------------------------------------------------------\n",
        "val_dir  = r\"Home Fire dataset\\test\\images\"\n",
        "test_dir = r\"Home Fire dataset\\new_test\\images\"\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# If no images exist in new_test, copy 5 validation images\n",
        "existing = glob.glob(os.path.join(test_dir, \"*.jpg\"))\n",
        "if len(existing) == 0:\n",
        "    src_imgs = sorted(glob.glob(os.path.join(val_dir, \"*.jpg\")))[:5]\n",
        "    for src in src_imgs:\n",
        "        shutil.copy(src, test_dir)\n",
        "    print(f\"📁 Copied {len(src_imgs)} sample images from validation set → {test_dir}\")\n",
        "else:\n",
        "    print(f\"📂 Found {len(existing)} existing test images in {test_dir}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 🔹 1. Load trained model\n",
        "# ------------------------------------------------------------\n",
        "trained_model_path = r\"runs/detect/fire_smoke_yolov8n_cpu_safe/weights/best.pt\"\n",
        "assert os.path.exists(trained_model_path), f\"❌ Model not found at {trained_model_path}\"\n",
        "model = YOLO(trained_model_path)\n",
        "print(f\"✅ Loaded trained model → {trained_model_path}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 🔹 2. Run inference on test images\n",
        "# ------------------------------------------------------------\n",
        "num_imgs = len(glob.glob(os.path.join(test_dir, \"*.jpg\")))\n",
        "print(f\"📂 Testing on {num_imgs} images in {test_dir}\")\n",
        "\n",
        "pred_results = model.predict(source=test_dir, conf=0.5, save=True, name=\"week3_predict\")\n",
        "\n",
        "# Show sample predictions\n",
        "pred_folder = Path(\"runs/detect/week3_predict\")\n",
        "pred_imgs = sorted(pred_folder.glob(\"*.jpg\"))[:5]\n",
        "if pred_imgs:\n",
        "    for img_path in pred_imgs:\n",
        "        display(Image(filename=img_path))\n",
        "else:\n",
        "    print(\"⚠️ No predicted images found to display.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 🔹 3. Test on a video (if available)\n",
        "# ------------------------------------------------------------\n",
        "test_video = r\"Home Fire dataset\\videos\\fire_test.mp4\"\n",
        "if os.path.exists(test_video):\n",
        "    print(\"🎥 Running inference on video...\")\n",
        "    model.predict(source=test_video, conf=0.5, save=True, name=\"week3_video\")\n",
        "else:\n",
        "    print(\"⚠️ No test video found — skipping video inference.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 🔹 4. Basic error analysis (confidence stats)\n",
        "# ------------------------------------------------------------\n",
        "confidences = []\n",
        "for r in pred_results:\n",
        "    for b in r.boxes:\n",
        "        confidences.append(float(b.conf))\n",
        "\n",
        "if confidences:\n",
        "    plt.hist(confidences, bins=10)\n",
        "    plt.title(\"Distribution of Detection Confidences (Week 3)\")\n",
        "    plt.xlabel(\"Confidence Score\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "    print(f\"📊 Average confidence: {np.mean(confidences):.3f}\")\n",
        "else:\n",
        "    print(\"⚠️ No detections found in new test images.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 🔹 5. Generate report summary\n",
        "# ------------------------------------------------------------\n",
        "summary = f\"\"\"\n",
        "📅 Week 3 (Oct 21–24) – Model Evaluation Summary\n",
        "• Tested YOLOv8n Fire/Smoke model on new unseen images/videos\n",
        "• Saved predictions in: runs/detect/week3_predict/\n",
        "• Avg confidence: {np.mean(confidences):.3f} (based on {len(confidences)} detections)\n",
        "• Visual outputs ready for presentation slides\n",
        "\"\"\"\n",
        "print(summary)\n",
        "\n"
      ],
      "metadata": {
        "id": "3QA7O9_88drP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}